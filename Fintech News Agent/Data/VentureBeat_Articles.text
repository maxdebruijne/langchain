Total number of articles: 40

Date: August 31, 2023 3:24 PM
Author: Carl Franzen
Link: https://venturebeat.com/ai/openai-wants-teachers-to-use-chatgpt-for-education/
Title: OpenAI wants teachers to use ChatGPT for education
Content: It’s not only programming, journalism and content moderation that OpenAI is seeking to revolutionize with the use of its landmark large language models (LLMs) GPT-3, GPT-3.5 and GPT-4.
Today, the company published a new blog post titled “Teaching with AI” that outlines examples of six educators from various countries, mostly at the university level though one teaches high school, using ChatGPT in their classrooms. 
“We’re sharing a few stories of how educators are using ChatGPT to accelerate student learning and some prompts to help educators get started with the tool,” the company writes. 
The examples range from one educator using ChatGPT as a kind of educational role player, taking on the part of a debate rival or recruiter and engaging students in a dialog; to another teacher using ChatGPT for translation assistance for English-as-a-second-language students; to yet another having their students fact-check the information it generates.
The company also includes sample prompts developed by AI influencer and University of Pennsylvania Wharton School professor Ethan Mollick and his wife and fellow professor Lilach Mollick that assist teachers with lesson planning and even turn the default ChatGPT into an “AI tutor” for students. 
Asked by this VentureBeat author on X (formerly Twitter) if OpenAI paid Ethan Mollick for use of his and his wife’s prompts, he responded in the negative: “No. I have never taken any money or compensation in any way from OpenAI, including token credits,” adding “In this case, they used prompts and material we have already published.”
Of course, the issue of generative AI in the classroom — like with many topics related to the technology — has been fraught with controversy, especially with regards to students using it as a means of cutting corners or avoiding doing their own coursework, such as writing essays. 
In fact, several schools, districts, and departments of education around the globe have already banned ChatGPT and added it to their internet network blocklists, although the New York City Public School  system did an about-face in May and moved to allow teachers to use ChatGPT as they see fit. 
OpenAI made headlines earlier this year by releasing an “AI Text Classifier” that was designed to allow anyone, including educators, to copy and paste in text and determine whether or not it was written by AI, but then ended up discontinuing it last month due to its “low rate of accuracy.”  
Today, OpenAI elaborated on the issues with the Text Classifier in a new Educator FAQ (frequently asked questions), which is far more robust and arguably even more helpful for schools than its promotional blog post.
Answering the question of “How can educators respond to students presenting AI-generated content as their own?,” OpenAI answers to say: “While some (including OpenAI) have released tools that purport to detect AI-generated content, none of these have proven to reliably distinguish between AI-generated and human-generated content,” and “When we at OpenAI tried to train an AI-generated content detector, we found that it labeled human-written text like Shakespeare and the Declaration of Independence as AI-generated.”
In addition, OpenAI admits: “There were also indications that it could disproportionately impact students who had learned or were learning English as a second language and students whose writing was particularly formulaic or concise.”
Plus, as the company points out, “even if these tools could accurately identify AI-generated content (which they cannot yet), students can make small edits to evade detection.”
Instead, OpenAI notes that some teachers have begun asking students to show their conversations with ChatGPT as a form of displaying their critical thinking skills. 
Furthermore, while OpenAI says that there is research supporting the fact that “ChatGPT can be a helpful tool, alongside teachers, for providing students with feedback,” it does not link to this specific research, and says “it is inadvisable and against our Usage Policies to rely on models for assessment decision purposes without a ‘human in the loop.'”
In other words — the idea of a teacher handing over most of their duties to ChatGPT is not in the cards yet, or likely the foreseeable future, and same with students and their coursework. 
Still, the company clearly wants to promote the idea that ChatGPT can be a useful new tool for both sides of the educational equation, teachers and students alike, joining the familiar classroom sights of pencils, notebooks, computers, and globes. 


Date: August 31, 2023 10:03 AM
Author: Louis Columbus
Link: https://venturebeat.com/security/5-ways-cisos-can-prepare-for-generative-ai-security-challenges-and-opportunities/
Title: 5 ways CISOs can prepare for generative AI’s security challenges and opportunities
Content: With generative AI tools like ChatGPT proliferating across enterprises, CISOs have to strike a very difficult balance: Performance gains versus unknown risks. Gen AI is delivering greater precision to cybersecurity but also being weaponized into new attack tools such as FraudGPT that advertise their ease of use for the next generation of attackers.
Solving the question of performance versus risk is proving a growth catalyst for cybersecurity spending. The market value of gen AI-based cybersecurity platforms, systems and solutions is expected to rise to $11.2 billion in 2032 from $1.6 billion in 2022. Canalys expects generative AI to support more than 70% of businesses’ cybersecurity operations within five years.
Gen AI attack strategies are focused on getting control of identities first. According to Gartner, human error in managing access privileges and identities caused 75% of security failures, up from 50% two years ago. Using gen AI to force human errors is one of the goals of attackers.
VentureBeat interviewed Michael Sentonas, president of CrowdStrike, to gain insights into how the cybersecurity leader is helping its customers take on the challenges of new, more lethal attacks that defy existing detection and response technologies.
Sentonas said that “the hacking [demo] session that [we] did at RSA [2023] was to show some of the challenges with identity and the complexity. The reason why we connected the endpoint with identity and the data that the user is accessing is because it’s a critical problem. And if you can solve that, you can solve a big part of the cyber problem that an organization has.” 
Leading cybersecurity vendors are up for the challenge of fast-tracking gen AI apps through DevOps to beta and doubling down on their many models in development.
During Palo Alto Networks‘ most recent earnings call, chairman and CEO Nikesh Arora emphasized the intensity the company is putting into gen AI, saying, “we’re doubling down, we’re quadrupling down to make sure that precision AI is deployed across every product. And we open up the floodgates of collecting good data with our customers for them to give them better security because we think that is the way we’re going to solve this problem to get real-time security.” 
For CISOs and their teams to win the war against AI attacks and threats, gen AI-based apps, tools and platforms must become part of their arsenals. Attackers are out-innovating the most adaptive enterprises, sharpening their tradecraft to penetrate the weakest attack vectors. What’s needed is greater cyber-resilience and self-healing endpoints.
Absolute Software’s 2023 Resilience Index reveals how challenging it is to excel at the comply-to-connect trend. Balancing security and cyber-resilience is the goal, and the Index provides a useful roadmap. Cyber-resilience, like zero trust, is an ongoing framework that adapts to an organization’s changing needs.
Every CEO and CISO VentureBeat interviewed at RSAC 2023 said employee- and company-owned endpoint devices are the fastest-moving, hardest-to-protect threat surfaces. With the rising risk of gen AI-based attacks, resilient, self-healing endpoints that can regenerate operating systems and configurations are the future of endpoint security.
Central to being prepared for gen AI-based attacks is to create muscle memory of every breach or intrusion attempt at scale, using AI and machine learning (ML) algorithms that learn from every intrusion attempt. Here are the five ways CISOs and their teams are preparing for gen AI-based attacks.
Despite the security risk of confidential data being leaked into LLMs, organizations are intrigued by boosting productivity with gen AI and ChatGPT. VentureBeat’s interviews with CISOs reveal that these professionals are split on defining AI governance. For any solution to this problem to work, it must secure access at the browser, app and API levels to be effective.
Several startups and larger cybersecurity vendors are working on solutions in this area. Nightfall AI’s recent announcement of an innovative security protocol is noteworthy. The company’s customizable data rules and remediation insights help users self-correct. The platform gives CISOs visibility and control so they can use AI while ensuring data security. 
SOC teams are seeing more sophisticated social engineering, phishing, malware and business email compromise (BEC) attacks that they attribute to gen AI. While attacks on LLMs and AI apps are nascent today, CISOs are already doubling down on zero trust to reduce these risks.
That includes continuously monitoring and analyzing gen AI traffic patterns to detect anomalies that could indicate emerging attacks and regularly testing and red-teaming systems in development to uncover potential vulnerabilities. While zero trust can’t eliminate all risks, it can help make organizations more resilient against gen AI threats.
Gen AI’s potential to improve microsegmentation, a cornerstone of zero trust, is already happening thanks to startups’ ingenuity. Nearly every microsegmentation provider is fast-tracking DevOps efforts. 
Leading vendors with deep AI and ML expertise include Akamai, Airgap Networks, AlgoSec, Cisco, ColorTokens, Elisity, Fortinet, Illumio, Microsoft Azure, Onclave Networks, Palo Alto Networks, VMware, Zero Networks and Zscaler.
One of the most innovative startups in microsegmentation is Airgap Networks, named one of the 20 best zero-trust startups of 2023. Airgap’s approach to agentless microsegmentation reduces the attack surface of every network endpoint, and it is possible to segment every endpoint across an enterprise while integrating the solution into an existing network with no device changes, downtime or hardware upgrades.
Airgap Networks also introduced its Zero Trust Firewall (ZTFW) with ThreatGPT, which uses graph databases and GPT-3 models to help SecOps teams gain new threat insights. The GPT-3 models analyze natural language queries and identify security threats, while graph databases provide contextual intelligence on endpoint traffic relationships.
“With highly accurate asset discovery, agentless microsegmentation and secure access, Airgap offers a wealth of intelligence to combat evolving threats,” Airgap CEO Ritesh Agrawal told VentureBeat. “What customers need now is an easy way to harness that power without any programming. And that’s the beauty of ThreatGPT — the sheer data-mining intelligence of AI coupled with an easy, natural language interface. It’s a game-changer for security teams.”
Security is often tested right before deployment, at the end of the software development lifecycle (SDLC). In an era of emerging gen AI threats, security must be pervasive throughout the SDLC, with continuous testing and verification. API security must also be a priority, and API testing and security monitoring should be automated in all DevOps pipelines.
While not foolproof against new gen AI threats, these practices significantly raise the barrier and enable quick threat detection. Integrating security across the SDLC and improving API defenses will help enterprises thwart AI-powered threats.
A zero-trust approach to every interaction with AI tools, apps and platforms and the endpoints they rely on is a must-have in any CISO’s playbook. Continuous monitoring and dynamic access controls must be in place to provide the granular visibility needed to enforce least privilege access and always-on verification of users, devices and the data they’re using, both at rest and in transit. 
CISOs are most worried about how gen AI will bring new attack vectors they’re unprepared to protect against. For enterprises LLMs, protecting against query attacks, prompt injections, model manipulation and data poisoning are high priorities.
CISOs, CIOs and their teams are facing a challenging problem today. Do gen AI tools like ChatGPT get free reign in their organizations to deliver greater productivity, or are they bridled in and controlled, and if so, by how much? Samsung’s failure to protect IP is still fresh in the minds of many board members.
One thing everyone agrees on, from the board level to SOC teams, is that gen AI-based attacks are increasing. Yet no board wants to jump into capital expense budgeting, especially given inflation and rising interest rates. The answer many are arriving at is accelerating zero-trust initiatives. While an effective zero-trust framework isn’t stopping gen AI attacks completely, it can help reduce their blast radius and establish a first line of defense in protecting identities and privileged access credentials.


Date: August 31, 2023 9:00 AM
Author: Michael Nuñez
Link: https://venturebeat.com/ai/pirros-a-startup-that-applies-ai-to-streamline-drawing-sets-for-buildings-and-infrastructure-lands-2-million-seed-round/
Title: Pirros, a startup that applies AI to streamline drawing sets for buildings and infrastructure, lands $2 million seed round
Content: Pirros, a technology platform that helps architecture and engineering firms manage their drawing sets more efficiently, announced today that it has raised a $2 million seed round from a group of investors and advisors with deep industry connections.
Notable contributors to the funding round include angel investors Carl Bass, former chief executive of Autodesk; Joseph Walla of HelloSign; and Ryan Sutton-Gee of the construction software firm PlanGrid. Venture capital firms including YCombinator, FundersClub and Twenty Two Ventures also participated in the seed round.
Pirros is a tool created to streamline detail management for architecture and engineering firms. It automatically categorizes and catalogs the primary deliverable of design professionals: The many thousands of drawing sets that firms create each year for buildings and infrastructure.
Most firms currently face an extremely inefficient paradigm of creating, using and effectively discarding design details — not because they are no longer useful, but because they are stored on on-premises servers with little to no ability to rediscover and reuse them. This means architects and engineers have to re-create drawings over and over for each project, which has the further effect of stripping them of the quality control process they went through in the course of initial creation.
With Pirros, architects and engineers can spend more time actually designing buildings instead of documenting them. This is achieved by automatic information aggregation and storage, so that all of a company’s outputs are stored and managed in a centralized, searchable platform for easy future re-use.
Pirros CEO and cofounder Ari Baranian said in an interview with VentureBeat: “Every company has tried to build out a small catalog, so about a couple of hundred details, and these will be the most common details that they’ve used … There’s just never been the tools to expand the catalog beyond 100, 200, or even 500 details.”
He further emphasized: “Now, our average company has over 10,000 [searchable] details on the platform. So with that ability, any new architect, any new engineer that joins the firm, quickly gets up to speed on the different standards of that office.”
The proof is in the rapid adoption of the tool among some of the industry’s biggest players. The software is already being used by more than 30 firms including large architecture companies like KPFF Engineers and RAMSA.
Pirros leverages the metadata from the building information models (BIMs) that firms use to create their drawing sets. It extracts and indexes this data into a searchable and reusable catalog of 2D assets. It also uses clustering algorithms to group similar details together so that users can see different versions of the same condition and choose the best one.
The platform integrates seamlessly with any firm’s existing tools or workflows. The onboarding process is simple: Firms just need to identify the models they want to include in their Pirros catalog, and Pirros does the rest of the work with its integration pipeline.
The company has received positive feedback from its customers, especially from the youngest architects and engineers who use its platform. 
“Seeing the amount of traction that we’ve gotten with the youngest architects and engineers was surprising to us, but also super motivating to see that we’re actually making an impact there.” said Baranian.
Pirros plans to use the $2 million seed funding to grow its team, improve its product and expand its market. One of the upcoming features that Baranian is excited about is using AI to identify the best versions of every detail automatically and provide users suggestions and recommendations.
Pirros is a pioneer in the field of architectural detail management, which has been largely overlooked by other technology platforms. By solving this specific problem, Pirros aims to transform the way buildings are designed and documented. 
As Baranian put it: “We built our product exactly as we would have wanted to use it.”


Date: August 31, 2023 8:59 AM
Author: Michael Nuñez
Link: https://venturebeat.com/enterprise-analytics/meet-superframe-the-ai-startup-that-wants-to-be-your-copilot-for-revenue-operations/
Title: Meet Superframe, the AI startup that wants to be your copilot for revenue operations
Content: Superframe, an AI-powered software company aiming to help businesses optimize their go-to-market technology stacks, announced today that it has raised $5 million in seed funding from more than 40 angel investors, including data and AI experts, Salesforce consultants and general operating experts.
The round comes on the heels of Superframe’s launch of its first official product, an AI assistant for managing complex Salesforce implementations. The startup says its technology will save companies time and money by making Salesforce configuration changes fast, safe, reliable and easy.
Derek Steer, cofounder and CEO of Superframe, said that accuracy is going to be the company’s number one differentiator in the AI market. 
“We want to fight the consumer frustration with a lack of accuracy. We want to build trust with our customers by giving them something they can’t get somewhere else,” he told VentureBeat in a recent interview.
Steer is no stranger to the data and AI world, as he previously sold his last company Mode, a business intelligence platform, to Thoughtspot for $200 million.
In the long term, Superframe aims to solve the pain points that many companies face when they implement go-to-market tools, such as Salesforce, Marketo and HubSpot. These tools are often complex, rigid and hard to configure, resulting in wasted time, money and resources. Superframe uses the latest language models from OpenAI (ChatGPT) to provide instant and accurate answers to questions about the current state of the system, and to propose and implement configuration changes based on the users’ description of what they want to do.
Steer also said that Superframe will not replace humans, but rather enable them to rely on their expertise and clear their backlogs. 
“We want to help more people build more expertise,” he said. “And that’s something that customers are still going to want to rely on.” 
He added that Superframe will help customers map out their business processes and configure their systems without being held back by the complexity and rigidity of the tools.
Superframe is currently in beta testing with a select group of customers, and plans to launch publicly in early 2024. The first phase of Superframe, which is answering questions about the system, will be free for users. The company plans to use the seed funding for product development and hiring more engineers. The startup currently has four employees.
Superframe is one of the many startups that are using AI to simplify and optimize business operations. According to a recent Gartner report, the market for AI software will reach almost $134.8 billion by 2025. The report also cites the increasing adoption of cloud-based services and applications as one of the key drivers for the AI market growth.
Superframe’s vision is to become the copilot for revenue operations teams, and to help them think more creatively about their go-to-market strategies. 
“We believe that humans are capable of a lot,” said Steer. “And we are in a lot of cases bottlenecked by the tools that we use. We want to remove those bottlenecks in order to give people a greater ability to employ their creativity.”


Date: August 31, 2023 7:25 AM
Author: Press Release
Link: https://venturebeat.com/business/daversa-partners-ranks-among-top-20-best-medium-workplaces-2023-according-to-fortune-media-and-great-place-to-work/
Title: Daversa Partners Ranks Among Top 20 Best Medium Workplaces 2023, According to Fortune Media and Great Place To Work®
Content: NEW YORK–(BUSINESS WIRE)–August 31, 2023–
Great Place To Work® and Fortune magazine have selected Daversa Partners as one of 2023’s 100 Best Medium Workplaces. Coming in at No. 19, this means that Daversa Partners has earned a spot as one of the best companies to work for in the country.
This press release features multimedia. View the full release here: https://www.businesswire.com/news/home/20230831931182/en/
To determine the Best Medium Workplaces list, Great Place To Work analyzed the survey responses of over 210,000 employees from Great Place To Work Certified™ companies with 100 to 999 U.S. employees.
The Best Medium Workplaces list is highly competitive. Great Place To Work, the global authority on workplace culture, determines its lists using its proprietary For All™ methodology to evaluate and certify thousands of organizations in America’s largest ongoing annual workforce study, based on over 1.3 million survey responses and data from companies representing more than 7.5 million employees this year alone.
Survey responses reflect a comprehensive picture of the workplace experience. Honorees were selected based on their ability to offer positive outcomes for employees regardless of job role, race, gender, sexual orientation, work status, or other demographic identifier.
“This year, we celebrate 30 years of Daversa Partners,” said Paul Daversa, Founder and CEO of Daversa Partners. “Over these three decades, we have had the privilege of being a part of the dynamic evolution of the tech industry. This journey has not just been about our growth as a firm, but about the remarkable founders, funders, and operators who have undeniably shaped the ecosystem with their strategic vision. We are proud and grateful to play a role in this evolution.”
In 2022, Daversa Partners earned Great Place to Work™ Certification, with 95% of employees saying that “people care about each other here.” Daversa Partners was also awarded Best Workplaces for Women™ by Fortune and Great Place to Work® in 2022 – a testament to the firm’s commitment to the 64% of women who make up the company, with 56% at the leadership level. So far this year, Daversa Partners has secured a No.4 spot on Fortune’s 2023 Best Workplaces in New York list, was named a 2023 Best Workplace for Millennials, and recertified as a Great Place to Work™.
About Daversa Partners
For three decades, Daversa Partners has built the leading management teams across the most disruptive companies of this generation, focused on serving the global founder and funder community around the world. Having worked alongside tech’s top VC and PE firms, Daversa Partners has had the privilege to build over 10,000 consumer and enterprise companies, all of which hold a shared vision: push the throttle on innovation. The company today is an important strategic partner that moves top executives into startup and growth oriented companies.
About the Fortune Best Medium Workplaces List
Great Place To Work selected the Fortune Best Medium Workplaces List by surveying companies employing 7.5 million people in the U.S. with 1.3 million confidential responses received. Of those, more than 210,000 responses were received from employees at companies eligible for the Best Medium Workplaces list and this ranking is based on that feedback. Company scores are derived from 60 employee experience questions within the Great Place To Work Trust Index™ Survey. Read the full methodology.

View source version on businesswire.com: https://www.businesswire.com/news/home/20230831931182/en/
Nicole DaversaNicole@daversapartners.com


Date: August 31, 2023 6:53 AM
Author: Carl Franzen
Link: https://venturebeat.com/ai/ibm-and-salesforce-team-up-to-bring-ai-tools-to-their-shared-clients/
Title: IBM and Salesforce team up to bring AI tools to their shared clients
Content: Big Blue is teaming with an even Bigger Blue to deliver AI solutions to clients.
Today, IBM and Salesforce announced they are joining forces to bring Salesforce AI solutions (Sales GPT, Service GPT, Salesforce Einstein, Slack GPT and Marketing GPT) to customers who do business with both companies.
Obviously, what Salesforce brings to the table is its popular and powerful customer relationship management (CRM) software, in addition to the aforementioned AI apps and tools. 
What IBM offers through the partnership is “industry expertise and innovative delivery models” through its IBM Consulting arm of 160,000 human consultants, the company said in a press release. 
Specifically, this includes “IBM Garage … an operating model for business transformation,” which will help the combined clients get their Salesforce AI integrations up and running.
IBM notes that the shared customers may also wish to adopt its Watsonx enterprise AI platform for finding and fine-tuning enterprise grade AI models. WatsonX can further help customers find “data locked in backend systems” that they can better access and leverage through their shiny new Salesforce and open-source AI models.
Further, customers should consider using IBM’s Data Classifier, an “AI-powered application trained on industry-specific data models,” to help them map all their internal data to make it useful and accessible to the AI tools and apps, IBM says. 
“Companies are embarking on a transformative journey fueled by generative AI,” Steve Corfield, Salesforce EVP and GM of global alliances and channels said in a press release. “Salesforce partners like IBM Consulting play an important role in helping businesses use Salesforce’s AI, data and CRM technologies to connect with their customers on a new level. Bringing Salesforce and IBM innovations together will help transform the way companies deliver personalized, engaging experiences.” 
IBM is practicing what it preaches. The original Big Blue used Salesforce and its own watsonx to overhaul its customer service and sales processes — now it’s hoping to do the same for many others around the globe.


Date: August 31, 2023 5:00 AM
Author: Carl Franzen
Link: https://venturebeat.com/ai/gong-introduces-call-spotlight-a-generative-ai-summary-of-customer-calls-for-revenue-teams/
Title: Gong’s new Call Spotlight uses AI to summarize customer calls for revenue teams
Content: Gong, the nine-year-old company focused on making technology that streamlines workflows for revenue teams across sectors, made news earlier this summer by introducing new generative AI-powered features to its customer conversation analysis platform, including gen AI messaging suggestions. 
Now, it’s going a step further: The company today announced exclusively with VentureBeat that it is introducing the new feature Call Spotlight, accessible for all of its 4,000 platform customers (and counting) globally, at no extra charge.
The new AI-driven tool (powered by a mix of proprietary Gong AI models and GPT-4 in Microsoft Azure OpenAI Service) automatically transcribes and analyzes a revenue team member’s conversation with a customer over video call, audio call, mobile or desktop, even emails and text correspondence — any communications the revenue team member wants — and auto-generates a summary and key points for the revenue team to act on.
For Gong’s largely business-to-business (B2B)-focused clients, who spend lots of time prospecting customers of their own and managing customer relationships through direct correspondence, the tool is poised to offer increased productivity and efficiency.
At the same time, Gong hopes the new feature allows revenue teams and salespeople even more time to forge and maintain the unique customer relationships that are key to landing business. 
“You become more efficient” using Call Spotlight, Gong chief product officer and cofounder Eilon Reshef, said in a video call with VentureBeat. “You don’t need to review the whole text. You don’t need to listen to the whole call. You don’t need to take notes. You don’t need to do anything manually.”
Just enable Call Spotlight through Gong’s platform — there are modes that will prompt the other parties in any given call to agree to being recorded and analyzed by Gong’s AI — and it will take care of it for you.
Gong says that Call Spotlight is unmatched in its accuracy, offering sales insights that are twice as reliable as generic solutions available on the market such as other consumer large language models (LLMs), having been trained on billions of sales interactions that Gong sourced from customers.
“What’s unique about Gong is that because we train the system based on revenue conversations, we get much more accurate results,” Reshef told VentureBeat.
This includes a more accurate AI interpreter of specific company and product names — something other auto-transcription AI services often struggle to handle, in VentureBeat’s testing, defaulting to generic words instead of trademarks.
One of Call Spotlight’s standout features is its unique “Ask Anything” function — the first of its kind tailored specifically for sales. Think of it as your personal sales coach, ready to answer any question you throw at it.
Whether it’s seeking guidance on sealing a deal or understanding why a particular conversation matters to a regional account executive, Ask Anything delivers precise, context-rich advice.
For instance, after a call, a sales rep might wonder, “What can I do to up my game for closing this deal?” Ask Anything churns out actionable steps based on its deep learning of a specific customer interaction, with context pulled from Gong’s extensive sales data.
Similarly, if a manager wants to know whether competitors were name-dropped during a conversation, the tool can sift through the call details and flag any potential threats, allowing for targeted coaching strategies.
In addition to the Ask Anything feature, Call Spotlight includes:
Gong customers can also share any of these AI-generated products with their colleagues and managers as needed, and also push data to their customer relationship management (CRM) software of choice for recordkeeping — or not. It’s all up to the customer to decide what to do with their gen AI work products.
Furthermore, Gong knows that security is top-of-mind for many of its customers, and seeks to reassure them that safeguarding their data is of paramount importance while introducing all of these new gen AI features. 
“One of the critical elements for us is security,” said Reshef. “We have some of the Fortune top 50 companies as customers, and they are very concerned about security and unlikely to allow us to sell their data outside the company. So we hire Gong employees and do everything in-house.”
Gong noted that it has been recording calls since 2016, and is GDPR-compliant and has stayed up-to-date on all relevant regulations in the years since. 
By marrying highly accurate, context-specific advice with a range of other features and security, Gong hopes that Call Spotlight will be a game-changer for the revenue teams that try it out.


Date: August 30, 2023 1:21 PM
Author: Sharon Goldman
Link: https://venturebeat.com/ai/ai21-labs-raises-155m-to-accelerate-genai-for-enterprises/
Title: AI21 Labs raises $155M to accelerate generative AI for enterprises
Content: Tel Aviv, Israel-based large language model (LLM) leader AI21 Labs confirmed with VentureBeat that it has has closed $155 million in series C funding to accelerate the growth of its text-based generative AI services for enterprises. The company is now valued at $1.4 billion. 
Investors in the round include Walden Catalyst, Pitango, SCB10X, b2venture, Samsung Next and Amnon Shashua with participation from Google and Nvidia. 
Founded in 2017 by AI pioneers and technology veterans Amnon Shasuha, Yoav Shoham and Ori Goshen, AI21 Labs may have been one of the first to bring gen AI to the masses, but it has also spent the past year chasing LLM rivals like OpenAI to commercial applications. 
After a $64 million series B round last year, Shoham, an emeritus professor of AI at Stanford University, told VentureBeat that he recognized that the funding landscape was tightening and more LLMs and multimodal models were being launched every day. 
He said the company was “very aware of the environment and not complacent in any way.” 
AI21’s proprietary Jurassic-2 foundation models are considered some of the world’s largest and most sophisticated LLMs. Jurassic-2 powers AI21 Studio, a developer platform for building custom text-based business applications off of AI21’s language models; and Wordtune, a multilingual reading and writing AI assistant for professionals and consumers.
AI21 chairman Shashua said in a press release: “AI21 Labs is a pure play in AI as it develops and owns foundation models which are served as a platform to developers and enterprises, while developing derivatives such as Wordtune directly to end users. The current round fuels the growth of the company to reach its goal of developing the next level of AI with the capabilities of reasoning across many domains. We believe that the impact of AI21 Labs growth plans would be of a global scale and quite soon.”
Jensen Huang, founder and CEO of Nvidia, also shouted out AI21’s work in the press release: “Generative AI is driving a new era of computing across every industry,” he said. “The innovative work by the AI21 Labs team will help enterprises accelerate productivity and efficiency with generative AI-based systems that are accurate, trustworthy and reliable.”
AI21 has recently collaborated with customers in diverse sectors, including Carrefour, Clarivate, eBay, Guesty, Monday.com and Ubisoft. The company was also named on the first ever CB Insights GenAI 50.


Date: August 30, 2023 9:39 AM
Author: Carl Franzen
Link: https://venturebeat.com/ai/sprig-uses-ai-to-transform-product-surveys-into-conversational-data/
Title: Sprig uses AI to transform product surveys into conversational data
Content: Sprig, a five-year-old startup focused on creating smart, contextually aware in-app surveys for enterprises, earned a big vote of confidence last year, securing $30 million in funding from prominent venture capital firms including a16z and Accel.
Today, the company is announcing where some of those funds went: A new feature Sprig calls AI Analysis for Surveys, which, as the name suggests, uses generative AI large language models (LLMs) to intelligently comb through survey data and provide instantaneous insights to the company that conducted the survey.
To put it more bluntly: Sprig’s AI Analysis for Surveys transforms survey data into a conversational AI product. 
With it, you as the survey owner can ask your survey results any conceivable question, and the AI will sort through them and attempt to respond with the most appropriate data, insights, takeaways or suggestions — and this includes qualitative survey data like open-ended text entries, not just multiple choice or quantitative answers.
“You can ask Sprig AI to answer any custom questions about your survey data, and it will analyze responses across all of your survey questions to find the answer,” Sprig CEO Ryan Glasgow, wrote in a blog post about the news. 
The company also announced an expanded free plan, and new large enterprise customers including PayPal, Figma, Ramp, Peloton and Mixpanel.
“World-class product teams continue to choose our platform because they value their user experience and have found Sprig to be a mission-critical platform to differentiate their products in today’s competitive environment,” wrote Glasgow.
Sprig first made waves in 2020 with the launch of its in-product survey platform and Open-Text AI Analysis feature, which automatically groups open-ended survey responses (those questions that ask you to write about your experience in a text box) into themes. 
The feature was adopted quickly by leading enterprises including Dropbox, Loom, Coinbase, Robinhood and Square. To date, Sprig has analyzed feedback from more than 6 billion product visitors across hundreds of high-growth technology companies.
With the new AI Analysis for Surveys, Sprig takes it to the next level by analyzing entire survey datasets. Product teams can now:
Glasgow wrote in an email to VentureBeat: “AI Analysis for Surveys solves a common pain point for product teams looking to deeply understand and optimize a specific part of their product experience, from understanding why users are churning out of a product to figuring out how to boost the conversion funnel.”
In addition to rolling out AI Analysis for Surveys, Sprig is expanding its free plan to make its AI-powered product insights accessible to more teams.
The free plan now includes in-product surveys, session replays and Open-Text AI Analysis. Teams of all sizes can immediately start using Sprig and the new AI Analysis for Surveys feature set.


Date: August 30, 2023 8:25 AM
Author: Press Release
Link: https://venturebeat.com/business/fianu-labs-secures-2-million-in-seed-funding-from-datatribe-to-automate-governance-of-software-development/
Title: Fianu Labs Secures $2 Million in Seed Funding from DataTribe to Automate Governance of Software Development
Content: 
Companies will soon be Liable for the Safety of Their Software for Consumers, Companies, and Governments.

FULTON, Md.–(BUSINESS WIRE)–August 30, 2023–
Fianu Labs, the software governance automation solution, today secured a $2 million seed investment from DataTribe, a global cyber foundry that invests in and co-builds next-generation cybersecurity and data science companies.
For businesses in regulated industries, the weight of software regulation is onerous. Each software release requires hundreds of hours of manual evidence gathering, leading to longer release cycles that stifle innovation and cost tens of millions of dollars in lost productivity every year. There looks to be no relief in sight as regulators have signaled a renewed focus on software development practices in response to recent attacks on the software supply chain. Businesses are in dire need of a solution that streamlines their compliance and shortens release cycles.
Fianu Labs is pioneering the path for businesses to succeed in the era of software regulation with an intuitive approach to governance that instills confidence in each release. Fianu captures and maintains a continuous audit trail that tells the story of each code change, from commit to release and automates a once chaotic manual process with speed and clarity. At its core, Fianu bridges the gap between Security, Quality Assurance, Engineering, and Risk with a shared language and a unified front to regulators and auditors. The result is reduced risk, faster release cycles, and easier audits.
“Fianu is truly revolutionizing secure software development observability,” said Leo Scott, Chief Innovation Officer for DataTribe and a Fianu Board of Directors member. “Fianu gives Chief Technology Officers, Chief Security Officers, and Chief Information Officers confidence to deliver software at the speed they want and with the integrity required.”
Over the last three years, the federal government has signaled increased scrutiny of software release patterns foreboding an era of crippling red tape and higher costs that could create significant challenges for companies across the regulatory landscape. Additionally, recent rulings have expanded the liability of software vendors and their executives. The message is clear: Companies that develop software will be held accountable for the security of their products. Fianu aims to reduce the weight of regulation for established companies while helping smaller and traditionally less-regulated companies transition to the new era of software development.
The company is providing visibility into the software development process in a provable way, enabling organizations to immutably attest to fundamental, sound, and secure software development best practices. Today, the demand is in regulated industries, but in the future, all companies producing custom software solutions will need to meet software governance requirements.
Fianu’s platform captures evidence across the DevSecOps toolchain mapped to internal policy during real-time, continuous audits against established risk controls and compliance frameworks. Each software release is accompanied by a Software Bill of Attestations (SBOA) designed to transmit immutable, audit-worthy evidence. By using Fianu, companies can replace opaque manual processes with streamlined, intuitive automation that makes software governance and compliance easy.
“There is no better team than DataTribe to help us realize our vision of a governance ecosystem that powers a modern approach to continuous delivery under rigorous regulatory requirements,” said Michael Edenzon, CEO and co-founder of Fianu Labs.
About DataTribe
DataTribe is a startup foundry that invests in and co-builds world-class startups focused on generational leaps in cybersecurity and data science. Founded by leading investors, startup veterans, and alumni of the U.S. intelligence community, DataTribe commits capital, in-kind services, access to an unparalleled network, and decades of professional expertise to give their companies an unfair advantage. DataTribe is headquartered in the Washington-Baltimore metro area in Fulton, Maryland. For more information, visit datatribe.com.
About Fianu Labs
Fianu Labs is a pioneer in the field of governance engineering and RegTech. Our focus is building software products to empower companies to deliver compliant software with maximum velocity. Fianu Labs is headquartered in Washington, D.C., and was founded by leaders in software governance, co-authors of Investments Unlimited, and software delivery experts from one of the nation’s largest banks. For more information, visit fianu.io.

View source version on businesswire.com: https://www.businesswire.com/news/home/20230830073713/en/
Josh Zecherjosh@vrge.us


Date: August 30, 2023 8:00 AM
Author: Shubham Sharma
Link: https://venturebeat.com/ai/typeface-teams-with-growthloop-and-google-cloud-to-launch-unified-genai-marketing-solution/
Title: Typeface teams with GrowthLoop and Google Cloud to launch unified ‘GenAI Marketing Solution’
Content: AI company Typeface has partnered with marketing player GrowthLoop and Google Cloud with the goal of transforming marketing for organizations of all sizes. The companies today announced a unified “GenAI Marketing Solution” that brings together the best of their respective platforms and gives marketers an end-to-end approach to create and launch campaigns across channels, at scale.
The offering allows teams to produce personalized content — from blogs to social media posts — for their campaigns, leveraging data from Google BigQuery, audience segmentation from GrowthLoop and Typeface’s generative AI smarts. According to the companies, it can cut the time taken to build and launch creative campaigns from several weeks down to days or even a few hours. 
“Marketing leaders across the globe have shared with us that producing personalized content at scale across audience segments can be a significant challenge, often causing campaigns to take months and months to launch,” Vishal Sood, head of product at Typeface, said in a statement. “The GenAI Marketing Solution announced at Google Cloud Next offers marketers — for the first time ever — the ability to rapidly generate and deploy tailored, on-brand content across customer segments. With this new solution, marketing teams can dramatically accelerate campaign launches freeing up time for more creativity and collaboration.”
Currently available in private preview for Google BigQuery users, the GenAI Marketing Solution merges gen AI from Typeface into a streamlined workflow that covers every aspect of the campaign creation process, from extracting 360-degree customer profiles and defining audience segments to creating personalized, on-brand content, distributing it and measuring the results.
First, users have to connect their BigQuery instance with GrowthLoop and use the latter’s visual or natural language builder to query data in the data warehouse and create audience segments to target. Once the segments are ready, they can export them to a marketing channel of choice, such as Google Ads, and use the Typeface integration with GrowthLoop to develop personalized creatives, ad copies, and campaign assets with text prompts.
As they develop the initial campaign assets, they can expand the effort by using Typeface to create an entire library of content for different marketing channels — such as personalized Instagram ads, SEO-optimized blog posts, and landing pages — that align with the GrowthLoop audience profile. This gives multiple variations of content, tailored to defined audience segments and brand voice, for different touchpoints.
Post-launch, teams can measure the results of the campaign directly within GrowthLoop, down to individual metrics such as revenue generated.
“Our collaboration results in an extraordinary solution, one that promises to reshape marketing workflows for businesses across the globe,” said Chris Sell, cofounder and co-CEO of GrowthLoop. “As we harness the transformative power of generative AI, we find ourselves at the cusp of a new chapter, empowering digital marketing teams with unparalleled efficiency and success-driving tools.”
While it remains unclear when the unified GenAI Marketing Solution will become generally available, there’s no denying that the move to rope in generative technologies is a welcome change for marketers who are facing increasing pressure to create compelling, personalized content to drive results in today’s fast-paced environment.
According to a Salesforce survey of more than 1,000 full-time marketers in the U.S., U.K. and Australia, gen AI is being seen as a “game-changer” that can save an employee about five hours of work every week. That’s more than a month every year, assuming eight-hour work days.
Among those using the technology at present, the most popular use case is basic content creation and writing marketing copy, with as many as 76% handling those tasks with LLM-driven apps like ChatGPT. The next most popular use cases are inspiring creative thinking (71%), analyzing market data (63%) and generating image assets (62%). 
Notably, LinkedIn’s Campaign Manager has already debuted a feature that allows users to generate introductory text and headlines for ads, using their data from the platform, while Meta has an AI Sandbox that lets advertisers create variations of basic copy for different audiences through text prompts.


Date: August 30, 2023 7:16 AM
Author: Sharon Goldman
Link: https://venturebeat.com/ai/ibm-serves-up-ai-generated-tennis-commentary-and-draw-analysis-at-the-us-open/
Title: At the US Open, IBM serves up AI-generated tennis commentary and draw analysis
Content: Back in May, IBM doubled down on its AI efforts with the announcement at the company’s annual Think conference of its new Watsonx product platform, which provides a foundational model library that can be used to fine-tune pretrained models for enterprise application development. 
Now, the company is serving up what it hopes is a generative AI ace: For the first time, it is offering AI-generated audio tennis highlights for all matches during the two-week-long U.S. Open Tennis Championships, as well as AI-powered analysis to determine the projected difficulty of player draws and potential opponents. 
More than 700,000 people head to Flushing Meadows, New York, each year to watch the best tennis players in the world compete, while more than 10 million tennis fans around the world follow the tournament through the U.S. Open app and website. And, for three decades, IBM has been working with the United States Tennis Association on creating digital experiences for tennis fans. 
The effort begins in the basement-level IBM data operations center at Arthur Ashe Stadium, where millions of data points are captured and analyzed. There are typically 56 data points collected for every single point of a tennis match. 
IBM is using gen AI models built, trained and deployed with Watsonx, and operating across a hybrid cloud infrastructure from Red Hat OpenShift, to generate detailed audio narration and captions to accompany U.S. Open highlight videos at unprecedented scale — for every match in the singles draw, across all 17 courts.
In addition, IBM debuted its Watsonx-powered AI Draw Analysis that uses both structured and unstructured data to project the level of advantage or disadvantage of all players in the singles draw. Each player receives an IBM AI Draw Analysis at the start of the tournament, which will be updated daily as the tournament progresses and players are eliminated. Every draw is ranked, allowing fans to click into individual matches and see the projected difficulty of their draw and potential opponents.
Kirsten Corio, chief commercial officer at the USTA, told VentureBeat that with 128 men and 120 women playing singles in the U.S. Open — as well as doubles, juniors and wheelchair tennis matches — the organization couldn’t cover the highlights of most of the matches throughout the tournament. 
“Depending on how many writers you have, you can only do a few matches at a time,” she said. “The other matches would just have stats and scores, but no commentary, so those stories are untold.” 
So the USTA and IBM began to think about how to scale tournament coverage by combining stats and stories with gen AI. 
“How could we use the data and technology to actually write highlights that would be reliable and accurate enough?” said Corio. 
Corio added that the USTA dreams of including AI-generated highlights in different languages in the future. “We would love to do that in Spanish, to scale more engagement,” she said. “That’s the natural next step.” 
While the USTA has been partnering with IBM on its technology efforts for decades, when it comes to today’s advanced AI applications, Corio pointed out that being able to control the data and the ecosystem is key. 
The USTA uses its own curated, official data, “but there are plenty out there who peddle in unofficial data,” she explained. “We’re not yet sure what the downstream effects of that could be, so we’re actually putting together a few different task forces across the company post-U.S. Open, to dig into how can it benefit us? How can we protect against any potential conflict?” 
A more of-the-moment concern is AI hallucinations — but in a presentation in the IBM Data Center beneath Arthur Ashe Stadium, an IBM spokesperson told VentureBeat that the company is doing human-in-the-loop quality checks on its AI Commentary. 
“We’re hoping over time we can reduce the need for human QA, but we do check each highlight clip, to make sure that the commentary is solid,” the spokesman said. 


Date: August 30, 2023 7:15 AM
Author: Carl Franzen
Link: https://venturebeat.com/ai/arize-ai-wants-to-improve-enterprise-llms-with-prompt-playground-new-data-analysis-tools/
Title: Arize AI wants to improve enterprise LLMs with ‘Prompt Playground,’ new data analysis tools
Content: We all know enterprises are racing at varying speeds to analyze and reap the benefits of generative AI — ideally in a smart, secure and cost-effective way. Survey after survey over the last year has shown this to be true. 
But once an organization identifies a large language model (LLM) or several that it wishes to use, the hard work is far from over. In fact, deploying the LLM in a way that benefits an organization requires understanding the best prompts employees or customers can use to generate helpful results — otherwise it’s pretty much worthless — as well as what data to include in those prompts from the organization or user.
“You can’t just take a Twitter demo [of an LLM] and put it into the real world,” Aparna Dhinakaran, cofounder and chief product officer of Arize AI, said in an exclusive video interview with VentureBeat. “It’s actually going to fail. And so how do you know where it fails? And how do you know what to improve? That’s what we focus on.”
Three-year-old business-to-business (B2) machine learning (ML) software provider Arize AI would know, as it has since day one been focused on making AI more observable (less technical and more understandable) to organizations. 
Today, the VB Transform award-winning company announced at Google’s Cloud Next 23 conference industry-first capabilities for optimizing the performance of LLMs deployed by enterprises, including a new “Prompt Playground” for selecting between and iterating on stored prompts designed for enterprises, and a new retrieval augmented generation (RAG) workflow to help organizations understand what data of theirs would be helpful to include in an LLMs responses. 
Almost a year ago, Arize debuted its initial platform in the Google Cloud Marketplace. Now it is augmenting its presence there with these powerful new features for its enterprise customers.
Arize’s new prompt engineering workflows, including Prompt Playground, enable teams to uncover poorly performing prompt templates, iterate on them in real time and verify improved LLM outputs before deployment. 
Prompt analysis is an important but often overlooked part of troubleshooting an LLM’s performance, which can simply be boosted by testing different prompt templates or iterating on one for better responses.
With these new workflows, teams can easily:
As Dhinakaran explained, prompt engineering is absolutely key to staying competitive with LLMs in the market today. The company’s new prompt analysis and iteration workflows help teams ensure their prompts cover necessary use cases and potential edge scenarios that may come up with real users.
“You’ve got to make sure that the prompt you’re putting into your model is pretty damn good to stay competitive,” said Dhinakaran. “What we launched helps teams engineer better prompts for better performance. That’s as simple as it is: We help you focus on making sure that that prompt is performant and covers all of these cases that you need it to handle.”
For example, prompts for an education LLM chatbot need to ensure no inappropriate responses, while customer service prompts should cover potential edge cases and nuances around services offered or not offered.
Arize is also providing the industry’s first insights into the private or contextual data that influences LLM outputs — what Dhinakaran called the “secret sauce” companies provide. The company uniquely analyzes embeddings to evaluate the relevance of private data fused into prompts.
“What we rolled out is a way for AI teams to now monitor, look at their prompts, make it better and then specifically understand the private data that’s now being put into those those prompts, because the private data part makes sense,” Dhinakaran said.
Dhinakaran told VentureBeat that enterprises can deploy its solutions on premises for security reasons, and that they are SOC-2 compliant. 
These new capabilities enable examination of whether the right context is present in prompts to handle real user queries. Teams can identify areas where they may need to add more content around common questions lacking coverage in the current knowledge base.
“No one else out there is really focusing on troubleshooting this private data, which is really like the secret sauce that companies have to influence the prompt,” Dhinakaran noted.
Arize also launched complementary workflows using search and retrieval to help teams troubleshoot issues stemming from the retrieval component of RAG models.
These workflows will empower teams to pinpoint where they may need to add additional context into their knowledge base, identify cases where retrieval failed to surface the most relevant information, and ultimately understand why their LLM may have hallucinated or generated suboptimal responses.
Dhinakaran gave an example of how Arize looks at query and knowledge base embeddings to uncover irrelevant retrieved documents that may have led to a faulty response.
“You can click on, let’s say, a user question in our product, and it’ll show you all of the relevant documents that it could have pulled, and which one it did finally pull to actually use in the response,” Dhinakaran explained. Then “you can see where the model may have hallucinated or provided suboptimal responses based on deficiencies in the knowledge base.”
This end-to-end observability and troubleshooting of prompts, private data and retrieval is designed to help teams optimize LLMs responsibly after initial deployment, when models invariably struggle to handle real-world variability.
Dhinakaran summarized Arize’s focus: “We’re not just a day one solution; we help you actually ongoing get it to work.”
The company aims to provide the monitoring and debugging capabilities organizations are missing, so they can continuously improve their LLMs post-deployment. This allows them to move past theoretical value to real-world impact across industries.


Date: August 30, 2023 7:01 AM
Author: Shubham Sharma
Link: https://venturebeat.com/ai/context-raises-3-5m-to-elevate-llm-apps-with-detailed-analytics/
Title: Context raises $3.5M to elevate LLM apps with detailed analytics
Content: London-based Context, a startup providing enterprises with detailed analytics to build better large language model (LLM)-powered applications, today said it has raised $3.5 million in funding from Google Ventures, Tomasz Tunguz from Theory Ventures and other sources. 
Context AI said it will use the capital to grow its engineering teams and build out its platform to better serve customers.
The investment comes at a time when global companies are bullish on AI and racing to implement LLMs into their internal workflows and consumer-facing applications. According to estimates from McKinsey, with this pace, generative AI technologies could add up to $4.4 trillion annually to the global economy.
While LLMs are all the rage, building applications using them isn’t exactly a cakewalk. You have to track a model’s performance, how the application is being used, and most importantly, whether it is providing the right answers to users or not — accurate, unbiased and grounded in reality. Without these insights, the whole effort is just like flying blind with no direction to make the product better.
Henry Scott-Green, who previously worked as a product manager at Google, saw similar challenges earlier this year when working on a side project that tapped LLMs to let users chat with websites. 
“We talked to many product developers in the AI space and discovered that this lack of user understanding was a shared, critical challenge facing the community,” Green told VentureBeat. “Once we identified and validated the problem, we started working on a prototype [analytics] solution. That was when we decided to build Context.”
Today, Context is a full-fledged product analytics platform for LLM-powered applications. The offering provides high-level insights detailing how users are engaging with an app and how the product is performing in return. 
This not only covers basic metrics like the volume of conversations on the application, top subjects being discussed, commonly used languages and user satisfaction ratings, but more specific tasks such as tracking specific topics (including risky ones) and transcribing entire conversations to help teams see how the application is responding in different scenarios.
“We ingest message transcripts from our customers via API, and we have SDKs and a LangChain plugin that make this process [take] less than 30 minutes of work,” Green explained. “We then run machine learning workflows over the ingested transcripts to understand the end user needs and the product performance. Specifically, this means assigning topics to the ingested conversations, automatically grouping them with similar conversations, and reporting the satisfaction of users with conversations about each topic.”
Ultimately, using the insights from the platform, teams can flag problem areas in their LLM products and work towards addressing them and delivering an improved offering to meet user needs.
Context claims to have garnered multiple paying customers since its founding four months ago, including Cognosys, Juicebox and ChartGPT, as well as several large enterprises. Citing non-disclosure agreements, Green did not share further details.
With this round, the company plans to build on its effort by hiring a technical founding team, which will allow Green and his team to accelerate their development and build an even better product. 
“The product itself has a few planned focus areas: to build higher-quality ML systems that deliver deeper insights; to improve the user experience; and to develop alternate deployment models, where our customers can deploy our software directly in their cloud,” the CEO said.
“At this stage, our goal is to continue growing our customer base while delivering value to the businesses using our product. And we’re seeing success,” he added.
As the demand for LLM-based applications grows, the number of solutions for tracking their performance is also expected to rise. 
Observability player Arize has already launched a solution called Phoenix, which visualizes complex LLM decision-making and flags when and where models fail, go wrong, give poor responses or incorrectly generalize. Datadog is going in the same direction and has started providing model monitoring capabilities that can analyze the behavior of a model and detect instances of hallucinations and drift based on data characteristics such as prompt and response lengths, API latencies and token counts.
Green, however, emphasized that Context provides more insights than these offerings, which just flag the problem areas, and is more like web product analytics companies such as Amplitude and Mixpanel.
The funding round also saw participation from 20SALES and multiple VCs and tech industry luminaries, including 20VC’s Harry Stebbings, Snyk founder Guy Podjarny, Synthesia founders Victor Riparbelli and Steffen Tjerrild, Google DeepMind’s Mehdi Ghissassi, Nested founder Matt Robinson, Deepset founder Milos Rusic and Sean Mullaney from Algolia.


Date: August 30, 2023 6:00 AM
Author: Sean Michael Kerner
Link: https://venturebeat.com/ai/couchbase-aims-to-boost-developer-database-productivity-with-capella-iq-ai-tool/
Title: Couchbase aims to boost developer database productivity with Capella IQ AI tool
Content: Database vendor Couchbase today announced the launch of Capella IQ, a new AI-powered tool aimed at enhancing developer productivity when building applications on the Couchbase Capella database-as-a-service (DBaaS) cloud platform.
Couchbase was originally developed as an open-source NoSQL database technology and has grown in recent years to add capabilities that are commonly found in relational database technologies. In 2021, Couchbase, Inc., went public on the NASDAQ and now trades under the symbol BASE. That same year, the company first released its Capella DBaaS platform, which has continued to expand with support on multiple cloud platforms including Google Cloud.
The goal with Couchbase Capella is to provide a database platform for developers that is easier to use and manage. The launch of Capella IQ brings the power of generative AI to the platform to help developers write database code.
“Think of it [Capella IQ] as a copilot for developers, using LLM [large language model] foundation models to really enhance the productivity of developers,” Matt Cain, Couchbase president and CEO, told VentureBeat.
The new tool fits into Couchbase’s overall four-pronged AI strategy, according to Cain.
Couchbase’s AI strategy includes driving developer productivity, optimizing AI processing, enabling AI-driven applications anywhere, and complementing its technology with partnerships. Cain said that Capella IQ addresses the first pillar around developer productivity.
Cain explained that Capella IQ leverages gen AI models to automate tedious development tasks like generating code snippets, sample datasets and unit tests. He noted that developers can access these capabilities directly within the Capella developer workbench through a conversational interface that is designed to have a low barrier to entry.
“It’s completely aligned with how we’re thinking about our AI strategy, but really focused on helping developers be as productive as possible with Capella and enabling next-generation applications,” said Cain.
With Capella IQ, Couchbase is using OpenAI’s models to help with code generation. Cain noted that Couchbase may choose to also work with other LLM providers in the future. 
He also emphasized that there are several capabilities in the Capella platform that help to enable the IQ feature beyond just connecting out to an LLM provider. One such feature is the Index Advisor, an existing built-in capability that is able to analyze data queries and provide users with optimization recommendations to improve database index to accelerate response time.
While Couchbase is now jumping into the gen AI era with Capella IQ, it is still missing at least one critical element needed to help power AI applications: vector embedding support.
This is an increasingly common feature on existing database platforms, with multiple vendors including DataStax, Google with AlloyDB and MongoDB announcing support in 2023. 
Support for vector embedding is very much on Cain’s mind, and it is part of his company’s roadmap for inclusion in the near future. He explained that vector embedding support will be enabled in the future as an extension to the platform.
“Our underlying system is a multi-model caching JSON document database that performs both operational and analytical capabilities, and then we have architecturally enabled services like full text search,” he said. “With a similar architecture we can approach vector and make that a seamless aspect of our platform, where developers can not only take advantage of those capabilities, but do more with less, with a true enterprise platform.”


Date: August 30, 2023 6:00 AM
Author: Michael Nuñez
Link: https://venturebeat.com/data-infrastructure/databricks-bets-big-on-activating-data-for-marketers-with-hightouch-investment/
Title: Databricks bets big on activating data for marketers with Hightouch investment
Content: We’re living in a time where just about every company is overflowing with data, but when it comes to getting meaningful insights from it — that’s where organizations are often coming up short. 
Enter Databricks, a San Francisco-based heavyweight in the data and AI space. They’re the team behind the lakehouse concept and they’re on a mission: To monetize data by making insights more accessible. 
Today, Databricks has announced it’s putting its money where its mouth is. The company’s venture capital arm, Databricks Ventures, revealed in an exclusive VentureBeat report that it has made a strategic investment in promising San Francisco-based startup Hightouch, a software platform that helps businesses synchronize and activate all of their customer data.
The strategic investment is a part of a recent $38 million funding announcement aimed squarely at a core challenge that has troubled businesses: How to effectively harness the power of their vast data resources. The combined offering of Databricks’ robust data platform and Hightouch’s efficient data extraction capabilities is set to provide businesses with the tools needed to fully exploit their data, particularly in the field of marketing.
Steve Sobel, who leads communications, media and entertainment at Databricks, explained the essence of the partnership in an interview with VentureBeat. “What we’re delivering with Hightouch is all around making data usable,” he said. “It’s about helping organizations through their enterprise data challenges and strategy.” 
Sobel’s comments underscore Databricks’ game plan to position itself as a vertical player in the sector, focusing on speaking the language of the customer and the industry. “We live in an era where every industry is moving toward direct-to-consumer,” he said. “Optimizing marketing and delivering a superior, personalized experience across any channel, anywhere, anytime is essential.”
Hightouch cofounder and co-CEO Kashish Gupta offered a complementary perspective, explaining the “match booster” concept, a feature built into Hightouch that harmonizes first-party data with third-party datasets. “This approach allows businesses to reach their customers across a multitude of different channels,” said Gupta.
He further explained the convergence of data and marketing strategies, saying: “A data strategy and marketing strategy have actually become one in the current business landscape. Personalization based on factors such as zip code, last login time and myriad other activities now decisively influences these strategies.”
Reflecting on the surge in digital data, Gupta pointed out: “Companies have more data than ever due to digital transformation. Extracting value out of that data by optimizing marketing using the data is truly where this partner strategy delivers.”
(Editor note: To help enterprise executives learn more about how to manage their data to prepare for generative AI applications, VentureBeat is hosting its Data Summit 2023 on November 15. The event will feature networking opportunities and sessions on topics such as data lakes, data fabrics, data governance and data ethics. Pre-registration for a 50% discount is open now.)
Founded in 2020 by Gupta, a former Bessemer Venture Partners investor, and former Segment engineers Tejas Manohar and Josh Curl, Hightouch helps customers leverage their data warehouse as a single source of truth for their business teams.
By using Hightouch’s reverse ETL (extract, transform and load) technology, customers can access, explore and sync data from their data warehouse to more than 200 SaaS tools such as Salesforce, HubSpot, Facebook and TikTok, without relying on engineering resources.
Hightouch claims to have hundreds of customers already across various verticals and industries, including the NBA, Grammarly, PetSmart, Imperfect Foods and Betterment. For context on its rapid growth, the company says it increased its revenue three times in the first half of 2022 alone and has grown its team from 40 employees in 2021 to 93 this year.
The new funding will be used to invest in product development, especially in the areas of customer understanding and out-of-the-box machine learning (ML) models, according to Gupta. Hightouch also plans to expand its go-to-market activities and hire more talent across different functions.
Gupta said that the company’s rapid growth has been driven by customer demand and product market fit. He said that Hightouch’s vision is to democratize data for all business teams by enabling them to use data from their data warehouse without code or engineers.
Hightouch is one of the pioneers of the reverse ETL category, which is rapidly growing as more businesses adopt data warehouses as their source of truth. According to Gartner, the number of enterprises implementing AI grew by 270% in the past four years and tripled in the past year, driving an increase in streaming data and analytics infrastructures with it. This creates a huge opportunity for platforms like Hightouch that can help businesses activate their data and apply AI to it.

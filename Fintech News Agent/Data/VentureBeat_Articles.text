Total number of articles: 40

Date: August 31, 2023 3:24 PM
Author: Carl Franzen
Link: https://venturebeat.com/ai/openai-wants-teachers-to-use-chatgpt-for-education/
Title: OpenAI wants teachers to use ChatGPT for education
Content: It’s not only programming, journalism and content moderation that OpenAI is seeking to revolutionize with the use of its landmark large language models (LLMs) GPT-3, GPT-3.5 and GPT-4.
Today, the company published a new blog post titled “Teaching with AI” that outlines examples of six educators from various countries, mostly at the university level though one teaches high school, using ChatGPT in their classrooms. 
“We’re sharing a few stories of how educators are using ChatGPT to accelerate student learning and some prompts to help educators get started with the tool,” the company writes. 
The examples range from one educator using ChatGPT as a kind of educational role player, taking on the part of a debate rival or recruiter and engaging students in a dialog; to another teacher using ChatGPT for translation assistance for English-as-a-second-language students; to yet another having their students fact-check the information it generates.
The company also includes sample prompts developed by AI influencer and University of Pennsylvania Wharton School professor Ethan Mollick and his wife and fellow professor Lilach Mollick that assist teachers with lesson planning and even turn the default ChatGPT into an “AI tutor” for students. 
Asked by this VentureBeat author on X (formerly Twitter) if OpenAI paid Ethan Mollick for use of his and his wife’s prompts, he responded in the negative: “No. I have never taken any money or compensation in any way from OpenAI, including token credits,” adding “In this case, they used prompts and material we have already published.”
Of course, the issue of generative AI in the classroom — like with many topics related to the technology — has been fraught with controversy, especially with regards to students using it as a means of cutting corners or avoiding doing their own coursework, such as writing essays. 
In fact, several schools, districts, and departments of education around the globe have already banned ChatGPT and added it to their internet network blocklists, although the New York City Public School  system did an about-face in May and moved to allow teachers to use ChatGPT as they see fit. 
OpenAI made headlines earlier this year by releasing an “AI Text Classifier” that was designed to allow anyone, including educators, to copy and paste in text and determine whether or not it was written by AI, but then ended up discontinuing it last month due to its “low rate of accuracy.”  
Today, OpenAI elaborated on the issues with the Text Classifier in a new Educator FAQ (frequently asked questions), which is far more robust and arguably even more helpful for schools than its promotional blog post.
Answering the question of “How can educators respond to students presenting AI-generated content as their own?,” OpenAI answers to say: “While some (including OpenAI) have released tools that purport to detect AI-generated content, none of these have proven to reliably distinguish between AI-generated and human-generated content,” and “When we at OpenAI tried to train an AI-generated content detector, we found that it labeled human-written text like Shakespeare and the Declaration of Independence as AI-generated.”
In addition, OpenAI admits: “There were also indications that it could disproportionately impact students who had learned or were learning English as a second language and students whose writing was particularly formulaic or concise.”
Plus, as the company points out, “even if these tools could accurately identify AI-generated content (which they cannot yet), students can make small edits to evade detection.”
Instead, OpenAI notes that some teachers have begun asking students to show their conversations with ChatGPT as a form of displaying their critical thinking skills. 
Furthermore, while OpenAI says that there is research supporting the fact that “ChatGPT can be a helpful tool, alongside teachers, for providing students with feedback,” it does not link to this specific research, and says “it is inadvisable and against our Usage Policies to rely on models for assessment decision purposes without a ‘human in the loop.'”
In other words — the idea of a teacher handing over most of their duties to ChatGPT is not in the cards yet, or likely the foreseeable future, and same with students and their coursework. 
Still, the company clearly wants to promote the idea that ChatGPT can be a useful new tool for both sides of the educational equation, teachers and students alike, joining the familiar classroom sights of pencils, notebooks, computers, and globes. 


Date: August 31, 2023 10:03 AM
Author: Louis Columbus
Link: https://venturebeat.com/security/5-ways-cisos-can-prepare-for-generative-ai-security-challenges-and-opportunities/
Title: 5 ways CISOs can prepare for generative AI’s security challenges and opportunities
Content: With generative AI tools like ChatGPT proliferating across enterprises, CISOs have to strike a very difficult balance: Performance gains versus unknown risks. Gen AI is delivering greater precision to cybersecurity but also being weaponized into new attack tools such as FraudGPT that advertise their ease of use for the next generation of attackers.
Solving the question of performance versus risk is proving a growth catalyst for cybersecurity spending. The market value of gen AI-based cybersecurity platforms, systems and solutions is expected to rise to $11.2 billion in 2032 from $1.6 billion in 2022. Canalys expects generative AI to support more than 70% of businesses’ cybersecurity operations within five years.
Gen AI attack strategies are focused on getting control of identities first. According to Gartner, human error in managing access privileges and identities caused 75% of security failures, up from 50% two years ago. Using gen AI to force human errors is one of the goals of attackers.
VentureBeat interviewed Michael Sentonas, president of CrowdStrike, to gain insights into how the cybersecurity leader is helping its customers take on the challenges of new, more lethal attacks that defy existing detection and response technologies.
Sentonas said that “the hacking [demo] session that [we] did at RSA [2023] was to show some of the challenges with identity and the complexity. The reason why we connected the endpoint with identity and the data that the user is accessing is because it’s a critical problem. And if you can solve that, you can solve a big part of the cyber problem that an organization has.” 
Leading cybersecurity vendors are up for the challenge of fast-tracking gen AI apps through DevOps to beta and doubling down on their many models in development.
During Palo Alto Networks‘ most recent earnings call, chairman and CEO Nikesh Arora emphasized the intensity the company is putting into gen AI, saying, “we’re doubling down, we’re quadrupling down to make sure that precision AI is deployed across every product. And we open up the floodgates of collecting good data with our customers for them to give them better security because we think that is the way we’re going to solve this problem to get real-time security.” 
For CISOs and their teams to win the war against AI attacks and threats, gen AI-based apps, tools and platforms must become part of their arsenals. Attackers are out-innovating the most adaptive enterprises, sharpening their tradecraft to penetrate the weakest attack vectors. What’s needed is greater cyber-resilience and self-healing endpoints.
Absolute Software’s 2023 Resilience Index reveals how challenging it is to excel at the comply-to-connect trend. Balancing security and cyber-resilience is the goal, and the Index provides a useful roadmap. Cyber-resilience, like zero trust, is an ongoing framework that adapts to an organization’s changing needs.
Every CEO and CISO VentureBeat interviewed at RSAC 2023 said employee- and company-owned endpoint devices are the fastest-moving, hardest-to-protect threat surfaces. With the rising risk of gen AI-based attacks, resilient, self-healing endpoints that can regenerate operating systems and configurations are the future of endpoint security.
Central to being prepared for gen AI-based attacks is to create muscle memory of every breach or intrusion attempt at scale, using AI and machine learning (ML) algorithms that learn from every intrusion attempt. Here are the five ways CISOs and their teams are preparing for gen AI-based attacks.
Despite the security risk of confidential data being leaked into LLMs, organizations are intrigued by boosting productivity with gen AI and ChatGPT. VentureBeat’s interviews with CISOs reveal that these professionals are split on defining AI governance. For any solution to this problem to work, it must secure access at the browser, app and API levels to be effective.
Several startups and larger cybersecurity vendors are working on solutions in this area. Nightfall AI’s recent announcement of an innovative security protocol is noteworthy. The company’s customizable data rules and remediation insights help users self-correct. The platform gives CISOs visibility and control so they can use AI while ensuring data security. 
SOC teams are seeing more sophisticated social engineering, phishing, malware and business email compromise (BEC) attacks that they attribute to gen AI. While attacks on LLMs and AI apps are nascent today, CISOs are already doubling down on zero trust to reduce these risks.
That includes continuously monitoring and analyzing gen AI traffic patterns to detect anomalies that could indicate emerging attacks and regularly testing and red-teaming systems in development to uncover potential vulnerabilities. While zero trust can’t eliminate all risks, it can help make organizations more resilient against gen AI threats.
Gen AI’s potential to improve microsegmentation, a cornerstone of zero trust, is already happening thanks to startups’ ingenuity. Nearly every microsegmentation provider is fast-tracking DevOps efforts. 
Leading vendors with deep AI and ML expertise include Akamai, Airgap Networks, AlgoSec, Cisco, ColorTokens, Elisity, Fortinet, Illumio, Microsoft Azure, Onclave Networks, Palo Alto Networks, VMware, Zero Networks and Zscaler.
One of the most innovative startups in microsegmentation is Airgap Networks, named one of the 20 best zero-trust startups of 2023. Airgap’s approach to agentless microsegmentation reduces the attack surface of every network endpoint, and it is possible to segment every endpoint across an enterprise while integrating the solution into an existing network with no device changes, downtime or hardware upgrades.
Airgap Networks also introduced its Zero Trust Firewall (ZTFW) with ThreatGPT, which uses graph databases and GPT-3 models to help SecOps teams gain new threat insights. The GPT-3 models analyze natural language queries and identify security threats, while graph databases provide contextual intelligence on endpoint traffic relationships.
“With highly accurate asset discovery, agentless microsegmentation and secure access, Airgap offers a wealth of intelligence to combat evolving threats,” Airgap CEO Ritesh Agrawal told VentureBeat. “What customers need now is an easy way to harness that power without any programming. And that’s the beauty of ThreatGPT — the sheer data-mining intelligence of AI coupled with an easy, natural language interface. It’s a game-changer for security teams.”
Security is often tested right before deployment, at the end of the software development lifecycle (SDLC). In an era of emerging gen AI threats, security must be pervasive throughout the SDLC, with continuous testing and verification. API security must also be a priority, and API testing and security monitoring should be automated in all DevOps pipelines.
While not foolproof against new gen AI threats, these practices significantly raise the barrier and enable quick threat detection. Integrating security across the SDLC and improving API defenses will help enterprises thwart AI-powered threats.
A zero-trust approach to every interaction with AI tools, apps and platforms and the endpoints they rely on is a must-have in any CISO’s playbook. Continuous monitoring and dynamic access controls must be in place to provide the granular visibility needed to enforce least privilege access and always-on verification of users, devices and the data they’re using, both at rest and in transit. 
CISOs are most worried about how gen AI will bring new attack vectors they’re unprepared to protect against. For enterprises LLMs, protecting against query attacks, prompt injections, model manipulation and data poisoning are high priorities.
CISOs, CIOs and their teams are facing a challenging problem today. Do gen AI tools like ChatGPT get free reign in their organizations to deliver greater productivity, or are they bridled in and controlled, and if so, by how much? Samsung’s failure to protect IP is still fresh in the minds of many board members.
One thing everyone agrees on, from the board level to SOC teams, is that gen AI-based attacks are increasing. Yet no board wants to jump into capital expense budgeting, especially given inflation and rising interest rates. The answer many are arriving at is accelerating zero-trust initiatives. While an effective zero-trust framework isn’t stopping gen AI attacks completely, it can help reduce their blast radius and establish a first line of defense in protecting identities and privileged access credentials.


Date: August 31, 2023 9:00 AM
Author: Michael Nuñez
Link: https://venturebeat.com/ai/pirros-a-startup-that-applies-ai-to-streamline-drawing-sets-for-buildings-and-infrastructure-lands-2-million-seed-round/
Title: Pirros, a startup that applies AI to streamline drawing sets for buildings and infrastructure, lands $2 million seed round
Content: Pirros, a technology platform that helps architecture and engineering firms manage their drawing sets more efficiently, announced today that it has raised a $2 million seed round from a group of investors and advisors with deep industry connections.
Notable contributors to the funding round include angel investors Carl Bass, former chief executive of Autodesk; Joseph Walla of HelloSign; and Ryan Sutton-Gee of the construction software firm PlanGrid. Venture capital firms including YCombinator, FundersClub and Twenty Two Ventures also participated in the seed round.
Pirros is a tool created to streamline detail management for architecture and engineering firms. It automatically categorizes and catalogs the primary deliverable of design professionals: The many thousands of drawing sets that firms create each year for buildings and infrastructure.
Most firms currently face an extremely inefficient paradigm of creating, using and effectively discarding design details — not because they are no longer useful, but because they are stored on on-premises servers with little to no ability to rediscover and reuse them. This means architects and engineers have to re-create drawings over and over for each project, which has the further effect of stripping them of the quality control process they went through in the course of initial creation.
With Pirros, architects and engineers can spend more time actually designing buildings instead of documenting them. This is achieved by automatic information aggregation and storage, so that all of a company’s outputs are stored and managed in a centralized, searchable platform for easy future re-use.
Pirros CEO and cofounder Ari Baranian said in an interview with VentureBeat: “Every company has tried to build out a small catalog, so about a couple of hundred details, and these will be the most common details that they’ve used … There’s just never been the tools to expand the catalog beyond 100, 200, or even 500 details.”
He further emphasized: “Now, our average company has over 10,000 [searchable] details on the platform. So with that ability, any new architect, any new engineer that joins the firm, quickly gets up to speed on the different standards of that office.”
The proof is in the rapid adoption of the tool among some of the industry’s biggest players. The software is already being used by more than 30 firms including large architecture companies like KPFF Engineers and RAMSA.
Pirros leverages the metadata from the building information models (BIMs) that firms use to create their drawing sets. It extracts and indexes this data into a searchable and reusable catalog of 2D assets. It also uses clustering algorithms to group similar details together so that users can see different versions of the same condition and choose the best one.
The platform integrates seamlessly with any firm’s existing tools or workflows. The onboarding process is simple: Firms just need to identify the models they want to include in their Pirros catalog, and Pirros does the rest of the work with its integration pipeline.
The company has received positive feedback from its customers, especially from the youngest architects and engineers who use its platform. 
“Seeing the amount of traction that we’ve gotten with the youngest architects and engineers was surprising to us, but also super motivating to see that we’re actually making an impact there.” said Baranian.
Pirros plans to use the $2 million seed funding to grow its team, improve its product and expand its market. One of the upcoming features that Baranian is excited about is using AI to identify the best versions of every detail automatically and provide users suggestions and recommendations.
Pirros is a pioneer in the field of architectural detail management, which has been largely overlooked by other technology platforms. By solving this specific problem, Pirros aims to transform the way buildings are designed and documented. 
As Baranian put it: “We built our product exactly as we would have wanted to use it.”


Date: August 31, 2023 8:59 AM
Author: Michael Nuñez
Link: https://venturebeat.com/enterprise-analytics/meet-superframe-the-ai-startup-that-wants-to-be-your-copilot-for-revenue-operations/
Title: Meet Superframe, the AI startup that wants to be your copilot for revenue operations
Content: Superframe, an AI-powered software company aiming to help businesses optimize their go-to-market technology stacks, announced today that it has raised $5 million in seed funding from more than 40 angel investors, including data and AI experts, Salesforce consultants and general operating experts.
The round comes on the heels of Superframe’s launch of its first official product, an AI assistant for managing complex Salesforce implementations. The startup says its technology will save companies time and money by making Salesforce configuration changes fast, safe, reliable and easy.
Derek Steer, cofounder and CEO of Superframe, said that accuracy is going to be the company’s number one differentiator in the AI market. 
“We want to fight the consumer frustration with a lack of accuracy. We want to build trust with our customers by giving them something they can’t get somewhere else,” he told VentureBeat in a recent interview.
Steer is no stranger to the data and AI world, as he previously sold his last company Mode, a business intelligence platform, to Thoughtspot for $200 million.
In the long term, Superframe aims to solve the pain points that many companies face when they implement go-to-market tools, such as Salesforce, Marketo and HubSpot. These tools are often complex, rigid and hard to configure, resulting in wasted time, money and resources. Superframe uses the latest language models from OpenAI (ChatGPT) to provide instant and accurate answers to questions about the current state of the system, and to propose and implement configuration changes based on the users’ description of what they want to do.
Steer also said that Superframe will not replace humans, but rather enable them to rely on their expertise and clear their backlogs. 
“We want to help more people build more expertise,” he said. “And that’s something that customers are still going to want to rely on.” 
He added that Superframe will help customers map out their business processes and configure their systems without being held back by the complexity and rigidity of the tools.
Superframe is currently in beta testing with a select group of customers, and plans to launch publicly in early 2024. The first phase of Superframe, which is answering questions about the system, will be free for users. The company plans to use the seed funding for product development and hiring more engineers. The startup currently has four employees.
Superframe is one of the many startups that are using AI to simplify and optimize business operations. According to a recent Gartner report, the market for AI software will reach almost $134.8 billion by 2025. The report also cites the increasing adoption of cloud-based services and applications as one of the key drivers for the AI market growth.
Superframe’s vision is to become the copilot for revenue operations teams, and to help them think more creatively about their go-to-market strategies. 
“We believe that humans are capable of a lot,” said Steer. “And we are in a lot of cases bottlenecked by the tools that we use. We want to remove those bottlenecks in order to give people a greater ability to employ their creativity.”


Date: August 31, 2023 7:25 AM
Author: Press Release
Link: https://venturebeat.com/business/daversa-partners-ranks-among-top-20-best-medium-workplaces-2023-according-to-fortune-media-and-great-place-to-work/
Title: Daversa Partners Ranks Among Top 20 Best Medium Workplaces 2023, According to Fortune Media and Great Place To Work®
Content: NEW YORK–(BUSINESS WIRE)–August 31, 2023–
Great Place To Work® and Fortune magazine have selected Daversa Partners as one of 2023’s 100 Best Medium Workplaces. Coming in at No. 19, this means that Daversa Partners has earned a spot as one of the best companies to work for in the country.
This press release features multimedia. View the full release here: https://www.businesswire.com/news/home/20230831931182/en/
To determine the Best Medium Workplaces list, Great Place To Work analyzed the survey responses of over 210,000 employees from Great Place To Work Certified™ companies with 100 to 999 U.S. employees.
The Best Medium Workplaces list is highly competitive. Great Place To Work, the global authority on workplace culture, determines its lists using its proprietary For All™ methodology to evaluate and certify thousands of organizations in America’s largest ongoing annual workforce study, based on over 1.3 million survey responses and data from companies representing more than 7.5 million employees this year alone.
Survey responses reflect a comprehensive picture of the workplace experience. Honorees were selected based on their ability to offer positive outcomes for employees regardless of job role, race, gender, sexual orientation, work status, or other demographic identifier.
“This year, we celebrate 30 years of Daversa Partners,” said Paul Daversa, Founder and CEO of Daversa Partners. “Over these three decades, we have had the privilege of being a part of the dynamic evolution of the tech industry. This journey has not just been about our growth as a firm, but about the remarkable founders, funders, and operators who have undeniably shaped the ecosystem with their strategic vision. We are proud and grateful to play a role in this evolution.”
In 2022, Daversa Partners earned Great Place to Work™ Certification, with 95% of employees saying that “people care about each other here.” Daversa Partners was also awarded Best Workplaces for Women™ by Fortune and Great Place to Work® in 2022 – a testament to the firm’s commitment to the 64% of women who make up the company, with 56% at the leadership level. So far this year, Daversa Partners has secured a No.4 spot on Fortune’s 2023 Best Workplaces in New York list, was named a 2023 Best Workplace for Millennials, and recertified as a Great Place to Work™.
About Daversa Partners
For three decades, Daversa Partners has built the leading management teams across the most disruptive companies of this generation, focused on serving the global founder and funder community around the world. Having worked alongside tech’s top VC and PE firms, Daversa Partners has had the privilege to build over 10,000 consumer and enterprise companies, all of which hold a shared vision: push the throttle on innovation. The company today is an important strategic partner that moves top executives into startup and growth oriented companies.
About the Fortune Best Medium Workplaces List
Great Place To Work selected the Fortune Best Medium Workplaces List by surveying companies employing 7.5 million people in the U.S. with 1.3 million confidential responses received. Of those, more than 210,000 responses were received from employees at companies eligible for the Best Medium Workplaces list and this ranking is based on that feedback. Company scores are derived from 60 employee experience questions within the Great Place To Work Trust Index™ Survey. Read the full methodology.

View source version on businesswire.com: https://www.businesswire.com/news/home/20230831931182/en/
Nicole DaversaNicole@daversapartners.com


Date: August 31, 2023 6:53 AM
Author: Carl Franzen
Link: https://venturebeat.com/ai/ibm-and-salesforce-team-up-to-bring-ai-tools-to-their-shared-clients/
Title: IBM and Salesforce team up to bring AI tools to their shared clients
Content: Big Blue is teaming with an even Bigger Blue to deliver AI solutions to clients.
Today, IBM and Salesforce announced they are joining forces to bring Salesforce AI solutions (Sales GPT, Service GPT, Salesforce Einstein, Slack GPT and Marketing GPT) to customers who do business with both companies.
Obviously, what Salesforce brings to the table is its popular and powerful customer relationship management (CRM) software, in addition to the aforementioned AI apps and tools. 
What IBM offers through the partnership is “industry expertise and innovative delivery models” through its IBM Consulting arm of 160,000 human consultants, the company said in a press release. 
Specifically, this includes “IBM Garage … an operating model for business transformation,” which will help the combined clients get their Salesforce AI integrations up and running.
IBM notes that the shared customers may also wish to adopt its Watsonx enterprise AI platform for finding and fine-tuning enterprise grade AI models. WatsonX can further help customers find “data locked in backend systems” that they can better access and leverage through their shiny new Salesforce and open-source AI models.
Further, customers should consider using IBM’s Data Classifier, an “AI-powered application trained on industry-specific data models,” to help them map all their internal data to make it useful and accessible to the AI tools and apps, IBM says. 
“Companies are embarking on a transformative journey fueled by generative AI,” Steve Corfield, Salesforce EVP and GM of global alliances and channels said in a press release. “Salesforce partners like IBM Consulting play an important role in helping businesses use Salesforce’s AI, data and CRM technologies to connect with their customers on a new level. Bringing Salesforce and IBM innovations together will help transform the way companies deliver personalized, engaging experiences.” 
IBM is practicing what it preaches. The original Big Blue used Salesforce and its own watsonx to overhaul its customer service and sales processes — now it’s hoping to do the same for many others around the globe.


Date: August 31, 2023 5:00 AM
Author: Carl Franzen
Link: https://venturebeat.com/ai/gong-introduces-call-spotlight-a-generative-ai-summary-of-customer-calls-for-revenue-teams/
Title: Gong’s new Call Spotlight uses AI to summarize customer calls for revenue teams
Content: Gong, the nine-year-old company focused on making technology that streamlines workflows for revenue teams across sectors, made news earlier this summer by introducing new generative AI-powered features to its customer conversation analysis platform, including gen AI messaging suggestions. 
Now, it’s going a step further: The company today announced exclusively with VentureBeat that it is introducing the new feature Call Spotlight, accessible for all of its 4,000 platform customers (and counting) globally, at no extra charge.
The new AI-driven tool (powered by a mix of proprietary Gong AI models and GPT-4 in Microsoft Azure OpenAI Service) automatically transcribes and analyzes a revenue team member’s conversation with a customer over video call, audio call, mobile or desktop, even emails and text correspondence — any communications the revenue team member wants — and auto-generates a summary and key points for the revenue team to act on.
For Gong’s largely business-to-business (B2B)-focused clients, who spend lots of time prospecting customers of their own and managing customer relationships through direct correspondence, the tool is poised to offer increased productivity and efficiency.
At the same time, Gong hopes the new feature allows revenue teams and salespeople even more time to forge and maintain the unique customer relationships that are key to landing business. 
“You become more efficient” using Call Spotlight, Gong chief product officer and cofounder Eilon Reshef, said in a video call with VentureBeat. “You don’t need to review the whole text. You don’t need to listen to the whole call. You don’t need to take notes. You don’t need to do anything manually.”
Just enable Call Spotlight through Gong’s platform — there are modes that will prompt the other parties in any given call to agree to being recorded and analyzed by Gong’s AI — and it will take care of it for you.
Gong says that Call Spotlight is unmatched in its accuracy, offering sales insights that are twice as reliable as generic solutions available on the market such as other consumer large language models (LLMs), having been trained on billions of sales interactions that Gong sourced from customers.
“What’s unique about Gong is that because we train the system based on revenue conversations, we get much more accurate results,” Reshef told VentureBeat.
This includes a more accurate AI interpreter of specific company and product names — something other auto-transcription AI services often struggle to handle, in VentureBeat’s testing, defaulting to generic words instead of trademarks.
One of Call Spotlight’s standout features is its unique “Ask Anything” function — the first of its kind tailored specifically for sales. Think of it as your personal sales coach, ready to answer any question you throw at it.
Whether it’s seeking guidance on sealing a deal or understanding why a particular conversation matters to a regional account executive, Ask Anything delivers precise, context-rich advice.
For instance, after a call, a sales rep might wonder, “What can I do to up my game for closing this deal?” Ask Anything churns out actionable steps based on its deep learning of a specific customer interaction, with context pulled from Gong’s extensive sales data.
Similarly, if a manager wants to know whether competitors were name-dropped during a conversation, the tool can sift through the call details and flag any potential threats, allowing for targeted coaching strategies.
In addition to the Ask Anything feature, Call Spotlight includes:
Gong customers can also share any of these AI-generated products with their colleagues and managers as needed, and also push data to their customer relationship management (CRM) software of choice for recordkeeping — or not. It’s all up to the customer to decide what to do with their gen AI work products.
Furthermore, Gong knows that security is top-of-mind for many of its customers, and seeks to reassure them that safeguarding their data is of paramount importance while introducing all of these new gen AI features. 
“One of the critical elements for us is security,” said Reshef. “We have some of the Fortune top 50 companies as customers, and they are very concerned about security and unlikely to allow us to sell their data outside the company. So we hire Gong employees and do everything in-house.”
Gong noted that it has been recording calls since 2016, and is GDPR-compliant and has stayed up-to-date on all relevant regulations in the years since. 
By marrying highly accurate, context-specific advice with a range of other features and security, Gong hopes that Call Spotlight will be a game-changer for the revenue teams that try it out.


Date: August 30, 2023 1:21 PM
Author: Sharon Goldman
Link: https://venturebeat.com/ai/ai21-labs-raises-155m-to-accelerate-genai-for-enterprises/
Title: AI21 Labs raises $155M to accelerate generative AI for enterprises
Content: Tel Aviv, Israel-based large language model (LLM) leader AI21 Labs confirmed with VentureBeat that it has has closed $155 million in series C funding to accelerate the growth of its text-based generative AI services for enterprises. The company is now valued at $1.4 billion. 
Investors in the round include Walden Catalyst, Pitango, SCB10X, b2venture, Samsung Next and Amnon Shashua with participation from Google and Nvidia. 
Founded in 2017 by AI pioneers and technology veterans Amnon Shasuha, Yoav Shoham and Ori Goshen, AI21 Labs may have been one of the first to bring gen AI to the masses, but it has also spent the past year chasing LLM rivals like OpenAI to commercial applications. 
After a $64 million series B round last year, Shoham, an emeritus professor of AI at Stanford University, told VentureBeat that he recognized that the funding landscape was tightening and more LLMs and multimodal models were being launched every day. 
He said the company was “very aware of the environment and not complacent in any way.” 
AI21’s proprietary Jurassic-2 foundation models are considered some of the world’s largest and most sophisticated LLMs. Jurassic-2 powers AI21 Studio, a developer platform for building custom text-based business applications off of AI21’s language models; and Wordtune, a multilingual reading and writing AI assistant for professionals and consumers.
AI21 chairman Shashua said in a press release: “AI21 Labs is a pure play in AI as it develops and owns foundation models which are served as a platform to developers and enterprises, while developing derivatives such as Wordtune directly to end users. The current round fuels the growth of the company to reach its goal of developing the next level of AI with the capabilities of reasoning across many domains. We believe that the impact of AI21 Labs growth plans would be of a global scale and quite soon.”
Jensen Huang, founder and CEO of Nvidia, also shouted out AI21’s work in the press release: “Generative AI is driving a new era of computing across every industry,” he said. “The innovative work by the AI21 Labs team will help enterprises accelerate productivity and efficiency with generative AI-based systems that are accurate, trustworthy and reliable.”
AI21 has recently collaborated with customers in diverse sectors, including Carrefour, Clarivate, eBay, Guesty, Monday.com and Ubisoft. The company was also named on the first ever CB Insights GenAI 50.


Date: August 30, 2023 9:39 AM
Author: Carl Franzen
Link: https://venturebeat.com/ai/sprig-uses-ai-to-transform-product-surveys-into-conversational-data/
Title: Sprig uses AI to transform product surveys into conversational data
Content: Sprig, a five-year-old startup focused on creating smart, contextually aware in-app surveys for enterprises, earned a big vote of confidence last year, securing $30 million in funding from prominent venture capital firms including a16z and Accel.
Today, the company is announcing where some of those funds went: A new feature Sprig calls AI Analysis for Surveys, which, as the name suggests, uses generative AI large language models (LLMs) to intelligently comb through survey data and provide instantaneous insights to the company that conducted the survey.
To put it more bluntly: Sprig’s AI Analysis for Surveys transforms survey data into a conversational AI product. 
With it, you as the survey owner can ask your survey results any conceivable question, and the AI will sort through them and attempt to respond with the most appropriate data, insights, takeaways or suggestions — and this includes qualitative survey data like open-ended text entries, not just multiple choice or quantitative answers.
“You can ask Sprig AI to answer any custom questions about your survey data, and it will analyze responses across all of your survey questions to find the answer,” Sprig CEO Ryan Glasgow, wrote in a blog post about the news. 
The company also announced an expanded free plan, and new large enterprise customers including PayPal, Figma, Ramp, Peloton and Mixpanel.
“World-class product teams continue to choose our platform because they value their user experience and have found Sprig to be a mission-critical platform to differentiate their products in today’s competitive environment,” wrote Glasgow.
Sprig first made waves in 2020 with the launch of its in-product survey platform and Open-Text AI Analysis feature, which automatically groups open-ended survey responses (those questions that ask you to write about your experience in a text box) into themes. 
The feature was adopted quickly by leading enterprises including Dropbox, Loom, Coinbase, Robinhood and Square. To date, Sprig has analyzed feedback from more than 6 billion product visitors across hundreds of high-growth technology companies.
With the new AI Analysis for Surveys, Sprig takes it to the next level by analyzing entire survey datasets. Product teams can now:
Glasgow wrote in an email to VentureBeat: “AI Analysis for Surveys solves a common pain point for product teams looking to deeply understand and optimize a specific part of their product experience, from understanding why users are churning out of a product to figuring out how to boost the conversion funnel.”
In addition to rolling out AI Analysis for Surveys, Sprig is expanding its free plan to make its AI-powered product insights accessible to more teams.
The free plan now includes in-product surveys, session replays and Open-Text AI Analysis. Teams of all sizes can immediately start using Sprig and the new AI Analysis for Surveys feature set.


Date: August 30, 2023 8:25 AM
Author: Press Release
Link: https://venturebeat.com/business/fianu-labs-secures-2-million-in-seed-funding-from-datatribe-to-automate-governance-of-software-development/
Title: Fianu Labs Secures $2 Million in Seed Funding from DataTribe to Automate Governance of Software Development
Content: 
Companies will soon be Liable for the Safety of Their Software for Consumers, Companies, and Governments.

FULTON, Md.–(BUSINESS WIRE)–August 30, 2023–
Fianu Labs, the software governance automation solution, today secured a $2 million seed investment from DataTribe, a global cyber foundry that invests in and co-builds next-generation cybersecurity and data science companies.
For businesses in regulated industries, the weight of software regulation is onerous. Each software release requires hundreds of hours of manual evidence gathering, leading to longer release cycles that stifle innovation and cost tens of millions of dollars in lost productivity every year. There looks to be no relief in sight as regulators have signaled a renewed focus on software development practices in response to recent attacks on the software supply chain. Businesses are in dire need of a solution that streamlines their compliance and shortens release cycles.
Fianu Labs is pioneering the path for businesses to succeed in the era of software regulation with an intuitive approach to governance that instills confidence in each release. Fianu captures and maintains a continuous audit trail that tells the story of each code change, from commit to release and automates a once chaotic manual process with speed and clarity. At its core, Fianu bridges the gap between Security, Quality Assurance, Engineering, and Risk with a shared language and a unified front to regulators and auditors. The result is reduced risk, faster release cycles, and easier audits.
“Fianu is truly revolutionizing secure software development observability,” said Leo Scott, Chief Innovation Officer for DataTribe and a Fianu Board of Directors member. “Fianu gives Chief Technology Officers, Chief Security Officers, and Chief Information Officers confidence to deliver software at the speed they want and with the integrity required.”
Over the last three years, the federal government has signaled increased scrutiny of software release patterns foreboding an era of crippling red tape and higher costs that could create significant challenges for companies across the regulatory landscape. Additionally, recent rulings have expanded the liability of software vendors and their executives. The message is clear: Companies that develop software will be held accountable for the security of their products. Fianu aims to reduce the weight of regulation for established companies while helping smaller and traditionally less-regulated companies transition to the new era of software development.
The company is providing visibility into the software development process in a provable way, enabling organizations to immutably attest to fundamental, sound, and secure software development best practices. Today, the demand is in regulated industries, but in the future, all companies producing custom software solutions will need to meet software governance requirements.
Fianu’s platform captures evidence across the DevSecOps toolchain mapped to internal policy during real-time, continuous audits against established risk controls and compliance frameworks. Each software release is accompanied by a Software Bill of Attestations (SBOA) designed to transmit immutable, audit-worthy evidence. By using Fianu, companies can replace opaque manual processes with streamlined, intuitive automation that makes software governance and compliance easy.
“There is no better team than DataTribe to help us realize our vision of a governance ecosystem that powers a modern approach to continuous delivery under rigorous regulatory requirements,” said Michael Edenzon, CEO and co-founder of Fianu Labs.
About DataTribe
DataTribe is a startup foundry that invests in and co-builds world-class startups focused on generational leaps in cybersecurity and data science. Founded by leading investors, startup veterans, and alumni of the U.S. intelligence community, DataTribe commits capital, in-kind services, access to an unparalleled network, and decades of professional expertise to give their companies an unfair advantage. DataTribe is headquartered in the Washington-Baltimore metro area in Fulton, Maryland. For more information, visit datatribe.com.
About Fianu Labs
Fianu Labs is a pioneer in the field of governance engineering and RegTech. Our focus is building software products to empower companies to deliver compliant software with maximum velocity. Fianu Labs is headquartered in Washington, D.C., and was founded by leaders in software governance, co-authors of Investments Unlimited, and software delivery experts from one of the nation’s largest banks. For more information, visit fianu.io.

View source version on businesswire.com: https://www.businesswire.com/news/home/20230830073713/en/
Josh Zecherjosh@vrge.us


Date: August 30, 2023 8:00 AM
Author: Shubham Sharma
Link: https://venturebeat.com/ai/typeface-teams-with-growthloop-and-google-cloud-to-launch-unified-genai-marketing-solution/
Title: Typeface teams with GrowthLoop and Google Cloud to launch unified ‘GenAI Marketing Solution’
Content: AI company Typeface has partnered with marketing player GrowthLoop and Google Cloud with the goal of transforming marketing for organizations of all sizes. The companies today announced a unified “GenAI Marketing Solution” that brings together the best of their respective platforms and gives marketers an end-to-end approach to create and launch campaigns across channels, at scale.
The offering allows teams to produce personalized content — from blogs to social media posts — for their campaigns, leveraging data from Google BigQuery, audience segmentation from GrowthLoop and Typeface’s generative AI smarts. According to the companies, it can cut the time taken to build and launch creative campaigns from several weeks down to days or even a few hours. 
“Marketing leaders across the globe have shared with us that producing personalized content at scale across audience segments can be a significant challenge, often causing campaigns to take months and months to launch,” Vishal Sood, head of product at Typeface, said in a statement. “The GenAI Marketing Solution announced at Google Cloud Next offers marketers — for the first time ever — the ability to rapidly generate and deploy tailored, on-brand content across customer segments. With this new solution, marketing teams can dramatically accelerate campaign launches freeing up time for more creativity and collaboration.”
Currently available in private preview for Google BigQuery users, the GenAI Marketing Solution merges gen AI from Typeface into a streamlined workflow that covers every aspect of the campaign creation process, from extracting 360-degree customer profiles and defining audience segments to creating personalized, on-brand content, distributing it and measuring the results.
First, users have to connect their BigQuery instance with GrowthLoop and use the latter’s visual or natural language builder to query data in the data warehouse and create audience segments to target. Once the segments are ready, they can export them to a marketing channel of choice, such as Google Ads, and use the Typeface integration with GrowthLoop to develop personalized creatives, ad copies, and campaign assets with text prompts.
As they develop the initial campaign assets, they can expand the effort by using Typeface to create an entire library of content for different marketing channels — such as personalized Instagram ads, SEO-optimized blog posts, and landing pages — that align with the GrowthLoop audience profile. This gives multiple variations of content, tailored to defined audience segments and brand voice, for different touchpoints.
Post-launch, teams can measure the results of the campaign directly within GrowthLoop, down to individual metrics such as revenue generated.
“Our collaboration results in an extraordinary solution, one that promises to reshape marketing workflows for businesses across the globe,” said Chris Sell, cofounder and co-CEO of GrowthLoop. “As we harness the transformative power of generative AI, we find ourselves at the cusp of a new chapter, empowering digital marketing teams with unparalleled efficiency and success-driving tools.”
While it remains unclear when the unified GenAI Marketing Solution will become generally available, there’s no denying that the move to rope in generative technologies is a welcome change for marketers who are facing increasing pressure to create compelling, personalized content to drive results in today’s fast-paced environment.
According to a Salesforce survey of more than 1,000 full-time marketers in the U.S., U.K. and Australia, gen AI is being seen as a “game-changer” that can save an employee about five hours of work every week. That’s more than a month every year, assuming eight-hour work days.
Among those using the technology at present, the most popular use case is basic content creation and writing marketing copy, with as many as 76% handling those tasks with LLM-driven apps like ChatGPT. The next most popular use cases are inspiring creative thinking (71%), analyzing market data (63%) and generating image assets (62%). 
Notably, LinkedIn’s Campaign Manager has already debuted a feature that allows users to generate introductory text and headlines for ads, using their data from the platform, while Meta has an AI Sandbox that lets advertisers create variations of basic copy for different audiences through text prompts.


Date: August 30, 2023 7:16 AM
Author: Sharon Goldman
Link: https://venturebeat.com/ai/ibm-serves-up-ai-generated-tennis-commentary-and-draw-analysis-at-the-us-open/
Title: At the US Open, IBM serves up AI-generated tennis commentary and draw analysis
Content: Back in May, IBM doubled down on its AI efforts with the announcement at the company’s annual Think conference of its new Watsonx product platform, which provides a foundational model library that can be used to fine-tune pretrained models for enterprise application development. 
Now, the company is serving up what it hopes is a generative AI ace: For the first time, it is offering AI-generated audio tennis highlights for all matches during the two-week-long U.S. Open Tennis Championships, as well as AI-powered analysis to determine the projected difficulty of player draws and potential opponents. 
More than 700,000 people head to Flushing Meadows, New York, each year to watch the best tennis players in the world compete, while more than 10 million tennis fans around the world follow the tournament through the U.S. Open app and website. And, for three decades, IBM has been working with the United States Tennis Association on creating digital experiences for tennis fans. 
The effort begins in the basement-level IBM data operations center at Arthur Ashe Stadium, where millions of data points are captured and analyzed. There are typically 56 data points collected for every single point of a tennis match. 
IBM is using gen AI models built, trained and deployed with Watsonx, and operating across a hybrid cloud infrastructure from Red Hat OpenShift, to generate detailed audio narration and captions to accompany U.S. Open highlight videos at unprecedented scale — for every match in the singles draw, across all 17 courts.
In addition, IBM debuted its Watsonx-powered AI Draw Analysis that uses both structured and unstructured data to project the level of advantage or disadvantage of all players in the singles draw. Each player receives an IBM AI Draw Analysis at the start of the tournament, which will be updated daily as the tournament progresses and players are eliminated. Every draw is ranked, allowing fans to click into individual matches and see the projected difficulty of their draw and potential opponents.
Kirsten Corio, chief commercial officer at the USTA, told VentureBeat that with 128 men and 120 women playing singles in the U.S. Open — as well as doubles, juniors and wheelchair tennis matches — the organization couldn’t cover the highlights of most of the matches throughout the tournament. 
“Depending on how many writers you have, you can only do a few matches at a time,” she said. “The other matches would just have stats and scores, but no commentary, so those stories are untold.” 
So the USTA and IBM began to think about how to scale tournament coverage by combining stats and stories with gen AI. 
“How could we use the data and technology to actually write highlights that would be reliable and accurate enough?” said Corio. 
Corio added that the USTA dreams of including AI-generated highlights in different languages in the future. “We would love to do that in Spanish, to scale more engagement,” she said. “That’s the natural next step.” 
While the USTA has been partnering with IBM on its technology efforts for decades, when it comes to today’s advanced AI applications, Corio pointed out that being able to control the data and the ecosystem is key. 
The USTA uses its own curated, official data, “but there are plenty out there who peddle in unofficial data,” she explained. “We’re not yet sure what the downstream effects of that could be, so we’re actually putting together a few different task forces across the company post-U.S. Open, to dig into how can it benefit us? How can we protect against any potential conflict?” 
A more of-the-moment concern is AI hallucinations — but in a presentation in the IBM Data Center beneath Arthur Ashe Stadium, an IBM spokesperson told VentureBeat that the company is doing human-in-the-loop quality checks on its AI Commentary. 
“We’re hoping over time we can reduce the need for human QA, but we do check each highlight clip, to make sure that the commentary is solid,” the spokesman said. 


Date: August 30, 2023 7:15 AM
Author: Carl Franzen
Link: https://venturebeat.com/ai/arize-ai-wants-to-improve-enterprise-llms-with-prompt-playground-new-data-analysis-tools/
Title: Arize AI wants to improve enterprise LLMs with ‘Prompt Playground,’ new data analysis tools
Content: We all know enterprises are racing at varying speeds to analyze and reap the benefits of generative AI — ideally in a smart, secure and cost-effective way. Survey after survey over the last year has shown this to be true. 
But once an organization identifies a large language model (LLM) or several that it wishes to use, the hard work is far from over. In fact, deploying the LLM in a way that benefits an organization requires understanding the best prompts employees or customers can use to generate helpful results — otherwise it’s pretty much worthless — as well as what data to include in those prompts from the organization or user.
“You can’t just take a Twitter demo [of an LLM] and put it into the real world,” Aparna Dhinakaran, cofounder and chief product officer of Arize AI, said in an exclusive video interview with VentureBeat. “It’s actually going to fail. And so how do you know where it fails? And how do you know what to improve? That’s what we focus on.”
Three-year-old business-to-business (B2) machine learning (ML) software provider Arize AI would know, as it has since day one been focused on making AI more observable (less technical and more understandable) to organizations. 
Today, the VB Transform award-winning company announced at Google’s Cloud Next 23 conference industry-first capabilities for optimizing the performance of LLMs deployed by enterprises, including a new “Prompt Playground” for selecting between and iterating on stored prompts designed for enterprises, and a new retrieval augmented generation (RAG) workflow to help organizations understand what data of theirs would be helpful to include in an LLMs responses. 
Almost a year ago, Arize debuted its initial platform in the Google Cloud Marketplace. Now it is augmenting its presence there with these powerful new features for its enterprise customers.
Arize’s new prompt engineering workflows, including Prompt Playground, enable teams to uncover poorly performing prompt templates, iterate on them in real time and verify improved LLM outputs before deployment. 
Prompt analysis is an important but often overlooked part of troubleshooting an LLM’s performance, which can simply be boosted by testing different prompt templates or iterating on one for better responses.
With these new workflows, teams can easily:
As Dhinakaran explained, prompt engineering is absolutely key to staying competitive with LLMs in the market today. The company’s new prompt analysis and iteration workflows help teams ensure their prompts cover necessary use cases and potential edge scenarios that may come up with real users.
“You’ve got to make sure that the prompt you’re putting into your model is pretty damn good to stay competitive,” said Dhinakaran. “What we launched helps teams engineer better prompts for better performance. That’s as simple as it is: We help you focus on making sure that that prompt is performant and covers all of these cases that you need it to handle.”
For example, prompts for an education LLM chatbot need to ensure no inappropriate responses, while customer service prompts should cover potential edge cases and nuances around services offered or not offered.
Arize is also providing the industry’s first insights into the private or contextual data that influences LLM outputs — what Dhinakaran called the “secret sauce” companies provide. The company uniquely analyzes embeddings to evaluate the relevance of private data fused into prompts.
“What we rolled out is a way for AI teams to now monitor, look at their prompts, make it better and then specifically understand the private data that’s now being put into those those prompts, because the private data part makes sense,” Dhinakaran said.
Dhinakaran told VentureBeat that enterprises can deploy its solutions on premises for security reasons, and that they are SOC-2 compliant. 
These new capabilities enable examination of whether the right context is present in prompts to handle real user queries. Teams can identify areas where they may need to add more content around common questions lacking coverage in the current knowledge base.
“No one else out there is really focusing on troubleshooting this private data, which is really like the secret sauce that companies have to influence the prompt,” Dhinakaran noted.
Arize also launched complementary workflows using search and retrieval to help teams troubleshoot issues stemming from the retrieval component of RAG models.
These workflows will empower teams to pinpoint where they may need to add additional context into their knowledge base, identify cases where retrieval failed to surface the most relevant information, and ultimately understand why their LLM may have hallucinated or generated suboptimal responses.
Dhinakaran gave an example of how Arize looks at query and knowledge base embeddings to uncover irrelevant retrieved documents that may have led to a faulty response.
“You can click on, let’s say, a user question in our product, and it’ll show you all of the relevant documents that it could have pulled, and which one it did finally pull to actually use in the response,” Dhinakaran explained. Then “you can see where the model may have hallucinated or provided suboptimal responses based on deficiencies in the knowledge base.”
This end-to-end observability and troubleshooting of prompts, private data and retrieval is designed to help teams optimize LLMs responsibly after initial deployment, when models invariably struggle to handle real-world variability.
Dhinakaran summarized Arize’s focus: “We’re not just a day one solution; we help you actually ongoing get it to work.”
The company aims to provide the monitoring and debugging capabilities organizations are missing, so they can continuously improve their LLMs post-deployment. This allows them to move past theoretical value to real-world impact across industries.


Date: August 30, 2023 7:01 AM
Author: Shubham Sharma
Link: https://venturebeat.com/ai/context-raises-3-5m-to-elevate-llm-apps-with-detailed-analytics/
Title: Context raises $3.5M to elevate LLM apps with detailed analytics
Content: London-based Context, a startup providing enterprises with detailed analytics to build better large language model (LLM)-powered applications, today said it has raised $3.5 million in funding from Google Ventures, Tomasz Tunguz from Theory Ventures and other sources. 
Context AI said it will use the capital to grow its engineering teams and build out its platform to better serve customers.
The investment comes at a time when global companies are bullish on AI and racing to implement LLMs into their internal workflows and consumer-facing applications. According to estimates from McKinsey, with this pace, generative AI technologies could add up to $4.4 trillion annually to the global economy.
While LLMs are all the rage, building applications using them isn’t exactly a cakewalk. You have to track a model’s performance, how the application is being used, and most importantly, whether it is providing the right answers to users or not — accurate, unbiased and grounded in reality. Without these insights, the whole effort is just like flying blind with no direction to make the product better.
Henry Scott-Green, who previously worked as a product manager at Google, saw similar challenges earlier this year when working on a side project that tapped LLMs to let users chat with websites. 
“We talked to many product developers in the AI space and discovered that this lack of user understanding was a shared, critical challenge facing the community,” Green told VentureBeat. “Once we identified and validated the problem, we started working on a prototype [analytics] solution. That was when we decided to build Context.”
Today, Context is a full-fledged product analytics platform for LLM-powered applications. The offering provides high-level insights detailing how users are engaging with an app and how the product is performing in return. 
This not only covers basic metrics like the volume of conversations on the application, top subjects being discussed, commonly used languages and user satisfaction ratings, but more specific tasks such as tracking specific topics (including risky ones) and transcribing entire conversations to help teams see how the application is responding in different scenarios.
“We ingest message transcripts from our customers via API, and we have SDKs and a LangChain plugin that make this process [take] less than 30 minutes of work,” Green explained. “We then run machine learning workflows over the ingested transcripts to understand the end user needs and the product performance. Specifically, this means assigning topics to the ingested conversations, automatically grouping them with similar conversations, and reporting the satisfaction of users with conversations about each topic.”
Ultimately, using the insights from the platform, teams can flag problem areas in their LLM products and work towards addressing them and delivering an improved offering to meet user needs.
Context claims to have garnered multiple paying customers since its founding four months ago, including Cognosys, Juicebox and ChartGPT, as well as several large enterprises. Citing non-disclosure agreements, Green did not share further details.
With this round, the company plans to build on its effort by hiring a technical founding team, which will allow Green and his team to accelerate their development and build an even better product. 
“The product itself has a few planned focus areas: to build higher-quality ML systems that deliver deeper insights; to improve the user experience; and to develop alternate deployment models, where our customers can deploy our software directly in their cloud,” the CEO said.
“At this stage, our goal is to continue growing our customer base while delivering value to the businesses using our product. And we’re seeing success,” he added.
As the demand for LLM-based applications grows, the number of solutions for tracking their performance is also expected to rise. 
Observability player Arize has already launched a solution called Phoenix, which visualizes complex LLM decision-making and flags when and where models fail, go wrong, give poor responses or incorrectly generalize. Datadog is going in the same direction and has started providing model monitoring capabilities that can analyze the behavior of a model and detect instances of hallucinations and drift based on data characteristics such as prompt and response lengths, API latencies and token counts.
Green, however, emphasized that Context provides more insights than these offerings, which just flag the problem areas, and is more like web product analytics companies such as Amplitude and Mixpanel.
The funding round also saw participation from 20SALES and multiple VCs and tech industry luminaries, including 20VC’s Harry Stebbings, Snyk founder Guy Podjarny, Synthesia founders Victor Riparbelli and Steffen Tjerrild, Google DeepMind’s Mehdi Ghissassi, Nested founder Matt Robinson, Deepset founder Milos Rusic and Sean Mullaney from Algolia.


Date: August 30, 2023 6:00 AM
Author: Sean Michael Kerner
Link: https://venturebeat.com/ai/couchbase-aims-to-boost-developer-database-productivity-with-capella-iq-ai-tool/
Title: Couchbase aims to boost developer database productivity with Capella IQ AI tool
Content: Database vendor Couchbase today announced the launch of Capella IQ, a new AI-powered tool aimed at enhancing developer productivity when building applications on the Couchbase Capella database-as-a-service (DBaaS) cloud platform.
Couchbase was originally developed as an open-source NoSQL database technology and has grown in recent years to add capabilities that are commonly found in relational database technologies. In 2021, Couchbase, Inc., went public on the NASDAQ and now trades under the symbol BASE. That same year, the company first released its Capella DBaaS platform, which has continued to expand with support on multiple cloud platforms including Google Cloud.
The goal with Couchbase Capella is to provide a database platform for developers that is easier to use and manage. The launch of Capella IQ brings the power of generative AI to the platform to help developers write database code.
“Think of it [Capella IQ] as a copilot for developers, using LLM [large language model] foundation models to really enhance the productivity of developers,” Matt Cain, Couchbase president and CEO, told VentureBeat.
The new tool fits into Couchbase’s overall four-pronged AI strategy, according to Cain.
Couchbase’s AI strategy includes driving developer productivity, optimizing AI processing, enabling AI-driven applications anywhere, and complementing its technology with partnerships. Cain said that Capella IQ addresses the first pillar around developer productivity.
Cain explained that Capella IQ leverages gen AI models to automate tedious development tasks like generating code snippets, sample datasets and unit tests. He noted that developers can access these capabilities directly within the Capella developer workbench through a conversational interface that is designed to have a low barrier to entry.
“It’s completely aligned with how we’re thinking about our AI strategy, but really focused on helping developers be as productive as possible with Capella and enabling next-generation applications,” said Cain.
With Capella IQ, Couchbase is using OpenAI’s models to help with code generation. Cain noted that Couchbase may choose to also work with other LLM providers in the future. 
He also emphasized that there are several capabilities in the Capella platform that help to enable the IQ feature beyond just connecting out to an LLM provider. One such feature is the Index Advisor, an existing built-in capability that is able to analyze data queries and provide users with optimization recommendations to improve database index to accelerate response time.
While Couchbase is now jumping into the gen AI era with Capella IQ, it is still missing at least one critical element needed to help power AI applications: vector embedding support.
This is an increasingly common feature on existing database platforms, with multiple vendors including DataStax, Google with AlloyDB and MongoDB announcing support in 2023. 
Support for vector embedding is very much on Cain’s mind, and it is part of his company’s roadmap for inclusion in the near future. He explained that vector embedding support will be enabled in the future as an extension to the platform.
“Our underlying system is a multi-model caching JSON document database that performs both operational and analytical capabilities, and then we have architecturally enabled services like full text search,” he said. “With a similar architecture we can approach vector and make that a seamless aspect of our platform, where developers can not only take advantage of those capabilities, but do more with less, with a true enterprise platform.”


Date: August 30, 2023 6:00 AM
Author: Michael Nuñez
Link: https://venturebeat.com/data-infrastructure/databricks-bets-big-on-activating-data-for-marketers-with-hightouch-investment/
Title: Databricks bets big on activating data for marketers with Hightouch investment
Content: We’re living in a time where just about every company is overflowing with data, but when it comes to getting meaningful insights from it — that’s where organizations are often coming up short. 
Enter Databricks, a San Francisco-based heavyweight in the data and AI space. They’re the team behind the lakehouse concept and they’re on a mission: To monetize data by making insights more accessible. 
Today, Databricks has announced it’s putting its money where its mouth is. The company’s venture capital arm, Databricks Ventures, revealed in an exclusive VentureBeat report that it has made a strategic investment in promising San Francisco-based startup Hightouch, a software platform that helps businesses synchronize and activate all of their customer data.
The strategic investment is a part of a recent $38 million funding announcement aimed squarely at a core challenge that has troubled businesses: How to effectively harness the power of their vast data resources. The combined offering of Databricks’ robust data platform and Hightouch’s efficient data extraction capabilities is set to provide businesses with the tools needed to fully exploit their data, particularly in the field of marketing.
Steve Sobel, who leads communications, media and entertainment at Databricks, explained the essence of the partnership in an interview with VentureBeat. “What we’re delivering with Hightouch is all around making data usable,” he said. “It’s about helping organizations through their enterprise data challenges and strategy.” 
Sobel’s comments underscore Databricks’ game plan to position itself as a vertical player in the sector, focusing on speaking the language of the customer and the industry. “We live in an era where every industry is moving toward direct-to-consumer,” he said. “Optimizing marketing and delivering a superior, personalized experience across any channel, anywhere, anytime is essential.”
Hightouch cofounder and co-CEO Kashish Gupta offered a complementary perspective, explaining the “match booster” concept, a feature built into Hightouch that harmonizes first-party data with third-party datasets. “This approach allows businesses to reach their customers across a multitude of different channels,” said Gupta.
He further explained the convergence of data and marketing strategies, saying: “A data strategy and marketing strategy have actually become one in the current business landscape. Personalization based on factors such as zip code, last login time and myriad other activities now decisively influences these strategies.”
Reflecting on the surge in digital data, Gupta pointed out: “Companies have more data than ever due to digital transformation. Extracting value out of that data by optimizing marketing using the data is truly where this partner strategy delivers.”
(Editor note: To help enterprise executives learn more about how to manage their data to prepare for generative AI applications, VentureBeat is hosting its Data Summit 2023 on November 15. The event will feature networking opportunities and sessions on topics such as data lakes, data fabrics, data governance and data ethics. Pre-registration for a 50% discount is open now.)
Founded in 2020 by Gupta, a former Bessemer Venture Partners investor, and former Segment engineers Tejas Manohar and Josh Curl, Hightouch helps customers leverage their data warehouse as a single source of truth for their business teams.
By using Hightouch’s reverse ETL (extract, transform and load) technology, customers can access, explore and sync data from their data warehouse to more than 200 SaaS tools such as Salesforce, HubSpot, Facebook and TikTok, without relying on engineering resources.
Hightouch claims to have hundreds of customers already across various verticals and industries, including the NBA, Grammarly, PetSmart, Imperfect Foods and Betterment. For context on its rapid growth, the company says it increased its revenue three times in the first half of 2022 alone and has grown its team from 40 employees in 2021 to 93 this year.
The new funding will be used to invest in product development, especially in the areas of customer understanding and out-of-the-box machine learning (ML) models, according to Gupta. Hightouch also plans to expand its go-to-market activities and hire more talent across different functions.
Gupta said that the company’s rapid growth has been driven by customer demand and product market fit. He said that Hightouch’s vision is to democratize data for all business teams by enabling them to use data from their data warehouse without code or engineers.
Hightouch is one of the pioneers of the reverse ETL category, which is rapidly growing as more businesses adopt data warehouses as their source of truth. According to Gartner, the number of enterprises implementing AI grew by 270% in the past four years and tripled in the past year, driving an increase in streaming data and analytics infrastructures with it. This creates a huge opportunity for platforms like Hightouch that can help businesses activate their data and apply AI to it.


Date: August 30, 2023 5:00 AM
Author: Carl Franzen
Link: https://venturebeat.com/enterprise-analytics/confirm-raises-6-2-million-to-bring-generative-ai-and-network-analysis-to-performance-reviews/
Title: Confirm raises $6.2 million to bring generative AI and network analysis to performance reviews
Content: Does anybody like hearing the phrase, “It’s performance review season, again”? 
In most organizations where this author has ever worked (and he has worked at many), neither managers nor employees particularly relished the process of giving and receiving performance reviews. 
Still, many companies insist on them as a way of evaluating their talent and ensuring that high performers are rewarded with promotions or new opportunities, while low performers are identified and put on a path to improvement — or toward exiting the company. Yet, when administered by human beings — be they managers or peers — performance reviews can feel like personal attacks.
Confirm thinks it has a better way forward. The San Francisco-based startup announced it has raised $6.2 million in series A funding (and a total of $11.4 million) to transform the performance review process from the ground up, incorporating “organizational network analysis (ONA),” an approach the consulting giant Deloitte describes as “​visualizing and analyzing formal and informal relationships in your organization,” as well as generative AI in the form of OpenAI’s GPT-4, to deliver more fair, scientific and efficient performance reviews. 
The round was spearheaded by Spero Ventures, and saw participation from SHRMLabs, Elefund, Gaingels and Black Angel Group as well as some of Confirm’s existing clients.
According to Confirm, traditional performance review methods like continuous feedback and 360-degree assessments often muddy the waters instead of clearing them. Confirm is looking to change this by making performance reviews more straightforward and data-driven. 
Confirm’s approach measures employee performance by examining how all employees in the company view one another. ONA operates on the principle that performance isn’t an isolated metric, but a network of relationships and influences within the workplace.
In fact, Confirm’s prior research published in Fast Company found that male employees received 25% higher ratings than female employees on average from managers, compared to the network ratings for both groups. 
It also offers GPT-4-created drafts of performance reviews customized to each specific employee with input from their peers and managers; auto-generated employee survey results; and auto-calibrated ratings for employees that seek to minimize bias from any one particular manager or another. 
Confirm was founded not too long ago in 2019, but companies like Canada Goose, Niantic and Thoropass have already been reaping the benefits of its performance review platform. 
Thoropass, for instance, managed to identify and keep all of its top performers during the wave of employee turnover known as “The Great Resignation,” in the late stages of the COVID-19 pandemic. 
According to Joe Bast, VP of people and operations at Thoropass, ONA has been a game-changer, helping the company understand not just high and low performers, but also who the real influencers within the company are.
The company also earned a “World Changing Ideas Award” from Fast Company, and an HR Tech Award for Best Talent Intelligence Solution from Lighthouse Research and Advisory. It was chosen by SHRMLabs for its 2023 WorkplaceTech Accelerator program, a platform that helps promising startups grow. 
While every organization — from large to small, from established longstanding leaders to nimble new startups — has its own culture and politics, those shouldn’t really influence performance reviews, according to Confirm’s vision of the future.
David Murray, cofounder and president, wants to create “a world where employees are recognized and rewarded for their hard work and positive impact, not their ability to play office politics.”
And, in a time where remote and hybrid teams are commonplace, there may not even be a real opportunity to evaluate someone face-to-face. Data-driven performance reviews matter more than ever, and Confirm aims to be the first name you think of when it comes time to do them — hopefully with a lot less dread than before. 


Date: August 29, 2023 4:02 PM
Author: Carl Franzen
Link: https://venturebeat.com/ai/runway-announces-creative-partners-program-giving-select-users-unlimited-plans-new-features/
Title: Runway announces ‘Creative Partners Program’ giving select users unlimited plans, new features
Content: RunwayML, the New York City-based startup that’s raised hundreds of millions in venture funding to develop generative AI video creation tools, has announced it will begin granting a select group of users early access to new features and and AI models. 
The company announced its new Runway Creative Partners Program on X (formerly Twitter), writing, “This program provides a select group of artists and creators with exclusive access to new Runway tools and models, Unlimited plans, 1 million credits, early access to new features and more.” 
“It’s all about being in the right place at the right time,” Runway CEO and founder Cristóbal Valenzuela posted on X.
On its website, Runway goes into more detail about what the Creative Partners Program will offer. Among the features are “direct access to the Runway team” and “priority access to Runway Studios grants.”
Runway’s pricing structure requires using several proprietary credits to generate each video through its Gen-1 and Gen-2 multimodal video generation AI tools (users can generate videos from existing videos, text prompts, and imagery). 
While the program does have a free tier with 125 non-renewable credits, the Standard Plan costs $12 per month per user for 625 credits that renew each month, while the Unlimited Plan tier costs $76 per user per month, but grants each user 2,250 credits/month of video generations in Gen-1 and Gen-2, and unlimited credits in a slower “relaxed” generation mode. 
The Unlimited plan with a million credits to start is a major win for potential users. 
In addition, the company has continually updated and expanded its gen AI offerings, moving from the text-to-video Gen-1 release in February of this year, to a video-to-video Gen-1 mobile app in April, to the release of the text/video/image-to-video Gen-2 for desktop and mobile in June. Just this month, the company released a new “Watch” tab to show off the video creations of its users, similar to YouTube. 
Therefore, it stands to reason that the company will have more new features and services soon — and it is promising to give them to those accepted into its Creative Partners Program first.
The company is for now open to considering seemingly any and all applicants, asking them to fill out a form on its website with fields for the user’s name, pronouns, portfolio and social media accounts.
When it comes to who is eligible, a Runway spokesperson emailed VentureBeat the following statement: 
“Anyone from anywhere in the world is welcome to apply. We’re looking for creators who are using AI tools and techniques to push the boundaries of creativity. It’s not required to have a paid Runway account to be admitted.
“Applications will be accepted on a rolling basis over the coming weeks and months, and creators who are accepted will announce their involvement to their own communities at their discretion.”
The obvious comparison to Runway is increasingly YouTube, although the latter is of course not limited to, nor does it presently offer, gen AI video creation tools and videos.
But YouTube paved the way in building a robust ecosystem of amateur (and pro) video creators, which it sought to nurture and continues to support through its YouTube Partner Program (YPP), which allows creators to monetize their videos through subscriptions, ecommerce affiliate links and product mentions, advertising, digital stickers and more. 
YouTube itself funded several higher-production TV shows and films through its YouTube Originals brand, including the Karate Kid spinoff Cobra Kai, although YouTube ultimately canceled its scripted development arm and that series was later canceled and picked up by rival Netflix. 
It’s unclear just how much of YouTube’s playbook Runway may seek to emulate, but launching a Creative Partners Program is a similar starting move for creating a thriving creator ecosystem, and seems like the necessary first step in making the dominant AI video platform. 


Date: August 29, 2023 1:00 PM
Author: Sean Michael Kerner
Link: https://venturebeat.com/ai/usertesting-expands-platform-with-generative-ai-to-scale-human-insights/
Title: UserTesting expands platform with generative AI to scale human insights
Content: UserTesting is kicking off its Human Insights Summit today with the launch of a new set of generative AI powered capabilities for its platform.
The new features that the company is simply calling UserTesting AI are intended to help customers scale up experience research efforts using AI. The initial set of tools benefit from an integration with OpenAI to help users more easily generate summaries and build reports from research data. They extend existing AI capabilities that UserTesting has developed in-house in recent years to help organizations to better understand user behavior and sentiment for products and services. 
Back in April, UserTesting launched its machine learning (ML)-powered friction detection capability for behavioral analytics.
The goal with the new UserTesting AI tools is to go beyond what the company has already been doing and tap into the power of gen AI technologies like OpenAI’s ChatGPT.
“UserTesting AI is a set of capabilities that are designed to be easily understood by our customers as being AI powered, that help a research, design, marketing or product team, essentially achieve more throughput,” Andy MacMillan, UserTesting CEO, told VentureBeat in an exclusive interview.
To date, much of the AI capabilities that UserTesting has provided to its users falls within the domain of ML.
MacMillan said that UserTesting has built its own ML models to take data from its platform, which enables teams to test how users interact with and experience a service or application. UserTesting records the user sessions and then uses its ML models to derive insights. The models have helped to identify things like sentiment, intent and where users get stuck in a workflow. 
With the new UserTesting AI tools, the company isn’t just sending raw data to the gen AI model to process. MacMillan emphasized that UserTesting is using the gen AI alongside its existing models.
“We’re taking a lot of those ML outputs, where we’ve extracted what a researcher would find interesting, the friction, the insights, the suggestions, in addition to the transcripts, and we’re providing that and we’re creating tasks, summaries and research report summaries using large language models (LLMs),” MacMillan said.
To date, user experience researchers have largely had to write reports and summaries on their own based on the data and insights from a UserTesting operation.
But now, for example, for a team that wants to test a new mobile app, the platform identifies and matches them with profiles of people ideal for testing. Users are then recorded as they test out the app prototype, with UserTesting ML models identifying interesting data points. The user is also recorded with video and audio and the entire sessions is transcribed.
“We run all those data streams through our ML models that help extract interesting moments,” said MacMillan.
The UserTesting platform then provides a results page that provides a list of interesting data points and highlights from the session. With UserTesting AI, researchers now get a full summary and report generated base on detailed findings. The report and summaries generated by AI will also have specific citations and references that can help researchers dig into specific data points.
While there is some concern with the broader use of gen AI and how it could have potential bias, MacMillan said that UserTesting AI could actually help to reduce potential bias.
“We think UserTesting AI can help our customers be more efficient,” said MacMillan. “I think it also helps researchers to avoid missing something, and it can help avoid biases, so you as the person doing the research might have some biases and AI can help you maybe see things you might not see.”


Date: August 29, 2023 12:45 PM
Author: Bryson Masse
Link: https://venturebeat.com/ai/openai-seeks-to-dismiss-majority-of-sarah-silvermans-and-authors-claims-in-chatgpt-lawsuits/
Title: OpenAI seeks to dismiss majority of Sarah Silverman’s and authors’ claims in ChatGPT lawsuits
Content: OpenAI, the organization behind ChatGPT and its underlying large language models (LLMs) GPT-3.5 and GPT-4, has filed motions to dismiss in two copyright lawsuits levied against the company for using copyrighted materials in AI model training data. The plaintiffs include a pair of U.S. authors and a second group including comedian and actor Sarah Silverman.
In the filings submitted to the U.S. District Court for the Northern District of California on Monday, OpenAI requested the dismissal of five out of the six counts lodged in the lawsuits. The company defended the transformative nature of its LLM technology, underscoring the need to balance copyright protection and technological advancement. OpenAI also said that it planned to contest the remaining count of direct copyright infringement in court as a matter of law.
The motions addressed the claims asserted in the copyright lawsuits and aimed to elucidate the case’s merits. OpenAI underscored the value and potential of AI, particularly ChatGPT, in enhancing productivity, aiding in coding and simplifying daily tasks. The company likened ChatGPT’s impact to a significant intellectual revolution, drawing parallels with the invention of the printing press.
“You can start to see the story that they’re going to tell here, which is that copyright has limitations to it. It doesn’t extend to facts and ideas,” said Gregory Leighton, a privacy law specialist at law firm Polsinelli. “Even if a work is copyright[ed] and an LLM [is] processing it or then producing a summary of it back or something like that, that’s not a derivative work on its face.”
OpenAI based its defense on the fundamental facts of the LLM technology: It is a type of neural network trained on extensive text data to comprehend human language effectively, and it enables users to input text prompts and receive corresponding generated content. Per the filings, OpenAI claims its products merge LLMs with parameters ensuring the accuracy, relevance, safety and utility of the produced outputs.  
The plaintiffs argued that ChatGPT was trained without permission using their copyrighted works. In response, OpenAI contended that this perspective overlooks the broader implications of copyright law, including fair use exceptions.
The company asserted that fair use can accommodate transformative innovations like LLMs and is aligned with the constitutional intent of copyright law to foster scientific and artistic progress. 
“It’s true substantively, but there’s an interesting sleight of hand going on here,” said Leighton.
“You shouldn’t be talking about fair use in a motion to dismiss, because fair use is an affirmative defense. It’s actually something that they, as the defendant, have to affirmatively plead and prove up,” he said.
OpenAI’s motion cited court cases where the fair use doctrine protected innovative uses of copyrighted materials. It called for the dismissal of secondary claims from the plaintiffs, including vicarious copyright infringement, violations of the Digital Millennium Copyright Act (DMCA), violations of California’s Unfair Competition Law (UCL), negligence and unjust enrichment. OpenAI challenged the legal validity of these claims and argued for their removal based on flawed legal reasoning.
“These were probably always the ancillary and companion claims, and the main meal here is copyright infringement,” said Leighton.
Vicarious copyright infringement is applied in cases where a party is in indirect benefit of copyright infringement, committed by another person. OpenAI stated that the plaintiff’s allegations of direct infringement were not valid as a matter of law, nor did it have any “right and ability to supervise” and it did not end up having any direct financial interest.
OpenAI offered refuting evidence to the plaintiffs’ various theories of why it violated vicarious infringement rules, the DMCA, and UCL, claims including: Every ChatGPT output is an infringing derivative work of their copyrighted books; and LLM training removes the “copyright management information” from the specified works.
OpenAI contends that the plaintiffs don’t have enough evidence to claim that LLMs produce derivative works, and that if those standards are applied on a wider scale, photographers would be able to sue painters who reference their material. The evidence offered by the plaintiffs about copyright management information was contradictory and failed to show how it was purposely removed, OpenAI said. 
The company also found deficiencies in the negligence and unjust enrichment claims, saying that there was no grounds for negligence as OpenAI or its users would be engaging in intentional acts and OpenAI did not owe the plaintiffs a duty of care. 
Nor, according to the filings, was there any evidence to support the claim that OpenAI held on to profits or benefits from the infringed material. 
Finally, OpenAI argued that both the negligence and unjust enrichment state law claims are preempted by federal copyright law.
“It might take a month or six weeks, but the plaintiffs will file a response where they’ll have to say why they think these claims should stay in,” said Leighton. “That actually might be quite interesting just to get their take of where they’re going with this.”
OpenAI’s dismissal motion is founded on ChatGPT’s transformative nature, fair use principles and perceived legal shortcomings in the plaintiffs’ ancillary claims. 
The motions provided insight into OpenAI’s overall defense of its ongoing operations as it navigates the complex intersection of copyright law and AI technology advancement. 
While Leighton believes that this particular motion to dismiss may not have huge immediate effects, the stakes in the overall case remain high. In determining the extent to which large language models can be trained on copyrighted works without infringing copyright, the outcome of the lawsuits could have major implications for AI use cases, especially if it is determined that ingesting copyrighted works always infringes copyright.
“We’re getting the first real insight into where this is really going to go,” said Leighton. “They’re introducing these things to the judge, not because it really has anything to do with the motion to dismiss itself and what they’re trying to accomplish procedurally, but it’s the intro thematically to [OpenAI’s] side of the case here.”
As the lawsuits unfold, this legal conflict will likely define the future of copyright law and technological progress.


Date: August 29, 2023 10:37 AM
Author: Shubham Sharma
Link: https://venturebeat.com/data-infrastructure/google-reveals-bigquery-innovations-to-transform-working-with-data/
Title: Google reveals BigQuery innovations to transform working with data
Content: Google is pushing the bar on how teams work with their data.
Today at its annual Cloud Next conference, the internet giant announced major improvements for BigQuery — its fully managed, serverless data warehouse, including a unified experience aimed at interconnecting data and workloads. The company also shared how it plans to bring AI to the data stored in the platform, and how it plans to leverage its generative AI collaborator to boost the productivity of teams looking to consume insights from data.
“These innovations will help organizations harness the potential of data and AI to realize business value — from personalizing customer experiences, improving supply chain efficiency, and helping reduce operating costs, to helping drive incremental revenue,” Gerrit Kazmaier, VP and GM for data and analytics at Google, wrote in a blog post.
However, it must be noted that most of these capabilities are still being previewed and not generally available to customers.
Within BigQuery, which allows users to perform scalable analysis over petabytes of data, Google is adding a unified interface called BigQuery Studio. This offering will provide users with a single environment for data engineering, analytics and predictive analysis.
Until now, data teams had to work with different tools for different tasks, from managing data warehouses and data lakes to governance and machine learning (ML). Handling these tools took a lot of time and slowed down productivity. With BigQuery Studio, Google is enabling these teams to work with all of these tools in one place, to quickly discover, prepare and analyze their datasets and run ML workloads on them.
“BigQuery Studio provides data teams with a single interface for your data analytics in Google Cloud, including editing of SQL, Python, Spark and other languages, to easily run analytics at petabyte scale without any additional infrastructure management overhead,” a company spokesperson told VentureBeat. “This means a data worker doesn’t have to switch from one tool to another; it’s all in one place, making their lives easier and getting to results faster.”
The offering is now available in preview and is already being tested by multiple enterprises including Shopify. Kazmaier also said Google is adding enhanced support for open-source formats like Hudi and Delta Lake within BigLake; performance acceleration for Apache Iceberg; and cross-cloud materialized views and cross-cloud joins in BigQuery Omni to analyze and train on data without moving it.
(Editor Note: To help enterprise executives learn more about how to manage their data to prepare for generative AI applications, VentureBeat is hosting its Data Summit 2023 on November 15. The event will feature networking opportunities and sessions on topics such as data lakes, data fabrics, data governance and data ethics. Pre-registration for a 50% discount is open now.)
Along with BigQuery Studio, Google is providing access to Vertex AI foundation models, including PaLM 2, directly from BigQuery. This will allow data teams using BigQueryML (to create and run ML models on their datasets) to scale SQL statements against large language models (LLMs) and gain more insights, quickly and easily. The company also said it is adding new model inference capabilities and vector embeddings in BigQuery to help teams run LLMs at scale on unstructured datasets.
“Using new model inference in BigQuery, customers can run model inferences across formats like TensorFlow, ONNX and XGBoost,” Kazmaier noted. “In addition, new capabilities for real-time inference can identify patterns and automatically generate alerts.”
Finally, the company said it is integrating its always-on generative AI-powered collaborator, Duet AI, into BigQuery, Looker and Dataplex. This will bring natural language interaction and automatic recommendations to these tools, boosting the productivity of teams and opening access to more users. 
This integration is also in preview with no word on general availability yet.
Google Cloud Next runs through August 31.


Date: August 29, 2023 8:44 AM
Author: Sean Michael Kerner
Link: https://venturebeat.com/ai/google-shows-off-whats-next-for-vertex-ai-foundation-models/
Title: Google shows off what’s next for Vertex AI, foundation models
Content: AI is a core focus for Google, and at its Google Next event today, the company announced a series of updates across its portfolio that benefit from the power of generative AI.
Front and center are enhancements and new capabilities across Google’s Vertex AI platform, including both developer tooling and foundation models.
Google’s PaLM 2 large language model (LLM), first announced at the Google I/O conference in May, is getting an incremental boost with more language support and longer token length. The Codey code generation LLM and the Imagen image generation LLMs are also getting updates to improve performance and quality.
Vertex AI is being expanded with new extensions to make it easier for developers to connect to data sources. Google is making both the Vertex AI Search and Vertex AI Conversation services generally available, providing search and chatbot capabilities to Google’s enterprise users.
Rounding out Google’s Vertex AI update is the Colab Enterprise service, which provides compliance and security capabilities to the data science notebook platform. 
In a press briefing ahead of the Google Next conference, June Yang, VP, cloud AI and industry solutions at Google, detailed some of the Vertex AI-related updates.
“AI is undergoing a major shift with the rise of foundation models. Now you can leverage these foundation models for a variety of use cases without ML [machine learning] expertise,” she said. “This is really a game-changer for AI, especially for the enterprises.”
Google builds its own foundation models and also provides support for a number of third-party models that can run on Google Cloud. Google’s flagship model is PaLM 2, available in a number of configurations. One is the text model, which is being enhanced with a larger input token length context window, something Yang said has been a “key request” from customers. Expanded from 4,000 to 32,000 tokens, PaLM 2’s context window will enable text users to process longer-form documents than before.
PaLM 2 is also being expanded with more language support, now with the general availability of 38 languages including Arabic, Chinese, Japanese, German and Spanish.
The Codey text-to-code LLM is another foundation model that has received an update, one which, according to Google, provides up to a 25% quality improvement for code generation.
“Leveraging our Codey foundation model, partners like GitLab are helping developers to stay in the flow by predicting and completing lines of code, generating test cases, explaining code and many more use cases,” Yang said.
The Imagen text-to-image LLM is being upgraded as well. The big new feature, one Yang referred to as one of the coolest she’s seen, is something Google calls “style tuning.”
“Our customers can now create images aligned to their specific brand guidelines or other creative needs with as few as 10 reference images,” she said.
For example, Yang said that with style tuning an Imagen user can apply corporate guidelines to either a newly generated image or an existing one, and the resulting Imagen image will have the appropriate style built into it.
While PaLM 2 is Google’s flagship foundation model, the company is also providing third-party LLM access on Google Cloud. The ability to support multiple foundation models is increasingly becoming table stakes for cloud providers. Amazon, for example, supports multiple third-party models with its Bedrock service.
Among the new third-party models that Google now supports is Meta’s Llama 2, which was just released in July. Yang said that Google will enable users to use reinforcement learning with human feedback (RLHF) so organizations can further train Llama 2 on their own enterprise data to get more relevant and precise results. 
Google will also be supporting Anthropic’s Claude 2 model and has pledged to support TII’s Falcon.
Foundation models on their own are interesting, but they get a whole lot more interesting when enterprises can connect them to their own data to take action. That’s where the new Vertex AI Extensions tools fit in.
Yang said that developers can use the Extensions to build powerful generative AI applications like digital assistants, customized search engines and automated workflows.
“Vertex AI Extensions are a set of fully managed developer tools, which connect models via API to real-world data and enable models to perform real-world actions,” Yang said.


Date: August 29, 2023 7:44 AM
Author: Louis Columbus
Link: https://venturebeat.com/security/whats-new-in-gartners-hype-cycle-for-data-security-in-2023/
Title: Quantum threats loom in Gartner’s 2023 Hype Cycle for data security
Content: The best-run organizations prioritize cybersecurity spending as a business decision first, and Gartner’s Hype Cycle for Data Security 2023 reflects the increasing dominance of this approach. Key technologies needed for assessing and quantifying cloud risk are maturing, and new technologies to protect against emerging threats are predicted to gain traction. 
Gartner sees the core technologies needed to validate and quantify cyber-risk maturing quickly as more organizations focus on measuring their cybersecurity investments’ impact. CISOs tell VentureBeat that it is a new era of financial accountability, and that extends to new technologies for securing data stored in multicloud tech stacks and across networks globally. Getting control of cybersecurity costs is becoming a much higher priority as boards of directors look at how data security spending protects, and potentially grows, revenue.
Gartner’s latest Hype Cycle for data security dovetails with what CISOs, CIOs and their teams tell VentureBeat, especially in compliance-centric industries such as insurance, financial services, institutional banking and securities investments. Gartner added five new technologies this year: crypto-agility, post-quantum cryptography, quantum key distribution, sovereign data strategies and digital communications governance. Eight technologies have been removed or reassigned this year. 
Getting integration right in data security at the enterprise level has always been a challenge. The need for more secure approaches to data integration has led to a proliferation of solutions over the years, some more secure than others. Gartner predicts these challenges will shift or consolidate data security technologies, including data security posture management (DSPM), data security platforms (DSPs) and multicloud database activity monitoring (DAM). 
CISOs also say they are monitoring quantum computing as an evolving potential threat and have delegated monitoring it to their strategic IT planning teams. Gartner also introduced crypto-agility in this year’s Hype Cycle, responding to its clients’ requests for as much data and knowledge as possible in this area. 
CISOs and the teams they manage tell VentureBeat that protecting data in the cloud, and the many identities associated with each data source across multicloud configurations, is getting more challenging given the need to provide access rights by data type while still tracking compliance. 
That’s made even more difficult by the exponential growth of machine identities across enterprises’ cloud instances. This year’s Hype Cycle for data security underscores this and other trends summarized here.
Board members regularly question CISOs about governance and risk management. CISOs tell VentureBeat that while board members know risk management at an expert level, they need to have the technology-based context of data governance and risk management defined from a tech stack and multicloud perspective. 
These dynamics between boards and CISOs are playing out across hundreds of companies as data governance and risk management dominate Gartner’s discussions in this year’s Hype Cycle. Boards want to know how to accurately quantify cyber-risk, which drives greater compliance. CISOs say that financial data risk assessment (FinDRA) is board-driven and weren’t surprised it appears on the Hype Cycle. 
Nearly every business relies on cloud services for a portion, if not all, of their infrastructure and application suites. Gartner sees this as a potential risk for data and has identified a series of technologies and techniques on the Hype Cycle to protect data in use and at rest. 
These include confidentiality, homomorphic encryption, differential privacy and secure multiparty computation (SMPC). Confidentiality relies on hardware-based trusted execution environments to isolate data processing, while SMPC allows collaborative data analysis without exposing raw data. The presence of these data-in-use technologies on the Hype Cycle demonstrate the shift from data security at rest to data security in transit.
Much has been written and predicted about when quantum computing will break encryption. In reality, no one knows when it will happen; however, there’s wide consensus that quantum technologies are progressing in that direction. CISOs VentureBeat interviewed on the topic see cryptography at varying levels of urgency depending on their business models, industries and how reliant they are on legacy encryption.
Gartner added both crypto-agility and post-quantum cryptography to the Hype Cycle for the first time this year. CISOs are pragmatic about technologies with as long a runway as these have. In previous interviews, CISOs told VentureBeat they could see where post-quantum cryptography could strengthen zero-trust frameworks in the long term.
Together, Gartner’s five new hype cycle technologies prepare CISOs for the next generation of quantum threats while addressing the most challenging aspects of governance and data sovereignty. The five newly added technologies are briefly summarized here: 
The purpose of crypto-agility is to upgrade encryption algorithms used in applications and systems in real time, alleviating the risk of a quantum-based breach. Gartner writes that this will enable organizations to replace vulnerable algorithms with new post-quantum cryptography to ward off attacks using quantum computing to defeat encryption. Crypto-agility offers CISOs a path to secure encryption as quantum capabilities advance over the next five to seven years. 
Gartner defines this new technology as based on new quantum-safe algorithms, such as lattice cryptography, that are resistant to decryption by quantum computers. The use case Gartner discusses in the Hype Cycle centers on using this technology in a pre-emptive strategy against quantum-based threats.
VentureBeat’s interviews with CISOs at financial trading firms revealed that pro-forma tech stacks already defend against quantum computing risks and threats. Gartner’s latest addition will likely be added to roadmaps for further evaluation by those CISOs responsible for commercial banking and other financial services and institutions. Leading vendors include Amazon, IBM and Microsoft.
This technology works by using quantum physics principles, including photon entanglement, to create and exchange tamper-evident keys. Gartner considers QKD a niche technology today. But given its nature, uses in applications critical to national security are a natural extension of its strengths, as it’s anticipated to be useful for exchanging high-value data. Leading vendors include ID Quantique, MagiQ Technologies and Toshiba.
This is a new addition to the Hype Cycle that supports data security governance, privacy impact assessment, financial data risk assessment (FinDRA) and data risk assessment. Sovereign data strategies reflect efforts by governments to provide strong governance and data security for their citizens and economy.
Privacy, security, access, use, retention, sharing regulations, processing and persistence are examples cited by Gartner. According to the firm, sovereign data strategies will eventually become table stakes for any business that needs to complete transactions across sovereign jurisdictions.
Digital communications governance (DCG) solutions monitor, analyze and enforce employee messaging, voice and video compliance policies. DCG platforms also manage regulatory and corporate governance requirements with data retention, surveillance, behavioral analytics and e-discovery. They help compliance teams identify misconduct and comply with regulations by monitoring communications data.
DCG also helps CIOs and CISOs manage employee messaging, voice and video platform risks by consolidating access and enforcement across communication channels. Leading vendors include Global Relay, Proofpoint and Veritas. 
Ten key trends emerge from this year’s Hype Cycle. Data governance, risk management and compliance are core drivers of the data security market. Gartner believes that preparing for quantum computing threats, convergence and integration of security tools, and managing unknown shadow IT data are high priorities. 
The following matrix compares the most influential factors, in order of priority, that are influencing the future of data security.


Date: August 29, 2023 6:30 AM
Author: Bryson Masse
Link: https://venturebeat.com/ai/ai-to-star-in-the-launch-of-webflows-built-in-app-ecosystem/
Title: AI to star in the launch of Webflow’s built-in app ecosystem
Content: Webflow, the low-code web development platform, has fully opened up its new app ecosystem, establishing a platform where third-party developers can integrate their applications directly into the Webflow designer. 
Webflow CTO Allan Leinwand shared insights about the vision for this ecosystem in an exclusive interview with VentureBeat, explaining that new APIs will allow apps to have a visible presence directly on the Webflow designer canvas. Additionally, Webflow has enhanced their backend APIs so apps can interact with Webflow forms, content and other data. The initiative has been a year in the making, with the aim to expose more functionality of Webflow designer and data models for developers to build deeply integrated apps.
“We have about 200,000 designers and companies that use Webflow and visual design to create these really fully customized professional websites without needing to code,” said Leinwand. “Part of that is we know we can’t write every piece of functionality for everyone else’s designers and companies. So we’ve been working on exposing the surface area of the designer, and of our core data models, for about a year now.”
Leinwand believes this combination of front-end and back-end access will be potent, as apps can put functionality right in front of designers while also connecting to Webflow sites. Drawing parallels to successful app marketplaces like Shopify (where he was former CTO), Leinwand envisions Webflow becoming a similar platform for designers. The ecosystem is open to all developers, whether targeting niche markets or larger ones.
“Developers realize that no-code development is the future, and they realize that people are moving into a no-code environment,” said Leinwand. “With generative AI, it even allows you to turn that up a notch, to really help generate some of that content and generate some of that design in an amazing way.”
Joining big names like Hubspot, Unspalsh and Typeform, one of the first apps to launch with this new ecosystem is Jasper AI, a marketing-focused AI writing assistant. Jasper AI will be able to generate relevant and contextual marketing copy content like blog posts or product descriptions within the Webflow designer, with changes saved directly into the Webflow backend. According to Leinwand, this seamless integration exemplifies how apps can leverage AI and other technologies to enhance the designer experience.
For developers looking to contribute to the ecosystem, Leinwand suggests focusing on addressing unmet needs within the design market using both the new frontend and backend APIs. As the Webflow ecosystem is just beginning, developers have the opportunity to get involved early. Leinwand invites developers to bring their ideas and start developing on the platform.
In a call with VentureBeat, Jasper AI President Shane Orlick discussed the company’s partnership with Webflow, emphasizing how gen AI is empowering creators. Jasper AI’s content creation platform, which businesses can use to generate high-quality marketing and advertising drafts at scale, is now accessible directly within the Webflow platform thanks to its API integration. This enables Webflow users to generate content directly in the app while building websites.
“It was really quick to get that vision lock,” Orlick said about early conversations about integrating the Jasper AI platform in Webflow. “We didn’t have the API. We had just started thinking about this. So once we had the API, it was really easy, because we actually have a solution that would fit nicely in their marketplace.”
Orlick believes that this partnership delivers more value for Webflow and drives adoption and engagement with their customers. Such partnerships enable the company to reach a new client-base, reducing the friction of AI adoption.
“We just want to meet the customers where they are and deliver the better experience,” said Orlick. “And because we’re only the app layer, we’re not raising $500 million to blow into training models [so] we’re able to just focus on the customer experience piece. That’s why Webflow is so exciting.”
Looking ahead, Orlick sees significant opportunities in serving large enterprise customers through customized AI templates, style guides and collaborative workflows. 
Yet, self-service and API-partner channels remain vital for driving leads to their core business. Orlick underscored how gen AI is transitioning from a novelty to an essential productivity tool. Partnerships like Webflow and Jasper that embed AI directly into creative workflows promise to unlock its full potential for both businesses and individuals.


Date: August 29, 2023 6:25 AM
Author: Press Release
Link: https://venturebeat.com/business/reveal-acquires-logikcull-and-ipro/
Title: Reveal Acquires Logikcull and IPRO
Content: 
Double Acquisition Introduces First Unified AI-Powered eDiscovery Platform Capable of Tackling Any Legal Case at Scale

CHICAGO–(BUSINESS WIRE)–August 29, 2023–
Reveal, a global provider of a category-leading AI-powered eDiscovery platform, announced today it has acquired both Logikcull and IPRO, two other leading eDiscovery players. Together, the three companies offer the first end-to-end eDiscovery platform that addresses matters of all sizes and for all legal teams, from solo legal practitioners to the largest enterprise. The transactions, valued at more than $1 billion, were funded by Reveal’s majority shareholder and leading software investment firm, K1 Investment Management.
The combination integrates Logikcull and IPRO’s unique capabilities with Reveal’s proven AI prowess to create an all-in-one hub of eDiscovery tools for matters of any size and scope. From self-service offerings for smaller cases to enterprise-grade solutions for complex legal challenges, Reveal now stands as the go-to partner for automating the practice of law.
“The acquisitions of Logikcull and IPRO build on Reveal’s growth strategy of integrating the best and most useful technologies into one platform so customers have greater choice and control over their eDiscovery workflows,” said Wendell Jisa, Founder & CEO of Reveal. “By bringing together the strengths of all three companies, including Logikcull’s intuitive, easy-to-use functionality and IPRO’s global reach and information governance tools, Reveal is now able to serve the diverse needs of clients across the legal spectrum, from SMB to mid-market and enterprise.”
In addition, the acquisitions will bring industry leading AI-powered eDiscovery solutions to an untapped global legal market. The company will now have employees stationed in more than two dozen countries, serving a customer base of over 4,000 clients.
“These two acquisitions are a continuation of our commitment to bring together the best technologies and people to propel the practice of law into a new era,” said Tarun Jain, Principal at K1 Investment Management. “With this combination, legal professionals will only have to look to one company to solve all their eDiscovery needs.”
By integrating Logikcull and IPRO into Reveal’s ecosystem, Reveal now offers the most advanced automation capabilities in the industry. Logikcull’s seamless, self-service functionality enables users to efficiently handle simpler cases in-house, while Reveal’s scalable, feature-rich platform helps tackle the most complex litigation matters. The combined suite covers every stage of the eDiscovery process, from data collection and processing to review and analysis, so legal experts can increase efficiency, reduce costs, and focus on higher-value tasks that better serve their clients.
Reveal’s expanded suite of solutions is available immediately, offering day-one benefits including:
Am Law 100 firms, Fortune 500 corporations, legal service providers, government agencies and financial institutions in more than 20 countries across five continents work collaboratively with Reveal to uncover insights faster and solve even the most complex legal challenges with the most advanced AI in the industry. For more information about Reveal, visit www.revealdata.com.
About Reveal
Reveal provides leading document review technology, underpinned by leading processing, visual analytics, and artificial intelligence, all seamlessly integrated into a single platform for eDiscovery and investigations. Our software combines technology and human guidance to transform structured and unstructured data into actionable insight. We help organizations, including law firms, corporations, government agencies, and intelligence services, uncover more useful information faster by providing a seamless user experience and patented AI technology that is embedded within every phase of the eDiscovery process.

View source version on businesswire.com: https://www.businesswire.com/news/home/20230829922415/en/
Media Contact: Liz Whelan312.315.0160liz@lwprconsulting.com


Date: August 29, 2023 6:10 AM
Author: Sean Michael Kerner
Link: https://venturebeat.com/data-infrastructure/rockset-to-boost-real-time-database-for-ai-era-with-44m-raise/
Title: Rockset to boost real-time database for AI era with $44M raise
Content: Database vendor Rockset is raising $44 million in new funding, as demand for its real-time indexing capabilities grows in the modern generative AI era.
The new fundraise follows the company’s series B round and brings total funding to date for the San Mateo, California-based company to $105 million. Icon Ventures led the new round, with participation from Glynn Capital, Four Rivers, K5 Global, Sequoia and Greylock.
Over the course of 2023 in particular, Rockset has been growing its technology, which uses the open-source RocksDB persistent key-value store originally created at Meta (formerly Facebook) as a foundation. In March, Rockset rolled out a platform update designed to make its real-time indexing database dramatically faster. That update was followed in April by vector embedding support to help enable AI use cases.
“We’re getting pulled in more and more into AI applications that are getting built, and that is a very, very big platform shift that’s happening,” Venkat Venkataramani, cofounder and CEO of Rockset, told VentureBeat. “Fundamentally what we do is real-time indexing, and it turns out applications also need real-time indexing on vector embeddings.”
The use of vector embeddings, stored in some form of vector database, has grown in 2023 with the rise of generative AI.
Vectors, numerical representations of data, are used to help power large language models (LLMs). There are a number of purpose-built vector databases, including Pinecone and Milvus, which join a growing number of existing database technologies including DataStax, MongoDB and Neo4j that support vector embeddings.
Inside Rockset, vector embeddings are supported as a data type known as an “array of floats” in the existing database. Venkataramani emphasized, however, that simply supporting vectors as a data type isn’t what’s particularly interesting to him.
Rather, what is more interesting from his perspective is how Rockset has now built a real-time index technology for the vector embeddings. The index provides a logical key for enabling search on a given set of data. Having the index updated in real time is critical for certain production use cases requiring the most updated information possible.
As it turns out, the same basic approach that Rockset has built for real-time indexing of metadata also works well for vectors. Having a real-time index that can query both regular data and vectors is useful for modern AI applications, according to Venkataramani.
“Every AI application we were dealing with doesn’t only work with vectors. There are always all these other database metadata fields associated with every one of them — and the application needs to query on all of them,” he said.
At the foundation of Rockset’s real-time database is the RocksDB data store, which the company has extended with the RocksDB Cloud technology.
Venkataramani explained that Rockset has developed a number of advanced techniques with RocksDB Cloud that help accelerate indexing for all data types. He noted that RocksDB Cloud now has an approximate nearest neighbor (ANN) indexing implementation, which is critical to enabling real-time search on vector data.
“Now, like any other index in Rockset, once you build a similarity ANN index for a vector embeddings column, it’s always up-to-date,” Venkataramani said. “It just automatically keeps itself up-to-date across inserts, updates and deletes.”
Rockset also integrates a distributed SQL engine for fast data queries. Venkataramani noted that the company’s SQL engine is now able to execute real-time queries across all supported data types on the database.
“You can now literally, in a single SQL query, do a whole bunch of filters and joins and aggregations, and also use a vector embedding to do ranking relevance in a similarity search use case,” he said. “A single SQL query is extremely efficient and very, very fast, because the SQL engine is built to power applications and not analysts that are waiting for reports.”
Looking forward, Venkataramani expects that there will be a lot more development of AI capabilities in Rockset. Among the future capabilities he’s looking forward to is support for GPU acceleration to further speed queries for LLMs and generative AI use cases.
“This industry is just getting started. This platform shift is not a fad; this is going to be a core part of every application,” he said.


Date: August 29, 2023 5:26 AM
Author: Press Release
Link: https://venturebeat.com/business/travelshift-secures-10-million-usd-capital-raise/
Title: Travelshift Secures $10 Million USD Capital Raise
Content: REYKJAVIK, Iceland–(BUSINESS WIRE)–August 29, 2023–
Travelshift, the leading online travel agency (OTA) in Iceland has raised $10 million USD of capital from existing shareholders, raising the total funding amount to $30 million USD.
This press release features multimedia. View the full release here: https://www.businesswire.com/news/home/20230829071571/en/
The financing represents a vote of confidence from Travelshift’s current investors in the company’s growth trajectory and future potential. According to Harshal Chaudhari, President and Chief Investment Officer at GE Investment Management Co., “We are proud to continue supporting Travelshift’s remarkable journey. The company’s unwavering commitment to innovation and customer satisfaction has been instrumental in its success, and we firmly believe in its potential to further disrupt the leisure travel industry.”
The latest funding round follows Travelshift’s recent launch of Guide to Europe, a travel platform that solves the Connected Trip for the European leisure travel market. This innovative service, which is powered by AI, allows travelers to book everything they need in one checkout and manage their entire journey in one app. It also gives travelers access to thousands of itineraries that have been optimized with AI, with what is now the world’s largest selection of vacation packages in Europe.
“We are thrilled to receive the continued support and trust from our existing shareholders,” said David Stewart, CEO of Travelshift. “This financing round enables us to accelerate our growth initiatives and continue to build the next generation of travel through innovative use and application of AI to deliver personalized and seamless travel experiences.”
Travelshift would like to express its sincere gratitude to its dedicated team, loyal customers, and steadfast shareholders for their continued support and belief in the company’s vision.
About Travelshift:
Travelshift is an leading Icelandic online travel agency (OTA) that specializes in providing technology-driven travel solutions. With over a decade of experience in the industry, Travelshift is committed to revolutionizing how people travel, offering innovative services and exceptional customer experiences.

View source version on businesswire.com: https://www.businesswire.com/news/home/20230829071571/en/
For media inquiries or further information, please contact:David StewartChief Executive OfficerEmail: dave@travelshift.com Phone: +354 791 9394


Date: August 29, 2023 5:00 AM
Author: Sean Michael Kerner
Link: https://venturebeat.com/ai/google-brings-new-ai-to-alloydb-and-database-migration-service/
Title: Google brings new AI to AlloyDB and database migration service
Content: At the Google Cloud Next conference today, Google will announce a series of AI-powered updates across its portfolio, including its database platforms.
Among the AI focused database announcements is the introduction of AlloyDB AI, which brings vector embeddings to the PostgreSQL compatible cloud database. The new vector embeddings will also be part of the AlloyDB Omni service which is entering public preview today, enabling users to run AlloyDB outside of the Google Cloud.
AlloyDB was first announced as a preview by Google in May 2022, providing both transactional and analytics capabilities with a PostgreSQL based database. The AlloyDB Omni platform was initially detailed by Google in March 2023, opening up the database to wider deployment options. 
AI will also help to enable database migrations from the Oracle database to AlloyDB, with the new Duet AI capability in the Google Database Migration Service. Beyond AlloyDB, Google is also introducing the new Cloud Spanner Data Boost capability that will enable data sorted in the Cloud Spanner database to be more easily queried with Google BigQuery. Duet AI is also making its way into Cloud Spanner to help enable natural language queries for data operations.
“We really see databases as helping to bridge the gap between large language models (LLMs) and AI apps,” Andi Gutmans, VP and GM for databases at Google, told VentureBeat. “Customers, especially enterprise customers, really like the ChatGPT experience, but ultimately they can’t have something that is too creative, and they really need to anchor their generative AI apps in the actual enterprise data.”
Vector enabled databases are increasingly critical to enabling databases to be data stores for AI applications.
While there are purpose built vector databases like Pinecone and milvus, existing database platforms such as PostgreSQL have also increasingly made efforts to support vectors. In PostgreSQL, the open-source pgvector technology is often used in the open-source database to support vectors. Some vendors such as Neon, which is a PostgreSQL compatible cloud database, have gone beyond pgvector, with Neon developing its own pg_embedding approach to supporting vectors in PostgreSQL.
Gutmans explained that with AlloyDB, Google is providing AI is a ‘superset’ of capabilities on top of pgvector. For one, the vector capabilities have been integrated deeply into the AlloyDB query processing engine.
“We’re probably smarter in how we execute the queries and how we optimize the queries,” said Gutmans. 
The other key element is added vector quantization support. Getmans explained that quantization enables AlloyDB users to significantly reduce vectors’ resource footprint in a running database, which helps improve and reduce storage costs.
Beyond just boosting pgvector, Gutmans emphasized that Google’s goal is to make it easier for developers to bring LLMs and enterprise data together.
AlloyDB AI integrates an easy way for developers to generate vector embeddings in several approaches. One approach is via an integration with Google’s Vertex AI to create vector embeddings. Additionally, Gutmans noted that Google is integrating a series of very lightweight embeddings models into the database. Integration with the open source LangChain technology is also part of the rollout, with the goal to help developers pull together data for AI powered applications.
“You should really think about [AlloyDB} as being all the different capabilities that developers need to be successful and bridging the gap between the data and LLMs,” said Gutmans.
PostgreSQL — and by extension, databases such as AlloyDB based on it — have long been positioned as potential alternatives to the Oracle database.
Google has been iterating on its own database migration service for its databases over the last several years. The database migration service aims to automatically map an existing Oracle database and its functions into an AlloyDB deployment. Gutmans explained that the existing technology is a rules-based model that meets many requirements, but it doesn’t solve for all use cases. That’s where the new Duet AI in the database migration service fits in.
The Duet AI in the database migration service enables developers to provide a prompt with manual hints on how they want to migrate certain parts of their Oracle database stored procedures. Gutmans said that Duet AI uses an LLM to generate the necessary code that can run across a cluster.
“There’s only so much you can do with a rules-based engine to migrate Oracle stored procedures to PostgreSQL,” said Gutmans. “Duet AI is basically an AI system for folks doing code conversion for that last mile that we couldn’t actually convert automatically.”


Date: August 29, 2023 5:00 AM
Author: Carl Franzen
Link: https://venturebeat.com/automation/dells-vc-arm-backs-industrial-edge-software-maker-iotechs-expansion-to-north-america/
Title: Dell’s VC arm backs industrial edge software maker IOTech’s expansion to North America
Content: You may not have heard of IOTech — yet. 
But that’s changing if Dell Technologies Capital has anything to say about it. The venture capital arm of the iconic PC brand has invested a new, undisclosed sum in IOTech, a U.K.-based firm that makes open-source software solutions for industrial edge devices. With the money, IOTech is targeting a major expansion of its business in the U.S. and North America. 
Think of all the sensors that the operator of a manufacturing plant might want to stick around their equipment to ensure it is running smoothly. Or the operator of a solar farm, who wants to know which cells are not performing well. Or the landlord of a building seeking to boost its environmental efficiency ratings. IOTech’s software is designed to work for all these types of use cases where physical capital can be monitored best by sensors at the “edge” feeding data about performance, state and conditions back into the cloud for decision-makers to review and act upon. 
This is what gives IOTech the “IOT” of its name: the Internet of Things — in this case, industrial things. Real-world devices equipped with sensors and analyzed using intelligent software.
The company already has a star-studded client list, including Accenture, EATON, Fluence Energy, Johnson Controls, King Steel and Schneider Electric.
While IOTech has to date built up most of its clientele in Europe and the Asia/Pacific region, the new funding round from Dell Technologies Capital — following its 2018 seed investment, according to Crunchbase — seeks to empower the company to make a bigger impact across the pond. 
Existing stakeholders, including SPDG — the holding company of the Périer-D’Ieteren family — Northstar Ventures and the Scottish Investment Bank are all contributing more. 
The fresh funds will empower the company to beef up its sales, marketing and pre-sales support. On top of that, IOTech has added field CTOs to its roster, further fortifying its expertise.
To help navigate this bold new chapter, David C. King, a seasoned hand in the industrial IoT world and former CEO of FogHorn, is joining IOTech’s board of directors. 
King is no stranger to steering companies toward success; he led FogHorn through three successful funding rounds before it was acquired by industrial automation giant Johnson Controls in 2022. 
Gregg Adkin, managing director with Dell Technologies Capital, believes that IOTech’s technology is like a gold mine for industrial data. 
As IOTech sets its sights on further U.S. growth, it’s also broadening its product portfolio beyond its current offering Edge Central, a control center that manages everything from connectivity to data processing of sensors and edge devices. 
This platform is a spin-off from EdgeX, a leading open-source data integration platform.
IOTech says its platform is not only adaptable, but future-proof, safeguarding investments well beyond the hardware life cycle.


Date: August 29, 2023 4:25 AM
Author: Press Release
Link: https://venturebeat.com/business/buildesg-adds-free-version-of-buildri-software-accelerating-the-path-toward-a-single-source-of-trust-for-responsible-investment-integration-in-the-alternative-investment-sector/
Title: BuildESG Adds Free Version of BuildRI Software, Accelerating the Path Toward a Single Source of Trust for Responsible Investment Integration in the Alternative Investment Sector
Content: 
The BuildRI Platform for LPs, Lenders and Investment Managers Emerges as the Network for Assessing, Supporting and Sharing Responsible Investment and ESG Information

NEW YORK–(BUSINESS WIRE)–August 29, 2023–
After launching its award-winning ESG operating platform in 2022, BuildESG, a leader in the responsible investment reporting landscape, is delighted to announce the launch of a free version of its BuildRI software. Tailored to meet the needs of alternative investment managers in private equity, venture capital and private debt and their key stakeholders, BuildRI aims to make responsible investment integration more standardized, accessible and actionable.
“In a financial landscape where responsible investment practices are taking center stage, the need for a powerful, yet easy-to-use platform for the alternative investment sector is greater than ever,” said James Lindstrom, CEO of BuildESG. Mr. Lindstrom continued, “The free BuildRI platform provides the essential tools for an alternative investment manager to launch, manage and report on its responsible investment program consistent with leading frameworks and standards.”
Supports Launch and Sharing of Responsible Investment Progress Across Limited Partner and Lender Network
To reinforce its commitment to facilitating responsible investment across the alternative investment industry, BuildRI offers free portals not just for investment managers, but also for their portfolio companies, limited partners and lenders. These dedicated portals enable sharing of content, ratings and data, serving as a centralized hub for collaborative responsible investment.
Feature-Rich Software Focused on Responsible Investment
To support a firm’s program launch, BuildRI offers a comprehensive set of features, including:
To get started with BuildRI, please contact info@buildesg.com or visit www.buildesg.com.
About BuildESG
BuildESG is a mission-driven organization providing a standardized Responsible Investment (RI) and Environmental, Social and Governance (ESG) platform and ratings system to investment managers, asset owners, limited partners and lenders. BuildESG’s platform product, BuildRI, is a single source of trust for investment managers and their limited partners, helping to assess, support and highlight managers and portfolio companies who prioritize responsible investment practices. BuildESG’s affiliates have provided strategic reporting services to the world’s leading organizations since 1999. To learn more, please visit www.buildesg.com.

View source version on businesswire.com: https://www.businesswire.com/news/home/20230829505166/en/
Information info@buildesg.com


Date: August 29, 2023 12:25 AM
Author: Press Release
Link: https://venturebeat.com/business/professor-j-mocco-to-join-protembis-board-of-directors/
Title: Professor J Mocco to Join Protembis’ Board of Directors
Content: 
Protembis announces the appointment of Professor J. Mocco to Board of Directors

AACHEN, Germany–(BUSINESS WIRE)–August 29, 2023–
Protembis GmbH (Protembis) a privately-held emerging cardiovascular medical device company, announced today the appointment of Professor J Mocco MD, MS, FAANS, FAHA of Icahn School of Medicine at Mount Sinai, NY, USA as an independent member of their Board of Directors.
Professor Mocco brings a wealth of clinical and academic experience as the Kalmon D. Post Professor and Senior Vice Chair of the Department of Neurological Surgery at Mount Sinai and is the immediate past President of the Society of Neurointerventional Surgery. Over his distinguished medical career spanning more than 20 years, he has authorship credits on over 600 publications. He is an editorial board member of Stroke since 2015 and has served or is serving as an associate editor of other journals including Neurosurgery, the Journal of Neurointerventional Surgery, and ISNR Stroke.
In his new role on the Board of Protembis, Professor Mocco will offer insights into the strategic direction of the company with his deep knowledge and clinical insights of endovascular stroke diagnosis and management. He will offer guidance on clinical strategies and new product development.
“I have been impressed by the Protembis team’s achievements in developing an elegant system to mitigate cerebral infarction risk during Transcatheter Aortic Valve Replacement” says Professor Mocco. He continues: “Their adaptive IDE clinical trial strategy is both rigorous and innovative. I am excited to offer my insights and guidance to the Board as this field evolves to treat future aortic stenosis patients who will have zero tolerance for brain injury as a potential procedural complication”.
Protembis has recently received FDA approval to conduct an IDE study aimed at demonstrating safety and efficacy of the ProtEmbo® Cerebral Protection System (“ProtEmbo”) during transcatheter aortic valve replacement (“TAVR”). The ProtEmbo® System is an intra-aortic filter device that protects the entire brain from embolic material liberated during the TAVR procedure. It is a low-profile system that shields all cerebral vessels, delivered through the left radial artery for optimal placement and stability. This is an ideal access site enabling physicians to avoid interference with TAVR equipment which is typically delivered through the femoral artery. The IDE study is designed as a multicenter randomized controlled trial in the USA and Europe.
“To have such an eminent expert with deep experience in the field of stroke joining our Board, is a strong indication of the Protembis solution for cerebral embolic protection’s impact in the future of TAVR” say Karl von Mangoldt and Conrad Rasmus Co-CEOs of Protembis. “I am delighted to welcome Professor Mocco to the Board of Protembis and to have his insights and strategic guidance as we generate confirmatory clinical data and further advance the field of cerebral embolic protection with the ProtEmbo System for complete cerebral protection” adds Dr Azin Parhizgar, Chairwoman of the Protembis Board of Directors.
About Protembis
Protembis is a privately-held emerging medical device company that has developed the ProtEmbo® Cerebral Protection System. The company strives to provide a simple and reliable solution to protect patients from brain injury during left-sided heart procedures, improving patient quality of life and reducing overall healthcare costs associated with brain injury during such procedures. The ProtEmbo® System is currently undergoing clinical investigations.

View source version on businesswire.com: https://www.businesswire.com/news/home/20230829785853/en/
Protembis GmbHConrad Rasmus & Karl von MangoldtCo-CEOs & Co-Founders+49(0)241 9903 3622management[at]protembis.comwww.protembis.com


Date: August 28, 2023 10:54 AM
Author: Sharon Goldman
Link: https://venturebeat.com/ai/openai-launches-long-awaited-chatgpt-for-enterprise-but-is-it-playing-catch-up/
Title: OpenAI launches long-awaited ChatGPT for Enterprise — but is it playing catch-up?
Content: Today OpenAI announced the launch of ChatGPT Enterprise, a platform that it hopes will entice large business users to invest in its growing software ecosystem. It is a long-awaited milestone that the company has been teasing since it launched ChatGPT last November — but is OpenAI now playing catch-up when it comes to bringing generative AI to the enterprise? 
After all, not only are many other companies targeting the same enterprise business audience with generative AI  — Cohere offers bespoke Large Language Model (LLM) options for the enterprise; Anthropic partnered with Scale AI to target the enterprise; and even Microsoft Azure has its own OpenAI service — but open source players are in the mix as well. Meta’s LLaMA 2, for instance, is available for commercial use. 
Still, as the first massively popular LLM interface geared toward consumers with 100 million monthly users at one point, OpenAI’s ChatGPT has already entered the pop culture lexicon (it was recently mentioned disparagingly at the U.S. Republican presidential debates). A new enterprise option may convince companies that were holding out for a product from arguably the most recognizable name in generative AI so far. 
The company says ChatGPT for Enterprise focuses on “enterprise-grade security,” unlimited access to GPT-4, extended context windows, advanced data analysis capabilities and customization options. 
Savvy enterprise technology leaders such as CTOs and heads of IT will be concerned about the security ramifications of ChatGPT for Enterprise. However, OpenAI offers two features to assuage doubts: “Customer prompts or data are not used for training models,” the company states. 
It also offers “data encryption at rest (AES-256) and in transit (TLS 1.2+),” and OpenAI says ChatGPT for Enterprise “has been audited and certified for SOC 2 Type 1 compliance (Type 2 coming soon).” As for data retention, OpenAI explains that “ChatGPT Enterprise securely retains data to enable features like conversation history. You control how long your data is retained. Any deleted conversations are removed from our systems within 30 days.” 
In a blog post outlining the new service offerings, OpenAI introduces several features of ChatGPT Enterprise that elevate its capabilities beyond the standard version. Users gain unlimited access to the faster GPT-4, enabling seamless and efficient interactions. The increased context window of 32k tokens allows for processing longer inputs and files, enhancing versatility. 
Advanced data analysis, previously known as Code Interpreter, empowers both technical and non-technical teams to analyze information in seconds. 
Additionally, shared chat templates enable collaborative workflows — with multiple team members able to engage in a single ChatGPT session — while free credits for OpenAI’s API offer customization options for organizations seeking a fully tailored LLM solution.
How much does it cost? OpenAI hasn’t specified, only sending VentureBeat the following email via a spokesperson: “It will depend on each company’s use case. Those interested should reach out to us for more information.” 
In its blog post, OpenAI said it “remains committed” to continuous improvement and expansion of ChatGPT Enterprise. It says long-term plans include upcoming features such as secure customization with company data integration, a self-serve ChatGPT Business offering for smaller teams and enhanced power tools for advanced data analysis and browsing. 
OpenAI said it aims to cater to specific roles within organizations, such as data analysts, marketers and customer support, by providing targeted solutions. 
Enterprise companies are moving slowly and deliberately to adopt generative AI if they have even started at all — whether because of concerns around enterprise data security and AI “hallucinations” or a lack of the necessary technology, talent and governance to implement generative AI successfully.
There’s certainly no doubt that executives want to access the power of generative AI. However, according to a recent KPMG study of U.S. executives, a solid majority (60%) of respondents said that while they expect generative AI to have an enormous long-term impact, they are still a year or two away from implementing their first solution.


Date: August 28, 2023 9:47 AM
Author: Sharon Goldman
Link: https://venturebeat.com/ai/finding-the-soul-of-ai-on-an-nyc-rooftop-at-sunset-the-ai-beat/
Title: Finding the soul of AI on an NYC rooftop at sunset  | The AI Beat
Content: As the senior reporter covering AI at VentureBeat, I often feel buried by the sheer scale of AI news, and occasionally left in the dust by the speed of the news cycle. I began my tenure in April 2022, the same week OpenAI launched its game-changing text-to-image generator DALL-E 2. From that moment on, it feels like I have barely stopped trying to catch up to the pace of development and trends in the space. I know I am far from alone — many in the AI community have shared with me that they feel the same way. 
I also work remotely in the New York City metro area, which I love. But mostly being on my own — interacting with my colleagues and editors on Slack, and chatting with sources on email, Twitter/X, Zoom, Teams, Meet, etc. — and living outside of San Francisco and Silicon Valley means only rarely getting a sense of the AI community in real life. Even the occasional conference is typically too overwhelming, with so many sessions, keynotes and workshops to attend, to get to meet people in a relaxed, casual way. 
Yet, I often long to do just that. There are so many issues and trends at play right now in AI — everything from potential risks of generative AI and regulatory efforts to workplace issues, research developments, debates around open and closed source AI. In addition to the move towards an AI-focused technology stack to help companies and enterprises begin to address possible use cases. 
Sometimes I just want to get a group together and, well, talk about it all. 
That’s why I was so amazed by the response I got to a simple, throwaway post on X back on August 10. Our editorial director, Michael Nuñez, was coming to New York City from San Francisco the week of August 25. Would anyone be up for a drink hang? Perhaps a dozen might meet us at a local bar to talk AI, I suggested. 
Instead, the response was overwhelming, on social media, email and in direct messages. Clearly, we needed a bigger boat — that is, a venue for an actual meetup. I reached out to William Falcon, CEO of Lightning AI, for a suggestion — he immediately offered up his building’s beautiful Manhattan rooftop. And we were off and running to quickly plan an AI event, called AI Loves NY, for the following week. In just a few days (thanks to the amazing team at Lightning AI, shout out to Surya!) we had more than 800 RSVPs, Michael was on a plane across the country, and we were ready to go. 
I can only describe the result as magical — a moment not just for the NYC tech community to come together, but also a welcome break from the normal networking routine of panels, workshops and discussions. I know plenty of Silicon Valley folks are at Burning Man this week, but for me, a laid-back evening with a Manhattan sunset and a view of the Empire State Building would have to do. 
I met programmers and researchers, startups and Big Tech folks, journalists and marketers, established brands and VCs. I felt the kind of energy and connection that is uniquely human — the antithesis of AI, really — and necessary, I think, to the success of any community or industry. 
Look, maybe I had a little too much wine. Perhaps I had a little too much adrenaline and excitement. But as cheesy as it may sound, I almost felt like I had discovered the soul of AI — no, not the endless talk about “sentience” or “AGI” — but the community of people involved in bringing this technology into the mainstream. 
I’ll pause for a minute, and acknowledge the thousands and thousands of human beings who often do not get acknowledged when it comes to thinking about the “magic” of AI — the veritable army of overseas, often exploited workers supporting the development of generative AI. Today’s article in the Washington Post about low-paid workers in the Philippines is just the latest example of a frustrating and nauseating trend that needs to be acknowledged more fully by companies and enterprises looking to profit from generative AI. 
But I can’t deny that on this Manhattan rooftop at sunset, on a late-summer evening with a slight breeze in the air, I felt a connection that I hope to experience more of: A vibrant, thriving AI community, in New York and beyond. 


Date: August 28, 2023 9:37 AM
Author: Louis Columbus
Link: https://venturebeat.com/security/honeywell-acquisition-cybersecurity-provider-manufacturing-sector-iot-vulnerabilities/
Title: Honeywell’s acquisition of cybersecurity provider sets sights on manufacturing sector’s deep IoT vulnerabilities
Content: The manufacturing sector is rife with unprotected Internet of Things (IoT) sensors and devices, many of them integrated into enterprises’ mission-critical systems. The resulting gaps make operations technology (OT) and information technology (IT) networks vulnerable to devastating cyberattacks.
Visibility is key. Shivan Mandalam, director of product management for IoT security at CrowdStrike, told VentureBeat that “it’s essential for organizations to eliminate blind spots associated with unmanaged or unsupported legacy systems. With greater visibility and analysis across IT and OT systems, security teams can quickly identify and address problems before adversaries exploit them.”
Honeywell’s acquisition of Israel-based SCADAfence, a leading provider of OT and IoT cybersecurity solutions, is just one example of the manufacturing industry trying to catch up, close these gaps and defend against increasing numbers of ransomware attacks. 
Anything that stops a shop floor from operating can quickly cost a business millions of dollars. That’s why ransomware attacks on manufacturers generate millions in payouts. Hundreds of manufacturers pay ransomware demands without disclosing that fact to customers. 
Gartner predicts that the financial impact of cyber-physical system (CPS) attacks will reach more than $50 billion by 2023. Recovery from a typical manufacturing breach costs $2.8 million. Not only that: Nearly nine in 10 manufacturers that have suffered a ransomware attack or breach have also had their supply chains disrupted.  
Honeywell’s SCADAfence acquisition provides the manufacturing giant “with additional technology and expertise that help accelerate our innovation roadmap … and support rapidly evolving customer requirements,” Michael Ruiz, GM of Honeywell Cybersecurity Services, said in a recent interview with VentureBeat.
The acquisition will deliver an integrated platform to manufacturers, process industries and infrastructure providers at a time when attacks are escalating. 
“SCADAfence is an ideal complement to Honeywell’s OT cybersecurity portfolio, and when combined with the Honeywell Forge Cybersecurity+ suite, it enables us to provide an end-to-end solution with applicability to asset, site and enterprise across key Honeywell sectors,” said Ruiz. 
Key focus areas include asset discovery, threat detection and compliance management, he told VentureBeat. “Our plan is to have the SCADAfence product portfolio integrate into the Honeywell Forge Cybersecurity+ suite within Honeywell Connected Enterprise, Honeywell’s fast-growing software arm with a strategic focus on digitalization, sustainability and OT cybersecurity SaaS offerings and solutions.” 
Known for its process analysis and integration expertise, Honeywell is concentrating on how it can make the most of its strengths in these areas and achieve scale quickly with the new acquisition. 
“This integration will enable Honeywell to provide an end-to-end enterprise OT cybersecurity solution to site managers, operations management and CISOs seeking enterprise security management and situational awareness,” said Ruiz. 
SCADAfence CEO Elad Ben Meir also commented on the synergies between the companies. “We are thrilled to join Honeywell as we work towards fulfilling our mission of empowering industrial organizations to operate securely, reliably and efficiently,” Ben Meir said in a press release. “This combination creates a significant opportunity for growth, allowing us to combine our top-tier OT cybersecurity products with one of the world’s leading companies in industrial software.”  
The deal expands Honeywell’s cybersecurity center of excellence in Tel Aviv, where SCADAfence is headquartered. Ruiz told VentureBeat that one of the most valuable aspects of the acquisition is that Honeywell will be able to “nearly double our research and development for OT cybersecurity, probably becoming one of the larger OT cybersecurity research and development organizations out there.”
The IBM Security X-Force Threat Intelligence Index found that manufacturing is the most attacked industry worldwide: The sector accounted for 23% of all ransomware attacks last year. More than six in 10 breach attempts on manufacturers first targeted OT systems essential to manufacturing operations.
Research firm Dragos predicts that ransomware attacks on industrial organizations will accelerate this year. Dragos’ most recent Industrial Ransomware Attack Analysis from Q2 2023 found that 47.5% of ransomware attacks tracked globally impacted industrial organizations and infrastructure in North America, an increase of 27% over the last quarter.
All told, seven out of 10 ransomware attacks in Q2 were aimed at manufacturing, followed by the industrial control systems (ICS) equipment and engineering sector, which accounted for16% of attacks.
The rapid rise in Fileless malware attacks reflects this trend. Fileless malware is designed to evade detection by cloaking its presence using legitimate tools. Kurt Baker, senior director of product marketing for CrowdStrike Falcon Intelligence, writes that “fileless malware is a type of malicious activity that uses native, legitimate tools built into a system to execute a cyber-attack. Unlike traditional malware, fileless malware does not require an attacker to install any code on a target’s system, making it hard to detect. This fileless technique of using native tools to conduct a malicious attack is sometimes referred to as living off the land or LOLbins.”
Security providers are upping their games. 
Last year at Fal.Con 2022, CrowdStrike augmented Falcon Insight, launching Falcon Insight XDR and Falcon Discover for IoT that target security gaps in and between industrial control systems (ICSs). 
Ivanti, for its part, has successfully launched four solutions for IoT security: Ivanti Neurons for RBVM, Ivanti Neurons for UEM, Ivanti Neurons for Healthcare — which supports the Internet of Medical Things (IoMT) — and Ivanti Neurons for IIoT based on the company’s Wavelink acquisition, which secures Industrial Internet of Things (IIoT) networks.
Other leading providers offering IoT cybersecurity solutions include AirGap Networks, Absolute Software, Armis, Broadcom, Cisco, CradlePoint, CrowdStrike, Entrust, Forescout, Fortinet, Ivanti, JFrog and Rapid7.
Airgap Networks has created one of the most innovative approaches to closing the OT-IT gap. Its   Zero Trust Firewall (ZTFW) combines agentless microsegmentation, secure access for critical assets and network and asset intelligence. Airgap’s unique approach provides its customers with the option of fully segmenting legacy servers, ICS, IoT and private 5G endpoints. The platform can also integrate into a running network without agents, hardware upgrades or major device changes. 
VentureBeat interviewed Ritesh Agrawal, CEO of Airgap Networks, immediately following its launch of ThreatGPT, the company’s ChatGPT integration with the Airgap Zero Trust Firewall. Agrawal told VentureBeat: “Because ThreatGPT is fully integrated into the core of the ZTFW architecture, our customers can use all available data to train the models. I believe we are first to market with this.” 
ThreatGPT uses graph databases and GPT-3 models to help SecOps teams gain new threat insights. The GPT-3 models analyze natural language queries and identify security threats, while graph databases provide contextual intelligence on endpoint traffic relationships. 
Agrawal told VentureBeat that, “IoT puts a lot of pressure on enterprise security maturity. Extending zero trust to IoT is hard because the endpoints vary, and the environment is dynamic and filled with legacy devices.”
Asked how manufacturers and other high-risk industry targets could get started, Agrawal advised that “accurate asset discovery, microsegmentation and identity are still the right answer, but how to deploy them with traditional solutions when most IoT devices can’t accept agents? This is why many enterprises embrace agentless cybersecurity like Airgap as the only workable architecture for IoT and IoMT.”


Date: August 28, 2023 9:24 AM
Author: Aoibhinn Mc Bride, Jobbio
Link: https://venturebeat.com/programming-development/this-is-how-ai-will-shape-early-career-tech-jobs/
Title: This is how AI will shape early-career tech jobs
Content: Move over dial-up internet.
From now on, the generational divide within the workplace looks set to revolve around remembering the days before AI dominated almost every aspect of our work lives, and the period after.
In fact, according to a recent study by McKinsey, generative AI is now being used by 79% of all workers and 22% use it regularly to complete their everyday work tasks.
Couple this with the fact that AI is predicted to eliminate 83 million global jobs by 2027 and it’s easy to see why for those starting out in their careers, AI will not only shape their day-to-day but have a massive impact on their overall career trajectory.
This is probably why educational institutions are the second largest cohort to utilize ChatGPT within the workplace after tech, and colleges are racing to build state-of-the-art AI faculties to not only facilitate student demand but address the skills gap which has seen 75% of companies struggle to recruit qualified talent. 
At the University of Albany, 27 new faculty members specializing in artificial intelligence have been hired “to incorporate elements of AI teaching and research across all academic programs.”
Elsewhere, the University of Southern California has invested more than $1 billion in its AI initiative which included courses in advanced computation, quantum computing, AI and ethics.
And Purdue University has established its Institute for Physical AI (IPAI), the first of its kind in the U.S., which will focus on areas including robotics, deep fake detection and AI-based manufacturing among others.
So, what does this mean for those who fall into the “days before AI” camp?
According to the World Economic Forum (WEF), 50% of all employees will need reskilling by 2025 as the adoption of technology increases.
And while keeping hard skills fresh and up-to-date is imperative, there’s also been a renewed focus on the importance of soft skills.
As such, the WEF has also identified the top 10 skills of tomorrow and critical thinking and problem-solving top the list along with creativity, leadership, resilience, flexibility and stress tolerance — all of which machines are yet to master.
Whatever stage you’re at in your working life, the VentureBeat Job Board is the perfect place to start your search if you’re looking for a way to futureproof your career prospects. It features thousands of jobs in companies that are actively hiring, like the three below.
NVIDIA is seeking a Senior Deep Learning Algorithms Software Engineer to join its deep learning algorithms team to develop and commercialize AI solutions related to natural language processing, computer vision, speech, text and recommendation systems. Day-to-day you’ll be developing algorithms for deep learning, data analytics, machine learning or scientific computing, constructing and curating large problem specific datasets, analyzing and improving the performance of graphic processing unit implementations and publishing state-of-the-art results on Github and scientific publications. View more details here.
Capgemini Engineering is an integral part of the Capgemini Group which addresses business needs, from strategy and design to operations, fuelled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. As Software Engineer Lead, you will design, develop and unit test APIs and applications, collaborate with multi-functional teams (such as architects, testers, product managers) and deliver, contribute to design architectural discussions, help triage, identify root cause for issues and implement solutions and document high and low level designs, sequence diagrams and flow diagrams etc. See the full job description here.
Project Starline from Google combines advances in hardware and software to enable friends, families and co-workers to feel together, even when they’re cities (or countries) apart. In this Senior Product Manager role, you will work cross-functionally to guide products from conception to launch by connecting the technical and business worlds. You can break down complex problems into steps that drive product development. You’ll need a Bachelor’s degree or equivalent practical experience, eight years’ of experience in product management, consulting, co-founder or related technical role, and three years’ of experience in building and shipping technical products. Get more information here.
Discover thousands more opportunities in tech on the VentureBeat Job Board.


Date: August 28, 2023 8:47 AM
Author: Shubham Sharma
Link: https://venturebeat.com/enterprise-analytics/conversight-raises-9m-to-accelerate-data-analytics-with-generative-ai/
Title: ConverSight raises $9M to accelerate data analytics with generative AI
Content: Indianapolis-based ConverSight, a startup that seeks to leverage generative AI to provide better and faster data analytics to enterprises, today announced a $9 million series A round. 
The company said it will use the new funding to fuel go-to-market efforts and expand its product with new features, including what it calls “MarketSpace.”
Surface Ventures led the investment, with participation from Techstars, Augment Ventures, Elevate Ventures and multiple earlier backers returning. 
With it, ConverSight has raised more than $15 million to date, and the new infusion comes at a critical time, as a number of data infrastructure vendors also seek to use AI large language models (LLMs) to make it easier for teams to control, access and configure their data. 
“While many companies have incorporated generative AI into data analytics over the past year, ConverSight has been working on this problem for more than 5 years and we believe has a critical head start in ensuring accuracy for mission-critical analytics,” Gyan Kapur, co-managing partner at Surface VC, said in a statement. “We see the potential for ConverSight’s platform to continue to extend its market leadership…”
Traditionally, businesses relied on developer-generated reports and dashboards to get the visualizations they needed to perform analysis and make decisions. The process was pretty static and took a lot of time, especially considering the pre-analytic steps of data integration, storage, etc.
ConverSight, founded in 2017, created a self-service, all-in-one solution for enterprise customers, covering the whole process end to end, right from data integration and storage to data transformation, analysis and reporting.
“The platform offers the necessary data Infrastructure, data sourcing and data storage (cloud neutral) foundation followed by a thorough data exploration and data transformation process. Once that’s done, the data science and data consumption (visualization) layer follow up, which is rounded off with conversational AI and NLP functionality to drive a totally unique and contextual experience down to the user role, level and department,” Ganesh Gandhieswaran, CEO and cofounder of ConverSight, told VentureBeat.
The conversational AI experience, dubbed Athena, is delivered with the company’s homegrown LLM and patented knowledge graph. It works just like OpenAI’s ChatGPT, where users simply put in their queries through voice or chat and the bot provides the required answer, complete with necessary details and context. 
“Over time, the AI capabilities enable Athena to anticipate questions or insights needed to proactively push insights and reports to end users. It develops a contextual understanding to paint a real-time picture of your business followed by recommendations and automated actions to help teams meet goals and improve decision-making,” Gandhieswaran added.
This, in a nutshell, makes the entire process of analytics consumption more on-demand and dynamic than ever.
ConverSight has already established a strong footprint with over 200 enterprise customers and dedicated solutions catering to functions like supply chain, services, sales and procurement. With this round, the company plans to accelerate its go-to-market teams and efforts as well as build out new product innovations to transform how companies consume data analytics. 
This, Gandhieswaran said, will include a new MarketSpace, which will be enterprise teams’ go-to place to discover a curated list of commonly used resources and solution templates. 
“Need to supercharge your inventory management? Try out the inventory optimization resource. Looking to enhance supply chain visibility? The supply chain visibility resource might be just what you need. Each resource comes with detailed explanations of its benefits for subscribers. You can easily subscribe and access these resources for a nominal fee. While payment integration is in the works, for now, a simple subscription process will notify us when you’re ready to dive in,” the CEO explained.
Along with ConverSight, a number of data players are using generative AI to transform how teams interact with their data and consume insights. 
Data lakehouse vendor Databricks, for one, has launched LakehouseIQ to allow anyone in an organization to search, understand and query internal corporate data by simply asking questions in plain English. Similarly, ThoughtSpot has launched Sage, a new LLM-driven search experience that provides enterprise users with a chat experience where they can type natural language prompts to query data for text or visual insights. Dremio and Tableau have also taken similar steps.
According to McKinsey, generative AI, with its promise to unlock new sources of value and innovation, could add up to $4.4 trillion to the global economy. 


Date: August 28, 2023 7:25 AM
Author: Press Release
Link: https://venturebeat.com/business/qualiti-ai-secures-6-5-million-seed-funding-to-ensure-software-engineers-never-need-to-test-again/
Title: Qualiti.ai Secures $6.5 Million Seed Funding to Ensure Software Engineers Never Need to Test Again
Content: LEHI, Utah–(BUSINESS WIRE)–August 28, 2023–
Qualiti.ai, a Utah-based software test automation solution, announced the closing of a $6.5 million Seed round today. Sierra Ventures led the funding round, with participation from Epic Ventures.
Founded by industry veterans Peter West (CEO) and Jeff Handy (COO), Qualiti uses AI to test any software product without human input. Qualiti can be set up in just 15 minutes, after which a full test suite will be created without human effort. Qualiti’s AI handles all new and ongoing test authoring and maintenance. Qualiti takes care of it 100% hands-off, adding new tests, maintaining existing tests, triaging results in real-time, and reporting any bugs found, all without human oversight or time, thus allowing it to replace up to 30% of a company’s engineering budget.
With a rapidly growing customer base (340% MoM and growing), Qualiti will use the funding to expand sales and their world-class engineering team. Qualiti is poised to be the only tool a company will need for all of its QA. With engineers getting near-instant feedback on their applications as they push code, Qualiti will change the way software is developed forever.
“Most AI companies today are wrappers around chat-gpt and most seem to just be glorified grammar checkers. Even the more interesting applications tend to just be a tool to help you do what you’re already doing. It’s about time that AI does the work for us, and Qualiti has made that happen for testing – and we’re the only ones who have truly made that, a truly hands-off no-human-work-needed AI managed solution, happen in testing,” stated Qualiti.ai CEO Peter West.
“Qualiti has an opportunity to disrupt the test automation industry, which is in desperate need of true innovation,” said Sierra Ventures Managing Director Mark Fernandes. “The rapid adoption of their solution by developers at very selective companies is evidence that the team has hit a nerve.”
About Qualiti.ai:
Qualiti is a generative AI-powered software solution for testing automation. It builds test automation suites without any human input. Qualiti ensures applications are covered by writing high-quality automated tests. It will then execute tests, provide advanced triage, and alert team members of any failures. The company is based in Lehi, Utah. For more information, visit https://qualiti.ai/.
About Sierra Ventures:
Sierra Ventures is a leading early-stage venture capital firm focused on the future of enterprise technologies. With four decades of experience and over $2 billion of assets under management, Sierra has created a vast network of successful entrepreneurs, Global 1000 CXOs, operational executives, and deep domain experts, providing a platform for entrepreneurs around the world. To connect with Sierra, visit https://www.sierraventures.com/.
About Epic Ventures:
Epic Ventures is a premier early-stage venture firm whose mission is to back entrepreneurs and companies positioned to lead the technologies and economy of tomorrow. With more than 15 IPO’s and several dozen acquisitions, people, products, and passion drive our time and resources. To connect with Epic, visit https://epicvc.com/.
For inquiries, please reach out to Jeff Handy at jhandy@qualiti.ai.

View source version on businesswire.com: https://www.businesswire.com/news/home/20230828402881/en/
Jeff Handyjhandy@qualiti.ai


Date: August 28, 2023 6:00 AM
Author: Sharon Goldman
Link: https://venturebeat.com/ai/doordash-launches-ai-powered-voice-ordering/
Title: DoorDash launches AI-powered voice ordering
Content: For those who prefer the old-school method of ordering takeout — over the phone — DoorDash has your back. Today the food delivery platform launched AI-powered voice ordering that answers calls and provides customers with curated recommendations. 
According to the company’s 2023 Restaurant Online Ordering Trends Report, one in five customers prefer ordering takeout via phone — but up to 50% of customer calls currently go unanswered, resulting in potential revenue losses. 
“Customers expect more from restaurateurs, and in return, restaurateurs expect even more technology-forward solutions from us — including support for phone channels to meet customers where they’re ordering,” said Rajat Shroff, head of product and design at DoorDash, in a press release. “Supporting operators by capturing customer demand through investments in our voice product is one way we’re delivering more and enabling our partners to grow their business.”
AI-powered voice ordering is becoming big business across the restaurant industry: In May, AI company SoundHound announced a voice AI partnership with Oracle for a point-of-sale technology integration that enables consumers to dictate their orders at the drive-thru. 
At the same time, Uber Eats launched an Amazon Alexa integration that allows consumers to track orders through their Amazon Echo devices. 
According to DoorDash, the new voice AI offering is based on feedback from restaurant partners and on customer preferences. “Coupling AI with best-in-class live agents ensures customer calls will be answered with little to no wait, enabling operators to capture the unmet customer demand,” said the press release. 
In addition, during restaurant peak times, AI can answer calls to allow employees to focus on hospitality to in-store customers. The AI offering also allows returning customers to quickly reorder their favorite meal, while live agents can jump in at any time. 
Of course, DoorDash was built on AI: According to a 2017 VentureBeat article, Tony Xu, DoorDash’s cofounder, decided in 2013 to build the company’s food-delivery software on artificial intelligence. 
“DoorDash at the end of the day has to be a phenomenal measurement and data business,” Xu said at MB 2017. “There’s a lot of information in the software world and in the physical world. From day one, our thinking was to create a business to bridge the two.”
Machine learning has long helped DoorDash with logistics, navigating “dashers” to the right places at the right time. It can also recalibrate a restaurant’s offerings when a worker has called in sick, and offer personalized recommendations. 


Date: August 28, 2023 5:00 AM
Author: Shubham Sharma
Link: https://venturebeat.com/ai/salesforce-survey-flags-ai-trust-gap-between-enterprises-and-customers/
Title: Salesforce survey flags AI trust gap between enterprises and customers
Content: Regardless of the sector, companies of all sizes are moving to implement large language models (LLMs) into their workflows — to drive efficiencies and deliver better customer experiences. 
However, a new Salesforce survey found that this so-called “race” to build out generative AI as soon as possible might come at the cost of a “trust gap” with customers. The company’s sixth State of the Connected Customer report, featuring data gathered between May 3 and July 14, 2023, surveyed more than 14,000 consumers and business buyers across 25 countries. It shows that even though customers and buyers are generally open to the use of AI for better experiences, a large number of folks still don’t trust their companies to use AI ethically. 
The findings highlight a major issue that enterprises implementing gen AI need to address in order to deliver the best possible AI experiences to their customers and keep their business growing. 
While the concept of “trust” seems simple at first, the reality is it can be very complex and multifaceted. For instance, a person might trust the quality of a company’s product but not its efforts toward sustainability. Similarly, they might not trust the company to protect their data.
For AI, trust is rooted in ethical principles where the system adheres to well-defined guidelines regarding certain fundamental values like individual rights, privacy and non-discrimination. According to the Salesforce survey, this is where the problem may appear.
Out of the 14,000 respondents surveyed, 76% said they trust companies to make honest claims about their products and services but nearly 50% claimed they do not trust them to use use AI ethically. 
While they highlighted multiple concerns, the most prominent challenges they reported were the lack of transparency and the lack of a human in the loop to validate the output of the AI — demanded by more than 80%. Just 37% of the respondents said they actually trust AI to provide as accurate responses as a human would. 
Other concerns they flagged included data security risks, the possibility of bias (where the system may discriminate against a gender, for example), and unintended consequences for society.
Among the survey respondents, business buyers expressed more optimism towards AI than consumers did, with 73% of them noting they are open to the use of this technology by businesses for better experiences. In contrast, just 51% of consumers shared the same view.
What’s intriguing here is that the general sentiment still seems to have dipped since 2022 when generative AI — capable of producing new content in a matter of seconds — came onto the scene. Last year, as many as 82% of business buyers and 65% of consumers were open to the use of AI for better experiences, Salesforce said. 
Notably, on the vendor side, optimism continues to remain sky-high, with a majority of professionals at the forefront of customer engagement (from IT and marketing to sales and service teams) saying generative AI will help their companies serve customers better. 
Even though companies cannot stop AI implementation — after all, they have to stay relevant in today’s dynamic environment — the survey found that a few key steps can help them win consumers’ trust and make sure they are on board with the shift.
The first, as mentioned above, would be ensuring a greater level of transparency and human validation of AI’s outputs. More than half of the customers surveyed said this would boost their trust. Beyond that, 49% of respondents said companies should focus on giving them more control of where and how AI is applied in engagement — such as opportunities to opt out; 39% called for third-party ethics review; and 36% sought government oversight. 
Other suggested steps included industry standards for AI implementation, solicitation of customer feedback on how to improve AI’s use, training on diverse datasets and making the underlying algorithms publicly available.
“As brands find new ways to keep up with rising customer expectations, they must also consider diverse viewpoints among their (targeted) base,” Michael Affronti, SVP and GM for Salesforce Commerce Cloud, said in a press release. 
“Leading with strong values and ethical use of emerging technologies like generative AI will be a key indicator of future success,” he added.


Date: August 27, 2023 10:10 AM
Author: Peter Klimek, Imperva
Link: https://venturebeat.com/security/why-generative-ai-is-a-double-edged-sword-for-the-cybersecurity-sector/
Title: Why generative AI is a double-edged sword for the cybersecurity sector
Content: Much has been made of the potential for generative AI and large language models (LLMs) to upend the security industry. On the one hand, the positive impact is hard to ignore. These new tools may be able to help write and scan code, supplement understaffed teams, analyze threats in real time, and perform a wide range of other functions to help make security teams more accurate, efficient and productive. In time, these tools may also be able to take over the mundane and repetitive tasks that today’s security analysts dread, freeing them up for the more engaging and impactful work that demands human attention and decision-making. 
On the other hand, generative AI and LLMs are still in their relative infancy — which means organizations are still grappling with how to use them responsibly. On top of that, security professionals aren’t the only ones who recognize the potential of generative AI. What’s good for security professionals is often good for attackers as well, and today’s adversaries are exploring ways to use generative AI for their own nefarious purposes. What happens when something we think is helping us begins hurting us? Will we eventually reach a tipping point where the technology’s potential as a threat eclipses its potential as a resource?
Understanding the capabilities of generative AI and how to use it responsibly will be critical as the technology grows both more advanced and more commonplace. 
It’s no overstatement to say that generative AI models like ChatGPT may fundamentally change the way we approach programming and coding. True, they are not capable of creating code completely from scratch (at least not yet). But if you have an idea for an application or program, there’s a good chance gen AI can help you execute it. It’s helpful to think of such code as a first draft. It may not be perfect, but it’s a useful starting point. And it’s a lot easier (not to mention faster) to edit existing code than to generate it from scratch. Handing these base-level tasks off to a capable AI means engineers and developers are free to engage in tasks more befitting of their experience and expertise. 
That being said, gen AI and LLMs create output based on existing content, whether that comes from the open internet or the specific datasets that they have been trained on. That means they are good at iterating on what came before, which can be a boon for attackers. For example, in the same way that AI can create iterations of content using the same set of words, it can create malicious code that is similar to something that already exists, but different enough to evade detection. With this technology, bad actors will generate unique payloads or attacks designed to evade security defenses that are built around known attack signatures.
One way attackers are already doing this is by using AI to develop webshell variants, malicious code used to maintain persistence on compromised servers. Attackers can input the existing webshell into a generative AI tool and ask it to create iterations of the malicious code. These variants can then be used, often in conjunction with a remote code execution vulnerability (RCE), on a compromised server to evade detection. 
Well-financed attackers are also good at reading and scanning source code to identify exploits, but this process is time-intensive and requires a high level of skill. LLMs and generative AI tools can help such attackers, and even those less skilled, discover and carry out sophisticated exploits by analyzing the source code of commonly used open-source projects or by reverse engineering commercial off-the-shelf software.  
In most cases, attackers have tools or plugins written to automate this process. They’re also more likely to use open-source LLMs, as these don’t have the same protection mechanisms in place to prevent this type of malicious behavior and are typically free to use. The result will be an explosion in the number of zero-day hacks and other dangerous exploits, similar to the MOVEit and Log4Shell vulnerabilities that enabled attackers to exfiltrate data from vulnerable organizations. 
Unfortunately, the average organization already has tens or even hundreds of thousands of unresolved vulnerabilities lurking in their code bases. As programmers introduce AI-generated code without scanning it for vulnerabilities, we’ll see this number rise due to poor coding practices. Naturally, nation-state attackers and other advanced groups will be ready to take advantage, and generative AI tools will make it easier for them to do so.  
There are no easy solutions to this problem, but there are steps organizations can take to ensure they are using these new tools in a safe and responsible way. One way to do that is to do exactly what attackers are doing: By using AI tools to scan for potential vulnerabilities in their code bases, organizations can identify potentially exploitative aspects of their code and remediate them before attackers can strike. This is particularly important for organizations looking to use gen AI tools and LLMs to assist in code generation. If an AI pulls in open-source code from an existing repository, it’s critical to verify that it isn’t bringing known security vulnerabilities with it. 
The concerns today’s security professionals have regarding the use and proliferation of generative AI and LLMs are very real — a fact underscored by a group of tech leaders recently urging an “AI pause” due to the perceived societal risk. And while these tools have the potential to make engineers and developers significantly more productive, it is essential that today’s organizations approach their use in a carefully considered manner, implementing the necessary safeguards before letting AI off its metaphorical leash. 
Peter Klimek is the director of technology within the Office of the CTO at Imperva.

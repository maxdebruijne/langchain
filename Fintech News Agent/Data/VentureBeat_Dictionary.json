{"OpenAI wants teachers to use ChatGPT for education": {"Date": "August 31, 2023 3:24 PM", "Author": "Carl Franzen", "Link": "https://venturebeat.com/ai/openai-wants-teachers-to-use-chatgpt-for-education/", "Content": "It\u2019s not only programming, journalism and content moderation that OpenAI is seeking to revolutionize with the use of its landmark large language models (LLMs) GPT-3, GPT-3.5 and GPT-4.\nToday, the company published a new blog post titled \u201cTeaching with AI\u201d that outlines examples of six educators from various countries, mostly at the university level though one teaches high school, using ChatGPT in their classrooms. \n\u201cWe\u2019re sharing a few stories of how educators are using ChatGPT to accelerate student learning and some prompts to help educators get started with the tool,\u201d the company writes. \nThe examples range from one educator using ChatGPT as a kind of educational role player, taking on the part of a debate rival or recruiter and engaging students in a dialog; to another teacher using ChatGPT for translation assistance for English-as-a-second-language students; to yet another having their students fact-check the information it generates.\nThe company also includes sample prompts developed by AI influencer and University of Pennsylvania Wharton School professor Ethan Mollick and his wife and fellow professor Lilach Mollick that assist teachers with lesson planning and even turn the default ChatGPT into an \u201cAI tutor\u201d for students. \nAsked by this VentureBeat author on X (formerly Twitter) if OpenAI paid Ethan Mollick for use of his and his wife\u2019s prompts, he responded in the negative: \u201cNo. I have never taken any money or compensation in any way from OpenAI, including token credits,\u201d adding \u201cIn this case, they used prompts and material we have already published.\u201d\nOf course, the issue of generative AI in the classroom \u2014 like with many topics related to the technology \u2014 has been fraught with controversy, especially with regards to students using it as a means of cutting corners or avoiding doing their own coursework, such as writing essays. \nIn fact, several schools, districts, and departments of education around the globe have already banned ChatGPT and added it to their internet network blocklists, although the New York City Public School  system did an about-face in May and moved to allow teachers to use ChatGPT as they see fit. \nOpenAI made headlines earlier this year by releasing an \u201cAI Text Classifier\u201d that was designed to allow anyone, including educators, to copy and paste in text and determine whether or not it was written by AI, but then ended up discontinuing it last month due to its \u201clow rate of accuracy.\u201d  \nToday, OpenAI elaborated on the issues with the Text Classifier in a new Educator FAQ (frequently asked questions), which is far more robust and arguably even more helpful for schools than its promotional blog post.\nAnswering the question of \u201cHow can educators respond to students presenting AI-generated content as their own?,\u201d OpenAI answers to say: \u201cWhile some (including OpenAI) have released tools that purport to detect AI-generated content, none of these have proven to reliably distinguish between AI-generated and human-generated content,\u201d and \u201cWhen we at OpenAI tried to train an AI-generated content detector, we found that it labeled human-written text like Shakespeare and the Declaration of Independence as AI-generated.\u201d\nIn addition, OpenAI admits: \u201cThere were also indications that it could disproportionately impact students who had learned or were learning English as a second language and students whose writing was particularly formulaic or concise.\u201d\nPlus, as the company points out, \u201ceven if these tools could accurately identify AI-generated content (which they cannot yet), students can make small edits to evade detection.\u201d\nInstead, OpenAI notes that some teachers have begun asking students to show their conversations with ChatGPT as a form of displaying their critical thinking skills. \nFurthermore, while OpenAI says that there is research supporting the fact that \u201cChatGPT can be a helpful tool, alongside teachers, for providing students with feedback,\u201d it does not link to this specific research, and says \u201cit is inadvisable and against our Usage Policies to rely on models for assessment decision purposes without a \u2018human in the loop.'\u201d\nIn other words \u2014 the idea of a teacher handing over most of their duties to ChatGPT is not in the cards yet, or likely the foreseeable future, and same with students and their coursework. \nStill, the company clearly wants to promote the idea that ChatGPT can be a useful new tool for both sides of the educational equation, teachers and students alike, joining the familiar classroom sights of pencils, notebooks, computers, and globes. "}, "5 ways CISOs can prepare for generative AI\u2019s security challenges and opportunities": {"Date": "August 31, 2023 10:03 AM", "Author": "Louis Columbus", "Link": "https://venturebeat.com/security/5-ways-cisos-can-prepare-for-generative-ai-security-challenges-and-opportunities/", "Content": "With generative AI tools like ChatGPT proliferating across enterprises, CISOs have to strike a very difficult balance: Performance gains versus unknown risks. Gen AI is delivering greater precision to cybersecurity but also being weaponized into new attack tools such as FraudGPT that advertise their ease of use for the next generation of attackers.\nSolving the question of performance versus risk is proving a growth catalyst for cybersecurity spending. The market value of gen AI-based cybersecurity platforms, systems and solutions is expected to rise to $11.2 billion in 2032 from $1.6 billion in 2022. Canalys expects generative AI to support more than 70% of businesses\u2019 cybersecurity operations within five years.\nGen AI attack strategies are focused on getting control of identities first. According to Gartner, human error in managing access privileges and identities caused 75% of security failures, up from 50% two years ago. Using gen AI to force human errors is one of the goals of attackers.\nVentureBeat interviewed Michael Sentonas, president of CrowdStrike, to gain insights into how the cybersecurity leader is helping its customers take on the challenges of new, more lethal attacks that defy existing detection and response technologies.\nSentonas said that \u201cthe hacking [demo] session that [we] did at RSA [2023] was to show some of the challenges with identity and the complexity. The reason why we connected the endpoint with identity and the data that the user is accessing is because it\u2019s a critical problem. And if you can solve that, you can solve a big part of the cyber problem that an organization has.\u201d\u00a0\nLeading cybersecurity vendors are up for the challenge of fast-tracking gen AI apps through DevOps to beta and doubling down on their many models in development.\nDuring Palo Alto Networks\u2018 most recent earnings call, chairman and CEO Nikesh Arora emphasized the intensity the company is putting into gen AI, saying, \u201cwe\u2019re doubling down, we\u2019re quadrupling down to make sure that precision AI is deployed across every product. And we open up the floodgates of collecting good data with our customers for them to give them better security because we think that is the way we\u2019re going to solve this problem to get real-time security.\u201d\u00a0\nFor CISOs and their teams to win the war against AI attacks and threats, gen AI-based apps, tools and platforms must become part of their arsenals. Attackers are out-innovating the most adaptive enterprises, sharpening their tradecraft to penetrate the weakest attack vectors. What\u2019s needed is greater cyber-resilience and self-healing endpoints.\nAbsolute Software\u2019s 2023 Resilience Index reveals how challenging it is to excel at the comply-to-connect trend. Balancing security and cyber-resilience is the goal, and the Index provides a useful roadmap. Cyber-resilience, like zero trust, is an ongoing framework that adapts to an organization\u2019s changing needs.\nEvery CEO and CISO VentureBeat interviewed at RSAC 2023 said employee- and company-owned endpoint devices are the fastest-moving, hardest-to-protect threat surfaces. With the rising risk of gen AI-based attacks, resilient, self-healing endpoints that can regenerate operating systems and configurations are the future of endpoint security.\nCentral to being prepared for gen AI-based attacks is to create muscle memory of every breach or intrusion attempt at scale, using AI and machine learning (ML) algorithms that learn from every intrusion attempt. Here are the five ways CISOs and their teams are preparing for gen AI-based attacks.\nDespite the security risk of confidential data being leaked into LLMs, organizations are intrigued by boosting productivity with gen AI and ChatGPT. VentureBeat\u2019s interviews with CISOs reveal that these professionals are split on defining AI governance. For any solution to this problem to work, it must secure access at the browser, app and API levels to be effective.\nSeveral startups and larger cybersecurity vendors are working on solutions in this area. Nightfall AI\u2019s recent announcement of an innovative security protocol is noteworthy. The company\u2019s customizable data rules and remediation insights help users self-correct. The platform gives CISOs visibility and control so they can use AI while ensuring data security.\u00a0\nSOC teams are seeing more sophisticated social engineering, phishing, malware and business email compromise (BEC) attacks that they attribute to gen AI. While attacks on LLMs and AI apps are nascent today, CISOs are already doubling down on zero trust to reduce these risks.\nThat includes continuously monitoring and analyzing gen AI traffic patterns to detect anomalies that could indicate emerging attacks and regularly testing and red-teaming systems in development to uncover potential vulnerabilities. While zero trust can\u2019t eliminate all risks, it can help make organizations more resilient against gen AI threats.\nGen AI\u2019s potential to improve microsegmentation, a cornerstone of zero trust, is already happening thanks to startups\u2019 ingenuity. Nearly every microsegmentation provider is fast-tracking DevOps efforts.\u00a0\nLeading vendors with deep AI and ML expertise include Akamai, Airgap Networks, AlgoSec, Cisco, ColorTokens, Elisity, Fortinet, Illumio, Microsoft Azure, Onclave Networks, Palo Alto Networks, VMware, Zero Networks and Zscaler.\nOne of the most innovative startups in microsegmentation is Airgap Networks, named one of the 20 best zero-trust startups of 2023. Airgap\u2019s approach to agentless microsegmentation reduces the attack surface of every network endpoint, and it is possible to segment every endpoint across an enterprise while integrating the solution into an existing network with no device changes, downtime or hardware upgrades.\nAirgap\u00a0Networks also introduced its\u00a0Zero\u00a0Trust\u00a0Firewall (ZTFW)\u00a0with\u00a0ThreatGPT, which uses\u00a0graph databases\u00a0and GPT-3 models to help SecOps teams gain new threat insights. The GPT-3 models analyze natural language queries and identify security threats, while graph databases provide contextual intelligence on endpoint traffic relationships.\n\u201cWith highly accurate asset discovery, agentless microsegmentation and secure access, Airgap offers a wealth of intelligence to combat evolving threats,\u201d Airgap CEO Ritesh Agrawal told VentureBeat. \u201cWhat customers need now is an easy way to harness that power without any programming. And that\u2019s the beauty of ThreatGPT \u2014 the sheer data-mining intelligence of AI coupled with an easy, natural language interface. It\u2019s a game-changer for security teams.\u201d\nSecurity is often tested right before deployment, at the end of the software development lifecycle (SDLC). In an era of emerging gen AI threats, security must be pervasive throughout the SDLC, with continuous testing and verification. API security must also be a priority, and API testing and security monitoring should be automated in all DevOps pipelines.\nWhile not foolproof against new gen AI threats, these practices significantly raise the barrier and enable quick threat detection. Integrating security across the SDLC and improving API defenses will help enterprises thwart AI-powered threats.\nA zero-trust approach to every interaction with AI tools, apps and platforms and the endpoints they rely on is a must-have in any CISO\u2019s playbook. Continuous monitoring and dynamic access controls must be in place to provide the granular visibility needed to enforce least privilege access and always-on verification of users, devices and the data they\u2019re using, both at rest and in transit.\u00a0\nCISOs are most worried about how gen AI will bring new attack vectors they\u2019re unprepared to protect against. For enterprises LLMs, protecting against query attacks, prompt injections, model manipulation and data poisoning are high priorities.\nCISOs, CIOs and their teams are facing a challenging problem today. Do gen AI tools like ChatGPT get free reign in their organizations to deliver greater productivity, or are they bridled in and controlled, and if so, by how much? Samsung\u2019s failure to protect IP is still fresh in the minds of many board members.\nOne thing everyone agrees on, from the board level to SOC teams, is that gen AI-based attacks are increasing. Yet no board wants to jump into capital expense budgeting, especially given inflation and rising interest rates. The answer many are arriving at is accelerating zero-trust initiatives. While an effective zero-trust framework isn\u2019t stopping gen AI attacks completely, it can help reduce their blast radius and establish a first line of defense in protecting identities and privileged access credentials."}, "Pirros, a startup that applies AI to streamline drawing sets for buildings and infrastructure, lands $2 million seed round": {"Date": "August 31, 2023 9:00 AM", "Author": "Michael Nu\u00f1ez", "Link": "https://venturebeat.com/ai/pirros-a-startup-that-applies-ai-to-streamline-drawing-sets-for-buildings-and-infrastructure-lands-2-million-seed-round/", "Content": "Pirros, a technology platform that helps architecture and engineering firms manage their drawing sets more efficiently, announced today that it has raised a $2 million seed round from a group of investors and advisors with deep industry connections.\nNotable contributors to the funding round include angel investors Carl Bass, former chief executive of Autodesk; Joseph Walla of HelloSign; and Ryan Sutton-Gee of the construction software firm PlanGrid. Venture capital firms including YCombinator, FundersClub and Twenty Two Ventures also participated in the seed round.\nPirros is a tool created to streamline detail management for architecture and engineering firms. It automatically categorizes and catalogs the primary deliverable of design professionals: The many thousands of drawing sets that firms create each year for buildings and infrastructure.\nMost firms currently face an extremely inefficient paradigm of creating, using and effectively discarding design details \u2014 not because they are no longer useful, but because they are stored on on-premises servers with little to no ability to rediscover and reuse them. This means architects and engineers have to re-create drawings over and over for each project, which has the further effect of stripping them of the quality control process they went through in the course of initial creation.\nWith Pirros, architects and engineers can spend more time actually designing buildings instead of documenting them. This is achieved by automatic information aggregation and storage, so that all of a company\u2019s outputs are stored and managed in a centralized, searchable platform for easy future re-use.\nPirros CEO and cofounder Ari Baranian said in an interview with VentureBeat: \u201cEvery company has tried to build out a small catalog, so about a couple of hundred details, and these will be the most common details that they\u2019ve used \u2026 There\u2019s just never been the tools to expand the catalog beyond 100, 200, or even 500 details.\u201d\nHe further emphasized: \u201cNow, our average company has over 10,000 [searchable] details on the platform. So with that ability, any new architect, any new engineer that joins the firm, quickly gets up to speed on the different standards of that office.\u201d\nThe proof is in the rapid adoption of the tool among some of the industry\u2019s biggest players. The software is already being used by more than 30 firms including large architecture companies like KPFF Engineers and RAMSA.\nPirros leverages the metadata from the building information models (BIMs) that firms use to create their drawing sets. It extracts and indexes this data into a searchable and reusable catalog of 2D assets. It also uses clustering algorithms to group similar details together so that users can see different versions of the same condition and choose the best one.\nThe platform integrates seamlessly with any firm\u2019s existing tools or workflows. The onboarding process is simple: Firms just need to identify the models they want to include in their Pirros catalog, and Pirros does the rest of the work with its integration pipeline.\nThe company has received positive feedback from its customers, especially from the youngest architects and engineers who use its platform. \n\u201cSeeing the amount of traction that we\u2019ve gotten with the youngest architects and engineers was surprising to us, but also super motivating to see that we\u2019re actually making an impact there.\u201d said Baranian.\nPirros plans to use the $2 million seed funding to grow its team, improve its product and expand its market. One of the upcoming features that Baranian is excited about is using AI to identify the best versions of every detail automatically and provide users suggestions and recommendations.\nPirros is a pioneer in the field of architectural detail management, which has been largely overlooked by other technology platforms. By solving this specific problem, Pirros aims to transform the way buildings are designed and documented. \nAs Baranian put it: \u201cWe built our product exactly as we would have wanted to use it.\u201d"}, "Meet Superframe, the AI startup that wants to be your copilot for revenue operations": {"Date": "August 31, 2023 8:59 AM", "Author": "Michael Nu\u00f1ez", "Link": "https://venturebeat.com/enterprise-analytics/meet-superframe-the-ai-startup-that-wants-to-be-your-copilot-for-revenue-operations/", "Content": "Superframe, an AI-powered software company aiming to help businesses optimize their go-to-market technology stacks, announced today that it has raised $5 million in seed funding from more than 40 angel investors, including data and AI experts, Salesforce consultants and general operating experts.\nThe round comes on the heels of Superframe\u2019s launch of its first official product, an AI assistant for managing complex Salesforce implementations. The startup says its technology will save companies time and money by making Salesforce configuration changes fast, safe, reliable and easy.\nDerek Steer, cofounder and CEO of Superframe, said that accuracy is going to be the company\u2019s number one differentiator in the AI market. \n\u201cWe want to fight the consumer frustration with a lack of accuracy. We want to build trust with our customers by giving them something they can\u2019t get somewhere else,\u201d he told VentureBeat in a recent interview.\nSteer is no stranger to the data and AI world, as he previously sold his last company Mode, a business intelligence platform, to Thoughtspot for $200 million.\nIn the long term, Superframe aims to solve the pain points that many companies face when they implement go-to-market tools, such as Salesforce, Marketo and HubSpot. These tools are often complex, rigid and hard to configure, resulting in wasted time, money and resources. Superframe uses the latest language models from OpenAI (ChatGPT) to provide instant and accurate answers to questions about the current state of the system, and to propose and implement configuration changes based on the users\u2019 description of what they want to do.\nSteer also said that Superframe will not replace humans, but rather enable them to rely on their expertise and clear their backlogs. \n\u201cWe want to help more people build more expertise,\u201d he said. \u201cAnd that\u2019s something that customers are still going to want to rely on.\u201d \nHe added that Superframe will help customers map out their business processes and configure their systems without being held back by the complexity and rigidity of the tools.\nSuperframe is currently in beta testing with a select group of customers, and plans to launch publicly in early 2024. The first phase of Superframe, which is answering questions about the system, will be free for users. The company plans to use the seed funding for product development and hiring more engineers. The startup currently has four employees.\nSuperframe is one of the many startups that are using AI to simplify and optimize business operations. According to a recent Gartner report, the market for AI software will reach almost $134.8 billion by 2025. The report also cites the increasing adoption of cloud-based services and applications as one of the key drivers for the AI market growth.\nSuperframe\u2019s vision is to become the copilot for revenue operations teams, and to help them think more creatively about their go-to-market strategies. \n\u201cWe believe that humans are capable of a lot,\u201d said Steer. \u201cAnd we are in a lot of cases bottlenecked by the tools that we use. We want to remove those bottlenecks in order to give people a greater ability to employ their creativity.\u201d"}, "Daversa Partners Ranks Among Top 20 Best Medium Workplaces 2023, According to Fortune Media and Great Place To Work\u00ae": {"Date": "August 31, 2023 7:25 AM", "Author": "Press Release", "Link": "https://venturebeat.com/business/daversa-partners-ranks-among-top-20-best-medium-workplaces-2023-according-to-fortune-media-and-great-place-to-work/", "Content": "NEW YORK\u2013(BUSINESS WIRE)\u2013August 31, 2023\u2013\nGreat Place To Work\u00ae and Fortune magazine have selected Daversa Partners as one of 2023\u2019s 100 Best Medium Workplaces. Coming in at No. 19, this means that Daversa Partners has earned a spot as one of the best companies to work for in the country.\nThis press release features multimedia. View the full release here: https://www.businesswire.com/news/home/20230831931182/en/\nTo determine the Best Medium Workplaces list, Great Place To Work analyzed the survey responses of over 210,000 employees from Great Place To Work Certified\u2122 companies with 100 to 999 U.S. employees.\nThe Best Medium Workplaces list is highly competitive. Great Place To Work, the global authority on workplace culture, determines its lists using its proprietary For All\u2122 methodology to evaluate and certify thousands of organizations in America\u2019s largest ongoing annual workforce study, based on over 1.3 million survey responses and data from companies representing more than 7.5 million employees this year alone.\nSurvey responses reflect a comprehensive picture of the workplace experience. Honorees were selected based on their ability to offer positive outcomes for employees regardless of job role, race, gender, sexual orientation, work status, or other demographic identifier.\n\u201cThis year, we celebrate 30 years of Daversa Partners,\u201d said Paul Daversa, Founder and CEO of Daversa Partners. \u201cOver these three decades, we have had the privilege of being a part of the dynamic evolution of the tech industry. This journey has not just been about our growth as a firm, but about the remarkable founders, funders, and operators who have undeniably shaped the ecosystem with their strategic vision. We are proud and grateful to play a role in this evolution.\u201d\nIn 2022, Daversa Partners earned Great Place to Work\u2122 Certification, with 95% of employees saying that \u201cpeople care about each other here.\u201d Daversa Partners was also awarded Best Workplaces for Women\u2122 by Fortune and Great Place to Work\u00ae in 2022 \u2013 a testament to the firm\u2019s commitment to the 64% of women who make up the company, with 56% at the leadership level. So far this year, Daversa Partners has secured a No.4 spot on Fortune\u2019s 2023 Best Workplaces in New York list, was named a 2023 Best Workplace for Millennials, and recertified as a Great Place to Work\u2122.\nAbout Daversa Partners\nFor three decades, Daversa Partners has built the leading management teams across the most disruptive companies of this generation, focused on serving the global founder and funder community around the world. Having worked alongside tech\u2019s top VC and PE firms, Daversa Partners has had the privilege to build over 10,000 consumer and enterprise companies, all of which hold a shared vision: push the throttle on innovation. The company today is an important strategic partner that moves top executives into startup and growth oriented companies.\nAbout the Fortune Best Medium Workplaces List\nGreat Place To Work selected the Fortune Best Medium Workplaces List by surveying companies employing 7.5 million people in the U.S. with 1.3 million confidential responses received. Of those, more than 210,000 responses were received from employees at companies eligible for the Best Medium Workplaces list and this ranking is based on that feedback. Company scores are derived from 60 employee experience questions within the Great Place To Work Trust Index\u2122 Survey. Read the full methodology.\n\nView source version on businesswire.com: https://www.businesswire.com/news/home/20230831931182/en/\nNicole DaversaNicole@daversapartners.com"}, "IBM and Salesforce team up to bring AI tools to their shared clients": {"Date": "August 31, 2023 6:53 AM", "Author": "Carl Franzen", "Link": "https://venturebeat.com/ai/ibm-and-salesforce-team-up-to-bring-ai-tools-to-their-shared-clients/", "Content": "Big Blue is teaming with an even Bigger Blue to deliver AI solutions to clients.\nToday, IBM and Salesforce announced they are joining forces to bring Salesforce AI solutions (Sales GPT, Service GPT, Salesforce Einstein, Slack GPT and Marketing GPT) to customers who do business with both companies.\nObviously, what Salesforce brings to the table is its popular and powerful customer relationship management (CRM) software, in addition to the aforementioned AI apps and tools. \nWhat IBM offers through the partnership is \u201cindustry expertise and innovative delivery models\u201d through its IBM Consulting arm of 160,000 human consultants, the company said in a press release. \nSpecifically, this includes \u201cIBM Garage \u2026 an operating model for business transformation,\u201d which will help the combined clients get their Salesforce AI integrations up and running.\nIBM notes that the shared customers may also wish to adopt its Watsonx enterprise AI platform for finding and fine-tuning enterprise grade AI models. WatsonX can further help customers find \u201cdata locked in backend systems\u201d that they can better access and leverage through their shiny new Salesforce and open-source AI models.\nFurther, customers should consider using IBM\u2019s Data Classifier, an \u201cAI-powered application trained on industry-specific data models,\u201d to help them map all their internal data to make it useful and accessible to the AI tools and apps, IBM says. \n\u201cCompanies are embarking on a transformative journey fueled by generative AI,\u201d Steve Corfield, Salesforce EVP and GM of global alliances and channels said in a press release. \u201cSalesforce partners like IBM Consulting play an important role in helping businesses use Salesforce\u2019s AI, data and CRM technologies to connect with their customers on a new level. Bringing Salesforce and IBM innovations together will help transform the way companies deliver personalized, engaging experiences.\u201d\u00a0\nIBM is practicing what it preaches. The original Big Blue used Salesforce and its own watsonx to overhaul its customer service and sales processes \u2014 now it\u2019s hoping to do the same for many others around the globe."}, "Gong\u2019s new Call Spotlight uses AI to summarize customer calls for revenue teams": {"Date": "August 31, 2023 5:00 AM", "Author": "Carl Franzen", "Link": "https://venturebeat.com/ai/gong-introduces-call-spotlight-a-generative-ai-summary-of-customer-calls-for-revenue-teams/", "Content": "Gong, the nine-year-old company focused on making technology that streamlines workflows for revenue teams across sectors, made news earlier this summer by introducing new generative AI-powered features to its customer conversation analysis platform, including gen AI messaging suggestions. \nNow, it\u2019s going a step further: The company today announced exclusively with VentureBeat that it is introducing the new feature Call Spotlight, accessible for all of its 4,000 platform customers (and counting) globally, at no extra charge.\nThe new AI-driven tool (powered by a mix of proprietary Gong AI models and GPT-4 in Microsoft Azure OpenAI Service) automatically transcribes and analyzes a revenue team member\u2019s conversation with a customer over video call, audio call, mobile or desktop, even emails and text correspondence \u2014 any communications the revenue team member wants \u2014 and auto-generates a summary and key points for the revenue team to act on.\nFor Gong\u2019s largely business-to-business (B2B)-focused clients, who spend lots of time prospecting customers of their own and managing customer relationships through direct correspondence, the tool is poised to offer increased productivity and efficiency.\nAt the same time, Gong hopes the new feature allows revenue teams and salespeople even more time to forge and maintain the unique customer relationships that are key to landing business. \n\u201cYou become more efficient\u201d using Call Spotlight, Gong chief product officer and cofounder Eilon Reshef, said in a video call with VentureBeat. \u201cYou don\u2019t need to review the whole text. You don\u2019t need to listen to the whole call. You don\u2019t need to take notes. You don\u2019t need to do anything manually.\u201d\nJust enable Call Spotlight through Gong\u2019s platform \u2014 there are modes that will prompt the other parties in any given call to agree to being recorded and analyzed by Gong\u2019s AI \u2014 and it will take care of it for you.\nGong says that Call Spotlight is unmatched in its accuracy, offering sales insights that are twice as reliable as generic solutions available on the market such as other consumer large language models (LLMs), having been trained on billions of sales interactions that Gong sourced from customers.\n\u201cWhat\u2019s unique about Gong is that because we train the system based on revenue conversations, we get much more accurate results,\u201d Reshef told VentureBeat.\nThis includes a more accurate AI interpreter of specific company and product names \u2014 something other auto-transcription AI services often struggle to handle, in VentureBeat\u2019s testing, defaulting to generic words instead of trademarks.\nOne of Call Spotlight\u2019s standout features is its unique \u201cAsk Anything\u201d function \u2014 the first of its kind tailored specifically for sales. Think of it as your personal sales coach, ready to answer any question you throw at it.\nWhether it\u2019s seeking guidance on sealing a deal or understanding why a particular conversation matters to a regional account executive, Ask Anything delivers precise, context-rich advice.\nFor instance, after a call, a sales rep might wonder, \u201cWhat can I do to up my game for closing this deal?\u201d Ask Anything churns out actionable steps based on its deep learning of a specific customer interaction, with context pulled from Gong\u2019s extensive sales data.\nSimilarly, if a manager wants to know whether competitors were name-dropped during a conversation, the tool can sift through the call details and flag any potential threats, allowing for targeted coaching strategies.\nIn addition to the Ask Anything feature, Call Spotlight includes:\nGong customers can also share any of these AI-generated products with their colleagues and managers as needed, and also push data to their customer relationship management (CRM) software of choice for recordkeeping \u2014 or not. It\u2019s all up to the customer to decide what to do with their gen AI work products.\nFurthermore, Gong knows that security is top-of-mind for many of its customers, and seeks to reassure them that safeguarding their data is of paramount importance while introducing all of these new gen AI features. \n\u201cOne of the critical elements for us is security,\u201d said Reshef. \u201cWe have some of the Fortune top 50 companies as customers, and they are very concerned about security and unlikely to allow us to sell their data outside the company. So we hire Gong employees and do everything in-house.\u201d\nGong noted that it has been recording calls since 2016, and is GDPR-compliant and has stayed up-to-date on all relevant regulations in the years since. \nBy marrying highly accurate, context-specific advice with a range of other features and security, Gong hopes that Call Spotlight will be a game-changer for the revenue teams that try it out."}, "AI21 Labs raises $155M to accelerate generative AI for enterprises": {"Date": "August 30, 2023 1:21 PM", "Author": "Sharon Goldman", "Link": "https://venturebeat.com/ai/ai21-labs-raises-155m-to-accelerate-genai-for-enterprises/", "Content": "Tel Aviv, Israel-based large language model (LLM) leader AI21 Labs confirmed with VentureBeat that it has has closed $155 million in series C funding to accelerate the growth of its text-based generative AI services for enterprises. The company is now valued at $1.4 billion. \nInvestors in the round include Walden Catalyst, Pitango, SCB10X, b2venture, Samsung Next and Amnon Shashua with participation from Google and Nvidia.\u00a0\nFounded in 2017 by AI pioneers and technology veterans Amnon Shasuha, Yoav Shoham and Ori Goshen, AI21 Labs may have been one of the first to bring gen AI to the masses, but it has also spent the past year chasing LLM rivals like OpenAI to commercial applications. \nAfter a $64 million series B round last year, Shoham, an emeritus professor of AI at Stanford University, told VentureBeat that he recognized that the funding landscape was tightening and more LLMs and multimodal models were being launched every day. \nHe said the company was \u201cvery aware of the environment and not complacent in any way.\u201d\u00a0\nAI21\u2019s proprietary Jurassic-2 foundation models are considered some of the world\u2019s largest and most sophisticated LLMs. Jurassic-2 powers AI21 Studio, a developer platform for building custom text-based business applications off of AI21\u2019s language models; and Wordtune, a\u00a0multilingual\u00a0reading and writing AI assistant for professionals and consumers.\nAI21 chairman Shashua said in a press release: \u201cAI21 Labs is a pure play in AI as it develops and owns foundation models which are served as a platform to developers and enterprises, while developing derivatives such as Wordtune directly to end users. The current round fuels the growth of the company to reach its goal of developing the next level of AI with the capabilities of reasoning across many domains. We believe that the impact of AI21 Labs growth plans would be of a global scale and quite soon.\u201d\nJensen Huang, founder and CEO of Nvidia, also shouted out AI21\u2019s work in the press release: \u201cGenerative AI is driving a new era of computing across every industry,\u201d he said. \u201cThe innovative work by the AI21 Labs team will help enterprises accelerate productivity and efficiency with generative AI-based systems that are accurate, trustworthy and reliable.\u201d\nAI21 has recently collaborated with customers in diverse sectors, including Carrefour, Clarivate, eBay, Guesty, Monday.com and Ubisoft. The company was also\u00a0named on the first ever CB Insights GenAI 50."}, "Sprig uses AI to transform product surveys into conversational data": {"Date": "August 30, 2023 9:39 AM", "Author": "Carl Franzen", "Link": "https://venturebeat.com/ai/sprig-uses-ai-to-transform-product-surveys-into-conversational-data/", "Content": "Sprig, a five-year-old startup focused on creating smart, contextually aware in-app surveys for enterprises, earned a big vote of confidence last year, securing $30 million in funding from prominent venture capital firms including a16z and Accel.\nToday, the company is announcing where some of those funds went: A new feature Sprig calls AI Analysis for Surveys, which, as the name suggests, uses generative AI large language models (LLMs) to intelligently comb through survey data and provide instantaneous insights to the company that conducted the survey.\nTo put it more bluntly: Sprig\u2019s AI Analysis for Surveys transforms survey data into a conversational AI product. \nWith it, you as the survey owner can ask your survey results any conceivable question, and the AI will sort through them and attempt to respond with the most appropriate data, insights, takeaways or suggestions \u2014 and this includes qualitative survey data like open-ended text entries, not just multiple choice or quantitative answers.\n\u201cYou can ask Sprig AI to answer any custom questions about your survey data, and it will analyze responses across all of your survey questions to find the answer,\u201d Sprig CEO Ryan Glasgow, wrote in a blog post about the news. \nThe company also announced an expanded free plan, and new large enterprise customers including PayPal, Figma, Ramp, Peloton and Mixpanel.\n\u201cWorld-class product teams continue to choose our platform because they value their user experience and have found Sprig to be a mission-critical platform to differentiate their products in today\u2019s competitive environment,\u201d wrote Glasgow.\nSprig first made waves in 2020 with the launch of its in-product survey platform and Open-Text AI Analysis feature, which automatically groups open-ended survey responses (those questions that ask you to write about your experience in a text box) into themes. \nThe feature was adopted quickly by leading enterprises including Dropbox, Loom, Coinbase, Robinhood and Square. To date, Sprig has analyzed feedback from more than 6 billion product visitors across hundreds of high-growth technology companies.\nWith the new AI Analysis for Surveys, Sprig takes it to the next level by analyzing entire survey datasets. Product teams can now:\nGlasgow wrote in an email to VentureBeat: \u201cAI Analysis for Surveys solves a common pain point for product teams looking to deeply understand and optimize a specific part of their product experience, from understanding why users are churning out of a product to figuring out how to boost the conversion funnel.\u201d\nIn addition to rolling out AI Analysis for Surveys, Sprig is expanding its free plan to make its AI-powered product insights accessible to more teams.\nThe free plan now includes in-product surveys, session replays and Open-Text AI Analysis. Teams of all sizes can immediately start using Sprig and the new AI Analysis for Surveys feature set."}, "Fianu Labs Secures $2 Million in Seed Funding from DataTribe to Automate Governance of Software Development": {"Date": "August 30, 2023 8:25 AM", "Author": "Press Release", "Link": "https://venturebeat.com/business/fianu-labs-secures-2-million-in-seed-funding-from-datatribe-to-automate-governance-of-software-development/", "Content": "\nCompanies will soon be Liable for the Safety of Their Software for Consumers, Companies, and Governments.\n\nFULTON, Md.\u2013(BUSINESS WIRE)\u2013August 30, 2023\u2013\nFianu Labs, the software governance automation solution, today secured a $2 million seed investment from DataTribe, a global cyber foundry that invests in and co-builds next-generation cybersecurity and data science companies.\nFor businesses in regulated industries, the weight of software regulation is onerous. Each software release requires hundreds of hours of manual evidence gathering, leading to longer release cycles that stifle innovation and cost tens of millions of dollars in lost productivity every year. There looks to be no relief in sight as regulators have signaled a renewed focus on software development practices in response to recent attacks on the software supply chain. Businesses are in dire need of a solution that streamlines their compliance and shortens release cycles.\nFianu Labs is pioneering the path for businesses to succeed in the era of software regulation with an intuitive approach to governance that instills confidence in each release. Fianu captures and maintains a continuous audit trail that tells the story of each code change, from commit to release and automates a once chaotic manual process with speed and clarity. At its core, Fianu bridges the gap between Security, Quality Assurance, Engineering, and Risk with a shared language and a unified front to regulators and auditors. The result is reduced risk, faster release cycles, and easier audits.\n\u201cFianu is truly revolutionizing secure software development observability,\u201d said Leo Scott, Chief Innovation Officer for DataTribe and a Fianu Board of Directors member. \u201cFianu gives Chief Technology Officers, Chief Security Officers, and Chief Information Officers confidence to deliver software at the speed they want and with the integrity required.\u201d\nOver the last three years, the federal government has signaled increased scrutiny of software release patterns foreboding an era of crippling red tape and higher costs that could create significant challenges for companies across the regulatory landscape. Additionally, recent rulings have expanded the liability of software vendors and their executives. The message is clear: Companies that develop software will be held accountable for the security of their products. Fianu aims to reduce the weight of regulation for established companies while helping smaller and traditionally less-regulated companies transition to the new era of software development.\nThe company is providing visibility into the software development process in a provable way, enabling organizations to immutably attest to fundamental, sound, and secure software development best practices. Today, the demand is in regulated industries, but in the future, all companies producing custom software solutions will need to meet software governance requirements.\nFianu\u2019s platform captures evidence across the DevSecOps toolchain mapped to internal policy during real-time, continuous audits against established risk controls and compliance frameworks. Each software release is accompanied by a Software Bill of Attestations (SBOA) designed to transmit immutable, audit-worthy evidence. By using Fianu, companies can replace opaque manual processes with streamlined, intuitive automation that makes software governance and compliance easy.\n\u201cThere is no better team than DataTribe to help us realize our vision of a governance ecosystem that powers a modern approach to continuous delivery under rigorous regulatory requirements,\u201d said Michael Edenzon, CEO and co-founder of Fianu Labs.\nAbout DataTribe\nDataTribe is a startup foundry that invests in and co-builds world-class startups focused on generational leaps in cybersecurity and data science. Founded by leading investors, startup veterans, and alumni of the U.S. intelligence community, DataTribe commits capital, in-kind services, access to an unparalleled network, and decades of professional expertise to give their companies an unfair advantage. DataTribe is headquartered in the Washington-Baltimore metro area in Fulton, Maryland. For more information, visit datatribe.com.\nAbout Fianu Labs\nFianu Labs is a pioneer in the field of governance engineering and RegTech. Our focus is building software products to empower companies to deliver compliant software with maximum velocity. Fianu Labs is headquartered in Washington, D.C., and was founded by leaders in software governance, co-authors of Investments Unlimited, and software delivery experts from one of the nation\u2019s largest banks. For more information, visit fianu.io.\n\nView source version on businesswire.com: https://www.businesswire.com/news/home/20230830073713/en/\nJosh Zecherjosh@vrge.us"}, "Typeface teams with GrowthLoop and Google Cloud to launch unified \u2018GenAI Marketing Solution\u2019": {"Date": "August 30, 2023 8:00 AM", "Author": "Shubham Sharma", "Link": "https://venturebeat.com/ai/typeface-teams-with-growthloop-and-google-cloud-to-launch-unified-genai-marketing-solution/", "Content": "AI company Typeface has partnered with marketing player GrowthLoop and Google Cloud with the goal of transforming marketing for organizations of all sizes. The companies today announced a unified \u201cGenAI Marketing Solution\u201d that brings together the best of their respective platforms and gives marketers an end-to-end approach to create and launch campaigns across channels, at scale.\nThe offering allows teams to produce personalized content \u2014 from blogs to social media posts \u2014 for their campaigns, leveraging data from Google BigQuery, audience segmentation from GrowthLoop and Typeface\u2019s generative AI smarts. According to the companies, it can cut the time taken to build and launch creative campaigns from several weeks down to days or even a few hours.\u00a0\n\u201cMarketing leaders across the globe have shared with us that producing personalized content at scale across audience segments can be a significant challenge, often causing campaigns to take months and months to launch,\u201d Vishal Sood, head of product at Typeface, said in a statement. \u201cThe GenAI Marketing Solution announced at Google Cloud Next offers marketers \u2014 for the first time ever \u2014 the ability to rapidly generate and deploy tailored, on-brand content across customer segments. With this new solution, marketing teams can dramatically accelerate campaign launches freeing up time for more creativity and collaboration.\u201d\nCurrently available in private preview for Google BigQuery users, the GenAI Marketing Solution merges gen AI from Typeface into a streamlined workflow that covers every aspect of the campaign creation process, from extracting 360-degree customer profiles and defining audience segments to creating personalized, on-brand content, distributing it and measuring the results.\nFirst, users have to connect their BigQuery instance with GrowthLoop and use the latter\u2019s visual or natural language builder to query data in the data warehouse and create audience segments to target. Once the segments are ready, they can export them to a marketing channel of choice, such as Google Ads, and use the Typeface integration with GrowthLoop to develop personalized creatives, ad copies, and campaign assets with text prompts.\nAs they develop the initial campaign assets, they can expand the effort by using Typeface to create an entire library of content for different marketing channels \u2014 such as personalized Instagram ads, SEO-optimized blog posts, and landing pages \u2014 that align with the GrowthLoop audience profile. This gives multiple variations of content, tailored to defined audience segments and brand voice, for different touchpoints.\nPost-launch, teams can measure the results of the campaign directly within GrowthLoop, down to individual metrics such as revenue generated.\n\u201cOur collaboration results in an extraordinary solution, one that promises to reshape marketing workflows for businesses across the globe,\u201d said Chris Sell, cofounder and co-CEO of GrowthLoop. \u201cAs we harness the transformative power of generative AI, we find ourselves at the cusp of a new chapter, empowering digital marketing teams with unparalleled efficiency and success-driving tools.\u201d\nWhile it remains unclear when the unified GenAI Marketing Solution will become generally available, there\u2019s no denying that the move to rope in generative technologies is a welcome change for marketers who are facing increasing pressure to create compelling, personalized content to drive results in today\u2019s fast-paced environment.\nAccording to a Salesforce survey of more than 1,000 full-time marketers in the U.S., U.K. and Australia, gen AI is being seen as a \u201cgame-changer\u201d that can save an employee about five hours of work every week. That\u2019s more than a month every year, assuming eight-hour work days.\nAmong those using the technology at present, the most popular use case is basic content creation and writing marketing copy, with as many as 76% handling those tasks with LLM-driven apps like ChatGPT. The next most popular use cases are inspiring creative thinking (71%), analyzing market data (63%) and generating image assets (62%).\u00a0\nNotably, LinkedIn\u2019s Campaign Manager has already debuted a feature that allows users to generate introductory text and headlines for ads, using their data from the platform, while Meta has an AI Sandbox that lets advertisers create variations of basic copy for different audiences through text prompts."}, "At the US Open, IBM serves up AI-generated tennis commentary and draw analysis": {"Date": "August 30, 2023 7:16 AM", "Author": "Sharon Goldman", "Link": "https://venturebeat.com/ai/ibm-serves-up-ai-generated-tennis-commentary-and-draw-analysis-at-the-us-open/", "Content": "Back in May, IBM doubled down on its AI efforts with the announcement at the company\u2019s annual\u00a0Think conference of its new Watsonx product platform, which provides a foundational model library that can be used to fine-tune pretrained models for enterprise application development. \nNow, the company is serving up what it hopes is a generative AI ace: For the first time, it is offering AI-generated audio tennis highlights for all matches during the two-week-long U.S. Open Tennis Championships, as well as AI-powered analysis to determine the projected difficulty of player draws and potential opponents. \nMore than 700,000 people head to Flushing Meadows, New York, each year to watch the best tennis players in the world compete, while more than 10 million tennis fans around the world follow the tournament through the U.S. Open app and website.\u00a0And, for three decades, IBM has been working with the\u00a0United States Tennis Association\u00a0on creating digital experiences for tennis fans. \nThe effort begins in the basement-level IBM data operations center at Arthur Ashe Stadium, where millions of data points are captured and analyzed. There are typically 56 data points collected for every single point of a tennis match. \nIBM is using gen AI models built, trained and deployed with Watsonx, and operating across a hybrid cloud infrastructure from Red Hat OpenShift, to generate detailed audio narration and captions to accompany U.S. Open highlight videos at unprecedented scale \u2014 for every match in the singles draw, across all 17 courts.\nIn addition, IBM debuted its Watsonx-powered AI Draw Analysis\u00a0that uses both structured and unstructured data to project the level of advantage or disadvantage of all players in the singles draw. Each player receives an IBM AI Draw Analysis at the start of the tournament, which will be updated daily as the tournament progresses and players are eliminated. Every draw is ranked, allowing fans to click into individual matches and see the projected difficulty of their draw and potential opponents.\nKirsten Corio, chief commercial officer at the USTA, told VentureBeat that with 128 men and 120 women playing singles in the U.S. Open \u2014 as well as doubles, juniors and wheelchair tennis matches \u2014 the organization couldn\u2019t cover the highlights of most of the matches throughout the tournament. \n\u201cDepending on how many writers you have, you can only do a few matches at a time,\u201d she said. \u201cThe other matches would just have stats and scores, but no commentary, so those stories are untold.\u201d \nSo the USTA and IBM began to think about how to scale tournament coverage by combining stats and stories with gen AI. \n\u201cHow could we use the data and technology to actually write highlights that would be reliable and accurate enough?\u201d said Corio. \nCorio added that the USTA dreams of including AI-generated highlights in different languages in the future. \u201cWe would love to do that in Spanish, to scale more engagement,\u201d she said. \u201cThat\u2019s the natural next step.\u201d \nWhile the USTA has been partnering with IBM on its technology efforts for decades, when it comes to today\u2019s advanced AI applications, Corio pointed out that being able to control the data and the ecosystem is key. \nThe USTA uses its own curated, official data, \u201cbut there are plenty out there who peddle in unofficial data,\u201d she explained. \u201cWe\u2019re not yet sure what the downstream effects of that could be, so we\u2019re actually putting together a few different task forces across the company post-U.S. Open, to dig into how can it benefit us? How can we protect against any potential conflict?\u201d \nA more of-the-moment concern is AI hallucinations \u2014 but in a presentation in the IBM Data Center beneath Arthur Ashe Stadium, an IBM spokesperson told VentureBeat that the company is doing human-in-the-loop quality checks on its AI Commentary. \n\u201cWe\u2019re hoping over time we can reduce the need for human QA, but we do check each highlight clip, to make sure that the commentary is solid,\u201d the spokesman said. "}, "Arize AI wants to improve enterprise LLMs with \u2018Prompt Playground,\u2019 new data analysis tools": {"Date": "August 30, 2023 7:15 AM", "Author": "Carl Franzen", "Link": "https://venturebeat.com/ai/arize-ai-wants-to-improve-enterprise-llms-with-prompt-playground-new-data-analysis-tools/", "Content": "We all know enterprises are racing at varying speeds to analyze and reap the benefits of generative AI \u2014 ideally in a smart, secure and cost-effective way. Survey after survey over the last year has shown this to be true. \nBut once an organization identifies a large language model (LLM) or several that it wishes to use, the hard work is far from over. In fact, deploying the LLM in a way that benefits an organization requires understanding the best prompts employees or customers can use to generate helpful results \u2014 otherwise it\u2019s pretty much worthless \u2014 as well as what data to include in those prompts from the organization or user.\n\u201cYou can\u2019t just take a Twitter demo [of an LLM] and put it into the real world,\u201d Aparna Dhinakaran, cofounder and chief product officer of Arize AI, said in an exclusive video interview with VentureBeat. \u201cIt\u2019s actually going to fail. And so how do you know where it fails? And how do you know what to improve? That\u2019s what we focus on.\u201d\nThree-year-old business-to-business (B2) machine learning (ML) software provider Arize AI would know, as it has since day one been focused on making AI more observable (less technical and more understandable) to organizations. \nToday, the VB Transform award-winning company announced at Google\u2019s Cloud Next 23 conference industry-first capabilities for optimizing the performance of LLMs deployed by enterprises, including a new \u201cPrompt Playground\u201d for selecting between and iterating on stored prompts designed for enterprises, and a new retrieval augmented generation (RAG) workflow to help organizations understand what data of theirs would be helpful to include in an LLMs responses. \nAlmost a year ago, Arize debuted its initial platform in the Google Cloud Marketplace. Now it is augmenting its presence there with these powerful new features for its enterprise customers.\nArize\u2019s new prompt engineering workflows, including Prompt Playground, enable teams to uncover poorly performing prompt templates, iterate on them in real time and verify improved LLM outputs before deployment. \nPrompt analysis is an important but often overlooked part of troubleshooting an LLM\u2019s performance, which can simply be boosted by testing different prompt templates or iterating on one for better responses.\nWith these new workflows, teams can easily:\nAs Dhinakaran explained, prompt engineering is absolutely key to staying competitive with LLMs in the market today. The company\u2019s new prompt analysis and iteration workflows help teams ensure their prompts cover necessary use cases and potential edge scenarios that may come up with real users.\n\u201cYou\u2019ve got to make sure that the prompt you\u2019re putting into your model is pretty damn good to stay competitive,\u201d said Dhinakaran. \u201cWhat we launched helps teams engineer better prompts for better performance. That\u2019s as simple as it is: We help you focus on making sure that that prompt is performant and covers all of these cases that you need it to handle.\u201d\nFor example, prompts for an education LLM chatbot need to ensure no inappropriate responses, while customer service prompts should cover potential edge cases and nuances around services offered or not offered.\nArize is also providing the industry\u2019s first insights into the private or contextual data that influences LLM outputs \u2014 what Dhinakaran called the \u201csecret sauce\u201d companies provide. The company uniquely analyzes embeddings to evaluate the relevance of private data fused into prompts.\n\u201cWhat we rolled out is a way for AI teams to now monitor, look at their prompts, make it better and then specifically understand the private data that\u2019s now being put into those those prompts, because the private data part makes sense,\u201d Dhinakaran said.\nDhinakaran told VentureBeat that enterprises can deploy its solutions on premises for security reasons, and that they are SOC-2 compliant. \nThese new capabilities enable examination of whether the right context is present in prompts to handle real user queries. Teams can identify areas where they may need to add more content around common questions lacking coverage in the current knowledge base.\n\u201cNo one else out there is really focusing on troubleshooting this private data, which is really like the secret sauce that companies have to influence the prompt,\u201d Dhinakaran noted.\nArize also launched complementary workflows using search and retrieval to help teams troubleshoot issues stemming from the retrieval component of RAG models.\nThese workflows will empower teams to pinpoint where they may need to add additional context into their knowledge base, identify cases where retrieval failed to surface the most relevant information, and ultimately understand why their LLM may have hallucinated or generated suboptimal responses.\nDhinakaran gave an example of how Arize looks at query and knowledge base embeddings to uncover irrelevant retrieved documents that may have led to a faulty response.\n\u201cYou can click on, let\u2019s say, a user question in our product, and it\u2019ll show you all of the relevant documents that it could have pulled, and which one it did finally pull to actually use in the response,\u201d Dhinakaran explained. Then \u201cyou can see where the model may have hallucinated or provided suboptimal responses based on deficiencies in the knowledge base.\u201d\nThis end-to-end observability and troubleshooting of prompts, private data and retrieval is designed to help teams optimize LLMs responsibly after initial deployment, when models invariably struggle to handle real-world variability.\nDhinakaran summarized Arize\u2019s focus: \u201cWe\u2019re not just a day one solution; we help you actually ongoing get it to work.\u201d\nThe company aims to provide the monitoring and debugging capabilities organizations are missing, so they can continuously improve their LLMs post-deployment. This allows them to move past theoretical value to real-world impact across industries."}, "Context raises $3.5M to elevate LLM apps with detailed analytics": {"Date": "August 30, 2023 7:01 AM", "Author": "Shubham Sharma", "Link": "https://venturebeat.com/ai/context-raises-3-5m-to-elevate-llm-apps-with-detailed-analytics/", "Content": "London-based Context, a startup providing enterprises with detailed analytics to build better large language model (LLM)-powered applications, today said it has raised $3.5 million in funding from Google Ventures, Tomasz Tunguz from Theory Ventures and other sources.\u00a0\nContext AI said it will use the capital to grow its engineering teams and build out its platform to better serve customers.\nThe investment comes at a time when global companies are bullish on AI and racing to implement LLMs into their internal workflows and consumer-facing applications. According to estimates from McKinsey, with this pace, generative AI technologies could add up to $4.4 trillion annually to the global economy.\nWhile LLMs are all the rage, building applications using them isn\u2019t exactly a cakewalk. You have to track a model\u2019s performance, how the application is being used, and most importantly, whether it is providing the right answers to users or not \u2014 accurate, unbiased and grounded in reality. Without these insights, the whole effort is just like flying blind with no direction to make the product better.\nHenry Scott-Green, who previously worked as a product manager at Google, saw similar challenges earlier this year when working on a side project that tapped LLMs to let users chat with websites.\u00a0\n\u201cWe talked to many product developers in the AI space and discovered that this lack of user understanding was a shared, critical challenge facing the community,\u201d Green told VentureBeat. \u201cOnce we identified and validated the problem, we started working on a prototype [analytics] solution. That was when we decided to build Context.\u201d\nToday, Context is a full-fledged product analytics platform for LLM-powered applications. The offering provides high-level insights detailing how users are engaging with an app and how the product is performing in return. \nThis not only covers basic metrics like the volume of conversations on the application, top subjects being discussed, commonly used languages and user satisfaction ratings, but more specific tasks such as tracking specific topics (including risky ones) and transcribing entire conversations to help teams see how the application is responding in different scenarios.\n\u201cWe ingest message transcripts from our customers via API, and we have SDKs and a LangChain plugin that make this process [take] less than 30 minutes of work,\u201d Green explained. \u201cWe then run machine learning workflows over the ingested transcripts to understand the end user needs and the product performance. Specifically, this means assigning topics to the ingested conversations, automatically grouping them with similar conversations, and reporting the satisfaction of users with conversations about each topic.\u201d\nUltimately, using the insights from the platform, teams can flag problem areas in their LLM products and work towards addressing them and delivering an improved offering to meet user needs.\nContext claims to have garnered multiple paying customers since its founding four months ago, including Cognosys, Juicebox and ChartGPT, as well as several large enterprises. Citing non-disclosure agreements, Green did not share further details.\nWith this round, the company plans to build on its effort by hiring a technical founding team, which will allow Green and his team to accelerate their development and build an even better product.\u00a0\n\u201cThe product itself has a few planned focus areas: to build higher-quality ML systems that deliver deeper insights; to improve the user experience; and to develop alternate deployment models, where our customers can deploy our software directly in their cloud,\u201d the CEO said.\n\u201cAt this stage, our goal is to continue growing our customer base while delivering value to the businesses using our product. And we\u2019re seeing success,\u201d he added.\nAs the demand for LLM-based applications grows, the number of solutions for tracking their performance is also expected to rise.\u00a0\nObservability player Arize has already launched a solution called Phoenix, which visualizes complex LLM decision-making and flags when and where models fail, go wrong, give poor responses or incorrectly generalize. Datadog is going in the same direction and has started providing model monitoring capabilities that can analyze the behavior of a model and detect instances of hallucinations and drift based on data characteristics such as prompt and response lengths, API latencies and token counts.\nGreen, however, emphasized that Context provides more insights than these offerings, which just flag the problem areas, and is more like web product analytics companies such as Amplitude and Mixpanel.\nThe funding round also saw participation from 20SALES and multiple VCs and tech industry luminaries, including 20VC\u2019s Harry Stebbings, Snyk founder Guy Podjarny, Synthesia founders Victor Riparbelli and Steffen Tjerrild, Google DeepMind\u2019s Mehdi Ghissassi, Nested founder Matt Robinson, Deepset founder Milos Rusic and Sean Mullaney from Algolia."}, "Couchbase aims to boost developer database productivity with Capella IQ AI tool": {"Date": "August 30, 2023 6:00 AM", "Author": "Sean Michael Kerner", "Link": "https://venturebeat.com/ai/couchbase-aims-to-boost-developer-database-productivity-with-capella-iq-ai-tool/", "Content": "Database vendor Couchbase today announced the launch of Capella IQ, a new AI-powered tool aimed at enhancing developer productivity when building applications on the Couchbase Capella database-as-a-service (DBaaS) cloud platform.\nCouchbase was originally developed as an open-source NoSQL database technology and has grown in recent years to add capabilities that are commonly found in relational database technologies. In 2021, Couchbase, Inc., went public on the NASDAQ and now trades under the symbol BASE. That same year, the company first released its Capella DBaaS platform, which has continued to expand with support on multiple cloud platforms including Google Cloud.\nThe goal with Couchbase Capella is to provide a database platform for developers that is easier to use and manage. The launch of Capella IQ brings the power of generative AI to the platform to help developers write database code.\n\u201cThink of it [Capella IQ] as a copilot for developers, using LLM [large language model] foundation models to really enhance the productivity of developers,\u201d Matt Cain, Couchbase president and CEO, told VentureBeat.\nThe new tool fits into Couchbase\u2019s overall four-pronged AI strategy, according to Cain.\nCouchbase\u2019s AI strategy includes driving developer productivity, optimizing AI processing, enabling AI-driven applications anywhere, and complementing its technology with partnerships. Cain said that Capella IQ addresses the first pillar around developer productivity.\nCain explained that Capella IQ leverages gen AI models to automate tedious development tasks like generating code snippets, sample datasets and unit tests. He noted that developers can access these capabilities directly within the Capella developer workbench through a conversational interface that is designed to have a low barrier to entry.\n\u201cIt\u2019s completely aligned with how we\u2019re thinking about our AI strategy, but really focused on helping developers be as productive as possible with Capella and enabling next-generation applications,\u201d said Cain.\nWith Capella IQ,\u00a0Couchbase is using OpenAI\u2019s models to help with code generation. Cain noted that Couchbase may choose to also work with other LLM providers in the future.\u00a0\nHe also emphasized that there are several capabilities in the Capella platform that help to enable the IQ feature beyond just connecting out to an LLM provider. One such feature is the Index Advisor, an existing built-in capability that is able to analyze data queries and provide users with optimization recommendations to improve database index to accelerate response time.\nWhile Couchbase is now jumping into the gen AI era with Capella IQ, it is still missing at least one critical element needed to help power AI applications: vector embedding support.\nThis is an increasingly common feature on existing database platforms, with multiple vendors including DataStax, Google with AlloyDB and MongoDB announcing support in 2023. \nSupport for vector embedding\u00a0is very much on Cain\u2019s mind, and it is part of his company\u2019s roadmap for inclusion in the near future. He explained that vector embedding support will be enabled in the future as an extension to the platform.\n\u201cOur underlying system is a multi-model caching JSON document database that performs both operational and analytical capabilities, and then we have architecturally enabled services like full text search,\u201d he said. \u201cWith a similar architecture we can approach vector and make that a seamless aspect of our platform, where developers can not only take advantage of those capabilities, but do more with less, with a true enterprise platform.\u201d"}, "Databricks bets big on activating data for marketers with Hightouch investment": {"Date": "August 30, 2023 6:00 AM", "Author": "Michael Nu\u00f1ez", "Link": "https://venturebeat.com/data-infrastructure/databricks-bets-big-on-activating-data-for-marketers-with-hightouch-investment/", "Content": "We\u2019re living in a time where just about every company is overflowing with data, but when it comes to getting meaningful insights from it \u2014 that\u2019s where organizations are often coming up short. \nEnter Databricks, a San Francisco-based heavyweight in the data and AI space. They\u2019re the team behind the lakehouse concept and they\u2019re on a mission: To monetize data by making insights more accessible. \nToday, Databricks has announced it\u2019s putting its money where its mouth is. The company\u2019s venture capital arm, Databricks Ventures, revealed in an exclusive VentureBeat report that it has made a strategic investment in promising San Francisco-based startup Hightouch, a software platform that helps businesses synchronize and activate all of their customer data.\nThe strategic investment is a part of a recent $38 million funding announcement aimed squarely at a core challenge that has troubled businesses: How to effectively harness the power of their vast data resources. The combined offering of Databricks\u2019 robust data platform and Hightouch\u2019s efficient data extraction capabilities is set to provide businesses with the tools needed to fully exploit their data, particularly in the field of marketing.\nSteve Sobel, who leads communications, media and entertainment at Databricks, explained the essence of the partnership in an interview with VentureBeat. \u201cWhat we\u2019re delivering with Hightouch is all around making data usable,\u201d he said. \u201cIt\u2019s about helping organizations through their enterprise data challenges and strategy.\u201d \nSobel\u2019s comments underscore Databricks\u2019 game plan to position itself as a vertical player in the sector, focusing on speaking the language of the customer and the industry. \u201cWe live in an era where every industry is moving toward direct-to-consumer,\u201d he said. \u201cOptimizing marketing and delivering a superior, personalized experience across any channel, anywhere, anytime is essential.\u201d\nHightouch cofounder and co-CEO Kashish Gupta offered a complementary perspective, explaining the \u201cmatch booster\u201d concept, a feature built into Hightouch that harmonizes first-party data with third-party datasets. \u201cThis approach allows businesses to reach their customers across a multitude of different channels,\u201d said Gupta.\nHe further explained the convergence of data and marketing strategies, saying: \u201cA data strategy and marketing strategy have actually become one in the current business landscape. Personalization based on factors such as zip code, last login time and myriad other activities now decisively influences these strategies.\u201d\nReflecting on the surge in digital data, Gupta pointed out: \u201cCompanies have more data than ever due to digital transformation. Extracting value out of that data by optimizing marketing using the data is truly where this partner strategy delivers.\u201d\n(Editor note: To help enterprise executives learn more about how to manage their data to prepare for generative AI applications, VentureBeat is hosting its Data Summit 2023 on November 15. The event will feature networking opportunities and sessions on topics such as data lakes, data fabrics, data governance and data ethics. Pre-registration for a 50% discount is open now.)\nFounded in 2020 by Gupta, a former Bessemer Venture Partners investor, and former Segment engineers Tejas Manohar and Josh Curl, Hightouch helps customers leverage their data warehouse as a single source of truth for their business teams.\nBy using Hightouch\u2019s reverse ETL (extract, transform and load) technology, customers can access, explore and sync data from their data warehouse to more than 200 SaaS tools such as Salesforce, HubSpot, Facebook and TikTok, without relying on engineering resources.\nHightouch claims to have hundreds of customers already across various verticals and industries, including the NBA, Grammarly, PetSmart, Imperfect Foods and Betterment. For context on its rapid growth, the company says it increased its revenue three times in the first half of 2022 alone and has grown its team from 40 employees in 2021 to 93 this year.\nThe new funding will be used to invest in product development, especially in the areas of customer understanding and out-of-the-box machine learning (ML) models, according to Gupta. Hightouch also plans to expand its go-to-market activities and hire more talent across different functions.\nGupta said that the company\u2019s rapid growth has been driven by customer demand and product market fit. He said that Hightouch\u2019s vision is to democratize data for all business teams by enabling them to use data from their data warehouse without code or engineers.\nHightouch is one of the pioneers of the reverse ETL category, which is rapidly growing as more businesses adopt data warehouses as their source of truth. According to Gartner, the number of enterprises implementing AI grew by 270% in the past four years and tripled in the past year, driving an increase in streaming data and analytics infrastructures with it. This creates a huge opportunity for platforms like Hightouch that can help businesses activate their data and apply AI to it."}, "Confirm raises $6.2 million to bring generative AI and network analysis to performance reviews": {"Date": "August 30, 2023 5:00 AM", "Author": "Carl Franzen", "Link": "https://venturebeat.com/enterprise-analytics/confirm-raises-6-2-million-to-bring-generative-ai-and-network-analysis-to-performance-reviews/", "Content": "Does anybody like hearing the phrase, \u201cIt\u2019s performance review season, again\u201d? \nIn most organizations where this author has ever worked (and he has worked at many), neither managers nor employees particularly relished the process of giving and receiving performance reviews. \nStill, many companies insist on them as a way of evaluating their talent and ensuring that high performers are rewarded with promotions or new opportunities, while low performers are identified and put on a path to improvement \u2014 or toward exiting the company. Yet, when administered by human beings \u2014 be they managers or peers \u2014 performance reviews can feel like personal attacks.\nConfirm thinks it has a better way forward. The San Francisco-based startup announced it has raised $6.2 million in series A funding (and a total of $11.4 million) to transform the performance review process from the ground up, incorporating \u201corganizational network analysis (ONA),\u201d an approach the consulting giant Deloitte describes as \u201c\u200bvisualizing and analyzing formal and informal relationships in your organization,\u201d as well as generative AI in the form of OpenAI\u2019s GPT-4, to deliver more fair, scientific and efficient performance reviews. \nThe round was spearheaded by Spero Ventures, and saw participation from SHRMLabs, Elefund, Gaingels and Black Angel Group as well as some of Confirm\u2019s existing clients.\nAccording to Confirm, traditional performance review methods like continuous feedback and 360-degree assessments often muddy the waters instead of clearing them. Confirm is looking to change this by making performance reviews more straightforward and data-driven. \nConfirm\u2019s approach measures employee performance by examining how all employees in the company view one another. ONA operates on the principle that performance isn\u2019t an isolated metric, but a network of relationships and influences within the workplace.\nIn fact, Confirm\u2019s prior research published in Fast Company found that male employees received 25% higher ratings than female employees on average from managers, compared to the network ratings for both groups. \nIt also offers GPT-4-created drafts of performance reviews customized to each specific employee with input from their peers and managers; auto-generated employee survey results; and auto-calibrated ratings for employees that seek to minimize bias from any one particular manager or another. \nConfirm was founded not too long ago in 2019, but companies like Canada Goose, Niantic and Thoropass have already been reaping the benefits of its performance review platform. \nThoropass, for instance, managed to identify and keep all of its top performers during the wave of employee turnover known as \u201cThe Great Resignation,\u201d in the late stages of the COVID-19 pandemic. \nAccording to Joe Bast, VP of people and operations at Thoropass, ONA has been a game-changer, helping the company understand not just high and low performers, but also who the real influencers within the company are.\nThe company also earned a \u201cWorld Changing Ideas Award\u201d from Fast Company, and an HR Tech Award for Best Talent Intelligence Solution from Lighthouse Research and Advisory. It was chosen by SHRMLabs for its 2023 WorkplaceTech Accelerator program, a platform that helps promising startups grow. \nWhile every organization \u2014 from large to small, from established longstanding leaders to nimble new startups \u2014 has its own culture and politics, those shouldn\u2019t really influence performance reviews, according to Confirm\u2019s vision of the future.\nDavid Murray, cofounder and president, wants to create \u201ca world where employees are recognized and rewarded for their hard work and positive impact, not their ability to play office politics.\u201d\nAnd, in a time where remote and hybrid teams are commonplace, there may not even be a real opportunity to evaluate someone face-to-face. Data-driven performance reviews matter more than ever, and Confirm aims to be the first name you think of when it comes time to do them \u2014 hopefully with a lot less dread than before. "}, "Runway announces \u2018Creative Partners Program\u2019 giving select users unlimited plans, new features": {"Date": "August 29, 2023 4:02 PM", "Author": "Carl Franzen", "Link": "https://venturebeat.com/ai/runway-announces-creative-partners-program-giving-select-users-unlimited-plans-new-features/", "Content": "RunwayML, the New York City-based startup that\u2019s raised hundreds of millions in venture funding to develop generative AI video creation tools, has announced it will begin granting a select group of users early access to new features and and AI models. \nThe company announced its new Runway Creative Partners Program on X (formerly Twitter), writing, \u201cThis program provides a select group of artists and creators with exclusive access to new Runway tools and models, Unlimited plans, 1 million credits, early access to new features and more.\u201d \n\u201cIt\u2019s all about being in the right place at the right time,\u201d Runway CEO and founder Crist\u00f3bal Valenzuela posted on X.\nOn its website, Runway goes into more detail about what the Creative Partners Program will offer. Among the features are \u201cdirect access to the Runway team\u201d and \u201cpriority access to Runway Studios grants.\u201d\nRunway\u2019s pricing structure requires using several proprietary credits to generate each video through its Gen-1 and Gen-2 multimodal video generation AI tools (users can generate videos from existing videos, text prompts, and imagery). \nWhile the program does have a free tier with 125 non-renewable credits, the Standard Plan costs $12 per month per user for 625 credits that renew each month, while the Unlimited Plan tier costs $76 per user per month, but grants each user 2,250 credits/month of video generations in Gen-1 and Gen-2, and unlimited credits in a slower \u201crelaxed\u201d generation mode. \nThe Unlimited plan with a million credits to start is a major win for potential users. \nIn addition, the company has continually updated and expanded its gen AI offerings, moving from the text-to-video Gen-1 release in February of this year, to a video-to-video Gen-1 mobile app in April, to the release of the text/video/image-to-video Gen-2 for desktop and mobile in June. Just this month, the company released a new \u201cWatch\u201d tab to show off the video creations of its users, similar to YouTube. \nTherefore, it stands to reason that the company will have more new features and services soon \u2014 and it is promising to give them to those accepted into its Creative Partners Program first.\nThe company is for now open to considering seemingly any and all applicants, asking them to fill out a form on its website with fields for the user\u2019s name, pronouns, portfolio and social media accounts.\nWhen it comes to who is eligible, a Runway spokesperson emailed VentureBeat the following statement: \n\u201cAnyone from anywhere in the world is welcome to apply. We\u2019re looking for creators who are using AI tools and techniques to push the boundaries of creativity. It\u2019s not required to have a paid Runway account to be admitted.\n\u201cApplications will be accepted on a rolling basis over the coming weeks and months, and creators who are accepted will announce their involvement to their own communities at their discretion.\u201d\nThe obvious comparison to Runway is increasingly YouTube, although the latter is of course not limited to, nor does it presently offer, gen AI video creation tools and videos.\nBut YouTube paved the way in building a robust ecosystem of amateur (and pro) video creators, which it sought to nurture and continues to support through its YouTube Partner Program (YPP), which allows creators to monetize their videos through subscriptions, ecommerce affiliate links and product mentions, advertising, digital stickers and more. \nYouTube itself funded several higher-production TV shows and films through its YouTube Originals brand, including the Karate Kid spinoff Cobra Kai, although YouTube ultimately canceled its scripted development arm and that series was later canceled and picked up by rival Netflix. \nIt\u2019s unclear just how much of YouTube\u2019s playbook Runway may seek to emulate, but launching a Creative Partners Program is a similar starting move for creating a thriving creator ecosystem, and seems like the necessary first step in making the dominant AI video platform. "}, "UserTesting expands platform with generative AI to scale human insights": {"Date": "August 29, 2023 1:00 PM", "Author": "Sean Michael Kerner", "Link": "https://venturebeat.com/ai/usertesting-expands-platform-with-generative-ai-to-scale-human-insights/", "Content": "UserTesting is kicking off its Human Insights Summit today with the launch of a new set of generative AI powered capabilities for its platform.\nThe new features that the company is simply calling UserTesting AI are intended to help customers scale up experience research efforts using AI. The initial set of tools benefit from an integration with OpenAI to help users more easily generate summaries and build reports from research data. They extend existing AI capabilities that UserTesting has developed in-house in recent years to help organizations to better understand user behavior and sentiment for products and services. \nBack in April, UserTesting launched its machine learning (ML)-powered friction detection capability for behavioral analytics.\nThe goal with the new UserTesting AI tools is to go beyond what the company has already been doing and tap into the power of gen AI technologies like OpenAI\u2019s ChatGPT.\n\u201cUserTesting AI is a set of capabilities that are designed to be easily understood by our customers as being AI powered, that help a research, design, marketing or product team, essentially achieve more throughput,\u201d Andy MacMillan, UserTesting CEO, told VentureBeat in an exclusive interview.\nTo date, much of the AI capabilities that UserTesting has provided to its users falls within the domain of ML.\nMacMillan said that UserTesting has built its own ML models to take data from its platform, which enables teams to test how users interact with and experience a service or application. UserTesting records the user sessions and then uses its ML models to derive insights. The models have helped to identify things like sentiment, intent and where users get stuck in a workflow.\u00a0\nWith the new UserTesting AI tools, the company isn\u2019t just sending raw data to the gen AI model to process. MacMillan emphasized that UserTesting is using the gen AI alongside its existing models.\n\u201cWe\u2019re taking a lot of those ML outputs, where we\u2019ve extracted what a researcher would find interesting, the friction, the insights, the suggestions, in addition to the transcripts, and we\u2019re providing that and we\u2019re creating tasks, summaries and research report summaries using large language models (LLMs),\u201d MacMillan said.\nTo date, user experience researchers have largely had to write reports and summaries on their own based on the data and insights from a UserTesting operation.\nBut now, for example, for a team that wants to test a new mobile app, the platform identifies and matches them with profiles of people ideal for testing. Users are then recorded as they test out the app prototype, with UserTesting ML models identifying interesting data points. The user is also recorded with video and audio and the entire sessions is transcribed.\n\u201cWe run all those data streams through our ML models that help extract interesting moments,\u201d said MacMillan.\nThe UserTesting platform then provides a results page that provides a list of interesting data points and highlights from the session. With UserTesting AI, researchers now get a full summary and report generated base on detailed findings. The report and summaries generated by AI will also have specific citations and references that can help researchers dig into specific data points.\nWhile there is some concern with the broader use of gen AI and how it could have potential bias, MacMillan said that UserTesting AI could actually help to reduce potential bias.\n\u201cWe think UserTesting AI can help our customers be more efficient,\u201d said MacMillan. \u201cI think it also helps researchers to avoid missing something, and it can help avoid biases, so you as the person doing the research might have some biases and AI can help you maybe see things you might not see.\u201d"}, "OpenAI seeks to dismiss majority of Sarah Silverman\u2019s and authors\u2019 claims in ChatGPT lawsuits": {"Date": "August 29, 2023 12:45 PM", "Author": "Bryson Masse", "Link": "https://venturebeat.com/ai/openai-seeks-to-dismiss-majority-of-sarah-silvermans-and-authors-claims-in-chatgpt-lawsuits/", "Content": "OpenAI, the organization behind ChatGPT and its underlying large language models (LLMs) GPT-3.5 and GPT-4, has filed motions to dismiss in two copyright lawsuits levied against the company for using copyrighted materials in AI model training data. The plaintiffs include a pair of U.S. authors and a second group including comedian and actor Sarah Silverman.\nIn the filings submitted to the U.S. District Court for the Northern District of California on Monday, OpenAI requested the dismissal of five out of the six counts lodged in the lawsuits. The company defended the transformative nature of its LLM technology, underscoring the need to balance copyright protection and technological advancement. OpenAI also said that it planned to contest the remaining count of direct copyright infringement in court as a matter of law.\nThe motions addressed the claims asserted in the copyright lawsuits and aimed to elucidate the case\u2019s merits. OpenAI underscored the value and potential of AI, particularly ChatGPT, in enhancing productivity, aiding in coding and simplifying daily tasks. The company likened ChatGPT\u2019s impact to a significant intellectual revolution, drawing parallels with the invention of the printing press.\n\u201cYou can start to see the story that they\u2019re going to tell here, which is that copyright has limitations to it. It doesn\u2019t extend to facts and ideas,\u201d said Gregory Leighton, a privacy law specialist at law firm Polsinelli. \u201cEven if a work is copyright[ed] and an LLM [is] processing it or then producing a summary of it back or something like that, that\u2019s not a derivative work on its face.\u201d\nOpenAI based its defense on the fundamental facts of the LLM technology: It is a type of neural network trained on extensive text data to comprehend human language effectively, and it enables users to input text prompts and receive corresponding generated content. Per the filings, OpenAI claims its products merge LLMs with parameters ensuring the accuracy, relevance, safety and utility of the produced outputs.\u00a0\u00a0\nThe plaintiffs argued that ChatGPT was trained without permission using their copyrighted works. In response, OpenAI contended that this perspective overlooks the broader implications of copyright law, including fair use exceptions.\nThe company asserted that fair use can accommodate transformative innovations like LLMs and is aligned with the constitutional intent of copyright law to foster scientific and artistic progress. \n\u201cIt\u2019s true substantively, but there\u2019s an interesting sleight of hand going on here,\u201d said Leighton.\n\u201cYou shouldn\u2019t be talking about fair use in a motion to dismiss, because fair use is an affirmative defense. It\u2019s actually something that they, as the defendant, have to affirmatively plead and prove up,\u201d he said.\nOpenAI\u2019s motion cited court cases where the fair use doctrine protected innovative uses of copyrighted materials. It called for the dismissal of secondary claims from the plaintiffs, including vicarious copyright infringement, violations of the Digital Millennium Copyright Act (DMCA), violations of California\u2019s Unfair Competition Law (UCL), negligence and unjust enrichment. OpenAI challenged the legal validity of these claims and argued for their removal based on flawed legal reasoning.\n\u201cThese were probably always the ancillary and companion claims, and the main meal here is copyright infringement,\u201d said Leighton.\nVicarious copyright infringement is applied in cases where a party is in indirect benefit of copyright infringement, committed by another person. OpenAI stated that the plaintiff\u2019s allegations of direct infringement were not valid as a matter of law, nor did it have any \u201cright and ability to supervise\u201d and it did not end up having any direct financial interest.\nOpenAI offered refuting evidence to the plaintiffs\u2019 various theories of why it violated vicarious infringement rules, the DMCA, and UCL, claims including: Every ChatGPT output is an infringing derivative work of their copyrighted books; and LLM training removes the \u201ccopyright management information\u201d from the specified works.\nOpenAI contends that the plaintiffs don\u2019t have enough evidence to claim that LLMs produce derivative works, and that if those standards are applied on a wider scale, photographers would be able to sue painters who reference their material. The evidence offered by the plaintiffs about copyright management information was contradictory and failed to show how it was purposely removed, OpenAI said.\u00a0\nThe company also found deficiencies in the negligence and unjust enrichment claims, saying that there was no grounds for negligence as OpenAI or its users would be engaging in intentional acts and OpenAI did not owe the plaintiffs a duty of care.\u00a0\nNor, according to the filings, was there any evidence to support the claim that OpenAI held on to profits or benefits from the infringed material.\u00a0\nFinally, OpenAI argued that both the negligence and unjust enrichment state law claims are preempted by federal copyright law.\n\u201cIt might take a month or six weeks, but the plaintiffs will file a response where they\u2019ll have to say why they think these claims should stay in,\u201d said Leighton. \u201cThat actually might be quite interesting just to get their take of where they\u2019re going with this.\u201d\nOpenAI\u2019s dismissal motion is founded on ChatGPT\u2019s transformative nature, fair use principles and perceived legal shortcomings in the plaintiffs\u2019 ancillary claims. \nThe motions provided insight into OpenAI\u2019s overall defense of its ongoing operations as it navigates the complex intersection of copyright law and AI technology advancement. \nWhile Leighton believes that this particular motion to dismiss may not have huge immediate effects, the stakes in the overall case remain high. In determining the extent to which large language models can be trained on copyrighted works without infringing copyright, the outcome of the lawsuits could have major implications for AI use cases, especially if it is determined that ingesting copyrighted works always infringes copyright.\n\u201cWe\u2019re getting the first real insight into where this is really going to go,\u201d said Leighton. \u201cThey\u2019re introducing these things to the judge, not because it really has anything to do with the motion to dismiss itself and what they\u2019re trying to accomplish procedurally, but it\u2019s the intro thematically to [OpenAI\u2019s] side of the case here.\u201d\nAs the lawsuits unfold, this legal conflict will likely define the future of copyright law and technological progress."}, "Google reveals BigQuery innovations to transform working with data": {"Date": "August 29, 2023 10:37 AM", "Author": "Shubham Sharma", "Link": "https://venturebeat.com/data-infrastructure/google-reveals-bigquery-innovations-to-transform-working-with-data/", "Content": "Google is pushing the bar on how teams work with their data.\nToday at its annual Cloud Next conference, the internet giant announced major improvements for BigQuery \u2014 its fully managed, serverless data warehouse, including a unified experience aimed at interconnecting data and workloads. The company also shared how it plans to bring AI to the data stored in the platform, and how it plans to leverage its generative AI collaborator to boost the productivity of teams looking to consume insights from data.\n\u201cThese innovations will help organizations harness the potential of data and AI to realize business value \u2014 from personalizing customer experiences, improving supply chain efficiency, and helping reduce operating costs, to helping drive incremental revenue,\u201d Gerrit Kazmaier, VP and GM for data and analytics at Google, wrote in a blog post.\nHowever, it must be noted that most of these capabilities are still being previewed and not generally available to customers.\nWithin BigQuery, which allows users to perform scalable analysis over petabytes of data, Google is adding a unified interface called BigQuery Studio. This offering will provide users with a single environment for data engineering, analytics and predictive analysis.\nUntil now, data teams had to work with different tools for different tasks, from managing data warehouses and data lakes to governance and machine learning (ML). Handling these tools took a lot of time and slowed down productivity. With BigQuery Studio, Google is enabling these teams to work with all of these tools in one place, to quickly discover, prepare and analyze their datasets and run ML workloads on them.\n\u201cBigQuery Studio provides data teams with a single interface for your data analytics in Google Cloud, including editing of SQL, Python, Spark and other languages, to easily run analytics at petabyte scale without any additional infrastructure management overhead,\u201d a company spokesperson told VentureBeat. \u201cThis means a data worker doesn\u2019t have to switch from one tool to another; it\u2019s all in one place, making their lives easier and getting to results faster.\u201d\nThe offering is now available in preview and is already being tested by multiple enterprises including Shopify. Kazmaier also said Google is adding enhanced support for open-source formats like Hudi and Delta Lake within BigLake; performance acceleration for Apache Iceberg; and cross-cloud materialized views and cross-cloud joins in BigQuery Omni to analyze and train on data without moving it.\n(Editor Note: To help enterprise executives learn more about how to manage their data to prepare for generative AI applications, VentureBeat is hosting its Data Summit 2023 on November 15. The event will feature networking opportunities and sessions on topics such as data lakes, data fabrics, data governance and data ethics. Pre-registration for a 50% discount is open now.)\nAlong with BigQuery Studio, Google is providing access to Vertex AI foundation models, including PaLM 2, directly from BigQuery. This will allow data teams using BigQueryML (to create and run ML models on their datasets) to scale SQL statements against large language models (LLMs) and gain more insights, quickly and easily. The company also said it is adding new model inference capabilities and vector embeddings in BigQuery to help teams run LLMs at scale on unstructured datasets.\n\u201cUsing new model inference in BigQuery, customers can run model inferences across formats like TensorFlow, ONNX and XGBoost,\u201d Kazmaier noted. \u201cIn addition, new capabilities for real-time inference can identify patterns and automatically generate alerts.\u201d\nFinally, the company said it is integrating its always-on generative AI-powered collaborator, Duet AI, into BigQuery, Looker and Dataplex. This will bring natural language interaction and automatic recommendations to these tools, boosting the productivity of teams and opening access to more users. \nThis integration is also in preview with no word on general availability yet.\nGoogle Cloud Next runs through August 31."}, "Google shows off what\u2019s next for Vertex AI, foundation models": {"Date": "August 29, 2023 8:44 AM", "Author": "Sean Michael Kerner", "Link": "https://venturebeat.com/ai/google-shows-off-whats-next-for-vertex-ai-foundation-models/", "Content": "AI is a core focus for Google, and at its Google Next event today, the company announced a series of updates across its portfolio that benefit from the power of generative AI.\nFront and center are enhancements and new capabilities across Google\u2019s Vertex AI platform, including both developer tooling and foundation models.\nGoogle\u2019s PaLM 2 large language model (LLM), first announced at the Google I/O conference in May, is getting an incremental boost with more language support and longer token length. The Codey code generation LLM and the Imagen image generation LLMs are also getting updates to improve performance and quality.\nVertex AI is being expanded with new extensions to make it easier for developers to connect to data sources. Google is making both the Vertex AI Search and Vertex AI Conversation services generally available, providing search and chatbot capabilities to Google\u2019s enterprise users.\nRounding out Google\u2019s Vertex AI update is the Colab Enterprise service, which provides compliance and security capabilities to the data science notebook platform.\u00a0\nIn a press briefing ahead of the Google Next conference, June Yang, VP, cloud AI and industry solutions at Google, detailed some of the Vertex AI-related updates.\n\u201cAI is undergoing a major shift with the rise of foundation models. Now you can leverage these foundation models for a variety of use cases without ML [machine learning] expertise,\u201d she said. \u201cThis is really a game-changer for AI, especially for the enterprises.\u201d\nGoogle builds its own foundation models and also provides support for a number of third-party models that can run on Google Cloud. Google\u2019s flagship model is PaLM 2, available in a number of configurations. One is the text model, which is being enhanced with a larger input token length context window, something Yang said has been a \u201ckey request\u201d from customers. Expanded from 4,000 to 32,000 tokens, PaLM 2\u2019s context window will enable text users to process longer-form documents than before.\nPaLM 2 is also being expanded with more language support, now with the general availability of 38 languages including Arabic, Chinese, Japanese, German and Spanish.\nThe Codey text-to-code LLM is another foundation model that has received an update, one which, according to Google, provides up to a 25% quality improvement for code generation.\n\u201cLeveraging our Codey foundation model, partners like GitLab are helping developers to stay in the flow by predicting and completing lines of code, generating test cases, explaining code and many more use cases,\u201d Yang said.\nThe Imagen text-to-image LLM is being upgraded as well. The big new feature, one Yang referred to as one of the coolest she\u2019s seen, is something Google calls \u201cstyle tuning.\u201d\n\u201cOur customers can now create images aligned to their specific brand guidelines or other creative needs with as few as 10 reference images,\u201d she said.\nFor example, Yang said that with style tuning an Imagen user can apply corporate guidelines to either a newly generated image or an existing one, and the resulting Imagen image will have the appropriate style built into it.\nWhile PaLM 2 is Google\u2019s flagship foundation model, the company is also providing third-party LLM access on Google Cloud. The ability to support multiple foundation models is increasingly becoming table stakes for cloud providers. Amazon, for example, supports multiple third-party models with its Bedrock service.\nAmong the new third-party models that Google now supports is Meta\u2019s Llama 2, which was just released in July. Yang said that Google will enable users to use reinforcement learning with human feedback (RLHF) so organizations can further train Llama 2 on their own enterprise data to get more relevant and precise results.\u00a0\nGoogle will also be supporting Anthropic\u2019s Claude 2 model and has pledged to support TII\u2019s Falcon.\nFoundation models on their own are interesting, but they get a whole lot more interesting when enterprises can connect them to their own data to take action. That\u2019s where the new Vertex AI Extensions tools fit in.\nYang said that developers can use the Extensions to build powerful generative AI applications like digital assistants, customized search engines and automated workflows.\n\u201cVertex AI Extensions are a set of fully managed developer tools, which connect models via API to real-world data and enable models to perform real-world actions,\u201d Yang said."}, "Quantum threats loom in Gartner\u2019s 2023 Hype Cycle for data security": {"Date": "August 29, 2023 7:44 AM", "Author": "Louis Columbus", "Link": "https://venturebeat.com/security/whats-new-in-gartners-hype-cycle-for-data-security-in-2023/", "Content": "The best-run organizations prioritize cybersecurity spending as a business decision first, and Gartner\u2019s Hype Cycle for Data Security 2023 reflects the increasing dominance of this approach. Key technologies needed for assessing and quantifying cloud risk are maturing, and new technologies to protect against emerging threats are predicted to gain traction.\u00a0\nGartner sees the core technologies needed to validate and quantify cyber-risk maturing quickly as more organizations focus on measuring their cybersecurity investments\u2019 impact. CISOs tell VentureBeat that it is a new era of financial accountability, and that extends to new technologies for securing data stored in multicloud tech stacks and across networks globally. Getting control of cybersecurity costs is becoming a much higher priority as boards of directors look at how data security spending protects, and potentially grows, revenue.\nGartner\u2019s latest Hype Cycle for data security dovetails with what CISOs, CIOs and their teams tell VentureBeat, especially in compliance-centric industries such as insurance, financial services, institutional banking and securities investments. Gartner added five new technologies this year: crypto-agility, post-quantum cryptography, quantum key distribution, sovereign data strategies and digital communications governance. Eight technologies have been removed or reassigned this year.\u00a0\nGetting integration right in data security at the enterprise level has always been a challenge. The need for more secure approaches to data integration has led to a proliferation of solutions over the years, some more secure than others. Gartner predicts these challenges will shift or consolidate data security technologies, including data security posture management (DSPM), data security platforms (DSPs) and multicloud database activity monitoring (DAM).\u00a0\nCISOs also say they are monitoring quantum computing as an evolving potential threat and have delegated monitoring it to their strategic IT planning teams. Gartner also introduced crypto-agility in this year\u2019s Hype Cycle, responding to its clients\u2019 requests for as much data and knowledge as possible in this area.\u00a0\nCISOs and the teams they manage tell VentureBeat that protecting data in the cloud, and the many identities associated with each data source across multicloud configurations, is getting more challenging given the need to provide access rights by data type while still tracking compliance. \nThat\u2019s made even more difficult by the\u00a0exponential growth of machine identities across enterprises\u2019 cloud instances. This year\u2019s Hype Cycle for data security underscores this and other trends summarized here.\nBoard members regularly question CISOs about governance and risk management. CISOs tell VentureBeat that while board members know risk management at an expert level, they need to have the technology-based context of data governance and risk management defined from a tech stack and multicloud perspective. \nThese dynamics between boards and CISOs are playing out across hundreds of companies as data governance and risk management dominate Gartner\u2019s discussions in this year\u2019s Hype Cycle. Boards want to know how to accurately quantify cyber-risk, which drives greater compliance. CISOs say that financial data risk assessment (FinDRA) is board-driven and weren\u2019t surprised it appears on the Hype Cycle.\u00a0\nNearly every business relies on cloud services for a portion, if not all, of their infrastructure and application suites. Gartner sees this as a potential risk for data and has identified a series of technologies and techniques on the Hype Cycle to protect data in use and at rest. \nThese include confidentiality, homomorphic encryption, differential privacy and secure multiparty computation (SMPC). Confidentiality relies on hardware-based trusted execution environments to isolate data processing, while SMPC allows collaborative data analysis without exposing raw data. The presence of these data-in-use technologies on the Hype Cycle demonstrate the shift from data security at rest to data security in transit.\nMuch has been written and predicted about when quantum computing will break encryption. In reality, no one knows when it will happen; however, there\u2019s wide consensus that quantum technologies are progressing in that direction. CISOs VentureBeat interviewed on the topic see cryptography at varying levels of urgency depending on their business models, industries and how reliant they are on legacy encryption.\nGartner added both crypto-agility and post-quantum cryptography to the Hype Cycle for the first time this year. CISOs are pragmatic about technologies with as long a runway as these have. In previous interviews, CISOs told VentureBeat they could see where post-quantum cryptography could strengthen zero-trust frameworks in the long term.\nTogether, Gartner\u2019s five new hype cycle technologies prepare CISOs for the next generation of quantum threats while addressing the most challenging aspects of governance and data sovereignty. The five newly added technologies are briefly summarized here:\u00a0\nThe purpose of crypto-agility is to upgrade encryption algorithms used in applications and systems in real time, alleviating the risk of a quantum-based breach. Gartner writes that this will enable organizations to replace vulnerable algorithms with new post-quantum cryptography to ward off attacks using quantum computing to defeat encryption. Crypto-agility offers CISOs a path to secure encryption as quantum capabilities advance over the next five to seven years.\u00a0\nGartner defines this new technology as based on new quantum-safe algorithms, such as lattice cryptography, that are resistant to decryption by quantum computers. The use case Gartner discusses in the Hype Cycle centers on using this technology in a pre-emptive strategy against quantum-based threats.\nVentureBeat\u2019s interviews with CISOs at financial trading firms revealed that pro-forma tech stacks already defend against quantum computing risks and threats. Gartner\u2019s latest addition will likely be added to roadmaps for further evaluation by those CISOs responsible for commercial banking and other financial services and institutions. Leading vendors include Amazon, IBM and Microsoft.\nThis technology works by using quantum physics principles, including photon entanglement, to create and exchange tamper-evident keys. Gartner considers QKD a niche technology today. But given its nature, uses in applications critical to national security are a natural extension of its strengths, as it\u2019s anticipated to be useful for exchanging high-value data. Leading vendors include ID Quantique, MagiQ Technologies and Toshiba.\nThis is a new addition to the Hype Cycle that supports data security governance, privacy impact assessment, financial data risk assessment (FinDRA) and data risk assessment. Sovereign data strategies reflect efforts by governments to provide strong governance and data security for their citizens and economy.\nPrivacy, security, access, use, retention, sharing regulations, processing and persistence are examples cited by Gartner. According to the firm, sovereign data strategies will eventually become table stakes for any business that needs to complete transactions across sovereign jurisdictions.\nDigital communications governance (DCG) solutions monitor, analyze and enforce employee messaging, voice and video compliance policies. DCG platforms also manage regulatory and corporate governance requirements with data retention, surveillance, behavioral analytics and e-discovery. They help compliance teams identify misconduct and comply with regulations by monitoring communications data.\nDCG also helps CIOs and CISOs manage employee messaging, voice and video platform risks by consolidating access and enforcement across communication channels. Leading vendors include Global Relay, Proofpoint and Veritas.\u00a0\nTen key trends emerge from this year\u2019s Hype Cycle. Data governance, risk management and compliance are core drivers of the data security market. Gartner believes that preparing for quantum computing threats, convergence and integration of security tools, and managing unknown shadow IT data are high priorities.\u00a0\nThe following matrix compares the most influential factors, in order of priority, that are influencing the future of data security."}, "AI to star in the launch of Webflow\u2019s built-in app ecosystem": {"Date": "August 29, 2023 6:30 AM", "Author": "Bryson Masse", "Link": "https://venturebeat.com/ai/ai-to-star-in-the-launch-of-webflows-built-in-app-ecosystem/", "Content": "Webflow, the low-code web development platform, has fully opened up its new app ecosystem, establishing a platform where third-party developers can integrate their applications directly into the Webflow designer.\u00a0\nWebflow CTO Allan Leinwand shared insights about the vision for this ecosystem in an exclusive interview with VentureBeat, explaining that new APIs will allow apps to have a visible presence directly on the Webflow designer canvas. Additionally, Webflow has enhanced their backend APIs so apps can interact with Webflow forms, content and other data. The initiative has been a year in the making, with the aim to expose more functionality of Webflow designer and data models for developers to build deeply integrated apps.\n\u201cWe have about 200,000 designers and companies that use Webflow and visual design to create these really fully customized professional websites without needing to code,\u201d said Leinwand. \u201cPart of that is we know we can\u2019t write every piece of functionality for everyone else\u2019s designers and companies. So we\u2019ve been working on exposing the surface area of the designer, and of our core data models, for about a year now.\u201d\nLeinwand believes this combination of front-end and back-end access will be potent, as apps can put functionality right in front of designers while also connecting to Webflow sites. Drawing parallels to successful app marketplaces like Shopify (where he was former CTO), Leinwand envisions Webflow becoming a similar platform for designers. The ecosystem is open to all developers, whether targeting niche markets or larger ones.\n\u201cDevelopers realize that no-code development is the future, and they realize that people are moving into a no-code environment,\u201d said Leinwand. \u201cWith generative AI, it even allows you to turn that up a notch, to really help generate some of that content and generate some of that design in an amazing way.\u201d\nJoining big names like Hubspot, Unspalsh and Typeform, one of the first apps to launch with this new ecosystem is Jasper AI, a marketing-focused AI writing assistant. Jasper AI will be able to generate relevant and contextual marketing copy content like blog posts or product descriptions within the Webflow designer, with changes saved directly into the Webflow backend. According to Leinwand, this seamless integration exemplifies how apps can leverage AI and other technologies to enhance the designer experience.\nFor developers looking to contribute to the ecosystem, Leinwand suggests focusing on addressing unmet needs within the design market using both the new frontend and backend APIs. As the Webflow ecosystem is just beginning, developers have the opportunity to get involved early. Leinwand invites developers to bring their ideas and start developing on the platform.\nIn a call with VentureBeat, Jasper AI President Shane Orlick discussed the company\u2019s partnership with Webflow, emphasizing how gen AI is empowering creators. Jasper AI\u2019s content creation platform, which businesses can use to generate high-quality marketing and advertising drafts at scale, is now accessible directly within the Webflow platform thanks to its API integration. This enables Webflow users to generate content directly in the app while building websites.\n\u201cIt was really quick to get that vision lock,\u201d Orlick said about early conversations about integrating the Jasper AI platform in Webflow. \u201cWe didn\u2019t have the API. We had just started thinking about this. So once we had the API, it was really easy, because we actually have a solution that would fit nicely in their marketplace.\u201d\nOrlick believes that this partnership delivers more value for Webflow and drives adoption and engagement with their customers. Such partnerships enable the company to reach a new client-base, reducing the friction of AI adoption.\n\u201cWe just want to meet the customers where they are and deliver the better experience,\u201d said Orlick. \u201cAnd because we\u2019re only the app layer, we\u2019re not raising $500 million to blow into training models [so] we\u2019re able to just focus on the customer experience piece. That\u2019s why Webflow is so exciting.\u201d\nLooking ahead, Orlick sees significant opportunities in serving large enterprise customers through customized AI templates, style guides and collaborative workflows. \nYet, self-service and API-partner channels remain vital for driving leads to their core business. Orlick underscored how gen AI is transitioning from a novelty to an essential productivity tool. Partnerships like Webflow and Jasper that embed AI directly into creative workflows promise to unlock its full potential for both businesses and individuals."}, "Reveal Acquires Logikcull and IPRO": {"Date": "August 29, 2023 6:25 AM", "Author": "Press Release", "Link": "https://venturebeat.com/business/reveal-acquires-logikcull-and-ipro/", "Content": "\nDouble Acquisition Introduces First Unified AI-Powered eDiscovery Platform Capable of Tackling Any Legal Case at Scale\n\nCHICAGO\u2013(BUSINESS WIRE)\u2013August 29, 2023\u2013\nReveal, a global provider of a category-leading AI-powered eDiscovery platform, announced today it has acquired both Logikcull and IPRO, two other leading eDiscovery players. Together, the three companies offer the first end-to-end eDiscovery platform that addresses matters of all sizes and for all legal teams, from solo legal practitioners to the largest enterprise. The transactions, valued at more than $1 billion, were funded by Reveal\u2019s majority shareholder and leading software investment firm, K1 Investment Management.\nThe combination integrates Logikcull and IPRO\u2019s unique capabilities with Reveal\u2019s proven AI prowess to create an all-in-one hub of eDiscovery tools for matters of any size and scope. From self-service offerings for smaller cases to enterprise-grade solutions for complex legal challenges, Reveal now stands as the go-to partner for automating the practice of law.\n\u201cThe acquisitions of Logikcull and IPRO build on Reveal\u2019s growth strategy of integrating the best and most useful technologies into one platform so customers have greater choice and control over their eDiscovery workflows,\u201d said Wendell Jisa, Founder & CEO of Reveal. \u201cBy bringing together the strengths of all three companies, including Logikcull\u2019s intuitive, easy-to-use functionality and IPRO\u2019s global reach and information governance tools, Reveal is now able to serve the diverse needs of clients across the legal spectrum, from SMB to mid-market and enterprise.\u201d\nIn addition, the acquisitions will bring industry leading AI-powered eDiscovery solutions to an untapped global legal market. The company will now have employees stationed in more than two dozen countries, serving a customer base of over 4,000 clients.\n\u201cThese two acquisitions are a continuation of our commitment to bring together the best technologies and people to propel the practice of law into a new era,\u201d said Tarun Jain, Principal at K1 Investment Management. \u201cWith this combination, legal professionals will only have to look to one company to solve all their eDiscovery needs.\u201d\nBy integrating Logikcull and IPRO into Reveal\u2019s ecosystem, Reveal now offers the most advanced automation capabilities in the industry. Logikcull\u2019s seamless, self-service functionality enables users to efficiently handle simpler cases in-house, while Reveal\u2019s scalable, feature-rich platform helps tackle the most complex litigation matters. The combined suite covers every stage of the eDiscovery process, from data collection and processing to review and analysis, so legal experts can increase efficiency, reduce costs, and focus on higher-value tasks that better serve their clients.\nReveal\u2019s expanded suite of solutions is available immediately, offering day-one benefits including:\nAm Law 100 firms, Fortune 500 corporations, legal service providers, government agencies and financial institutions in more than 20 countries across five continents work collaboratively with Reveal to uncover insights faster and solve even the most complex legal challenges with the most advanced AI in the industry. For more information about Reveal, visit www.revealdata.com.\nAbout Reveal\nReveal provides leading document review technology, underpinned by leading processing, visual analytics, and artificial intelligence, all seamlessly integrated into a single platform for eDiscovery and investigations. Our software combines technology and human guidance to transform structured and unstructured data into actionable insight. We help organizations, including law firms, corporations, government agencies, and intelligence services, uncover more useful information faster by providing a seamless user experience and patented AI technology that is embedded within every phase of the eDiscovery process.\n\nView source version on businesswire.com: https://www.businesswire.com/news/home/20230829922415/en/\nMedia Contact: Liz Whelan312.315.0160liz@lwprconsulting.com"}, "Rockset to boost real-time database for AI era with $44M raise": {"Date": "August 29, 2023 6:10 AM", "Author": "Sean Michael Kerner", "Link": "https://venturebeat.com/data-infrastructure/rockset-to-boost-real-time-database-for-ai-era-with-44m-raise/", "Content": "Database vendor Rockset is raising $44 million in new funding, as demand for its real-time indexing capabilities grows in the modern generative AI era.\nThe new fundraise follows the company\u2019s series B round and brings total funding to date for the San Mateo, California-based company to $105 million. Icon Ventures led the new round, with participation from Glynn Capital, Four Rivers, K5 Global, Sequoia and Greylock.\nOver the course of 2023 in particular, Rockset has been growing its technology, which uses the open-source RocksDB persistent key-value store originally created at Meta (formerly Facebook) as a foundation. In March, Rockset rolled out a platform update designed to make its real-time indexing database dramatically faster. That update was followed in April by vector embedding support to help enable AI use cases.\n\u201cWe\u2019re getting pulled in more and more into AI applications that are getting built, and that is a very, very big platform shift that\u2019s happening,\u201d Venkat Venkataramani, cofounder and CEO of Rockset, told VentureBeat. \u201cFundamentally what we do is real-time indexing, and it turns out applications also need real-time indexing on vector embeddings.\u201d\nThe use of vector embeddings, stored in some form of vector database, has grown in 2023 with the rise of generative AI.\nVectors, numerical representations of data, are used to help power large language models (LLMs). There are a number of purpose-built vector databases, including Pinecone and Milvus, which join a growing number of existing database technologies including DataStax, MongoDB and Neo4j that support vector embeddings.\nInside Rockset, vector embeddings are supported as a data type known as an \u201carray of floats\u201d in the existing database. Venkataramani emphasized, however, that simply supporting vectors as a data type isn\u2019t what\u2019s particularly interesting to him.\nRather, what is more interesting from his perspective is how Rockset has now built a real-time index technology for the vector embeddings. The index provides a logical key for enabling search on a given set of data. Having the index updated in real time is critical for certain production use cases requiring the most updated information possible.\nAs it turns out, the same basic approach that Rockset has built for real-time indexing of metadata also works well for vectors. Having a real-time index that can query both regular data and vectors is useful for modern AI applications, according to Venkataramani.\n\u201cEvery AI application we were dealing with doesn\u2019t only work with vectors. There are always all these other database metadata fields associated with every one of them \u2014 and the application needs to query on all of them,\u201d he said.\nAt the foundation of Rockset\u2019s real-time database is the RocksDB data store, which the company has extended with the RocksDB Cloud technology.\nVenkataramani explained that Rockset has developed a number of advanced techniques with RocksDB Cloud that help accelerate indexing for all data types. He noted that RocksDB Cloud now has an approximate nearest neighbor (ANN) indexing implementation, which is critical to enabling real-time search on vector data.\n\u201cNow, like any other index in Rockset, once you build a similarity ANN index for a vector embeddings column, it\u2019s always up-to-date,\u201d Venkataramani said. \u201cIt just automatically keeps itself up-to-date across inserts, updates and deletes.\u201d\nRockset also integrates a distributed SQL engine for fast data queries. Venkataramani noted that the company\u2019s SQL engine is now able to execute real-time queries across all supported data types on the database.\n\u201cYou can now literally, in a single SQL query, do a whole bunch of filters and joins and aggregations, and also use a vector embedding to do ranking relevance in a similarity search use case,\u201d he said. \u201cA single SQL query is extremely efficient and very, very fast, because the SQL engine is built to power applications and not analysts that are waiting for reports.\u201d\nLooking forward, Venkataramani expects that there will be a lot more development of AI capabilities in Rockset. Among the future capabilities he\u2019s looking forward to is support for GPU acceleration to further speed queries for LLMs and generative AI use cases.\n\u201cThis industry is just getting started. This platform shift is not a fad; this is going to be a core part of every application,\u201d he said."}, "Travelshift Secures $10 Million USD Capital Raise": {"Date": "August 29, 2023 5:26 AM", "Author": "Press Release", "Link": "https://venturebeat.com/business/travelshift-secures-10-million-usd-capital-raise/", "Content": "REYKJAVIK, Iceland\u2013(BUSINESS WIRE)\u2013August 29, 2023\u2013\nTravelshift, the leading online travel agency (OTA) in Iceland has raised $10 million USD of capital from existing shareholders, raising the total funding amount to $30 million USD.\nThis press release features multimedia. View the full release here: https://www.businesswire.com/news/home/20230829071571/en/\nThe financing represents a vote of confidence from Travelshift\u2019s current investors in the company\u2019s growth trajectory and future potential. According to Harshal Chaudhari, President and Chief Investment Officer at GE Investment Management Co., \u201cWe are proud to continue supporting Travelshift\u2019s remarkable journey. The company\u2019s unwavering commitment to innovation and customer satisfaction has been instrumental in its success, and we firmly believe in its potential to further disrupt the leisure travel industry.\u201d\nThe latest funding round follows Travelshift\u2019s recent launch of Guide to Europe, a travel platform that solves the Connected Trip for the European leisure travel market. This innovative service, which is powered by AI, allows travelers to book everything they need in one checkout and manage their entire journey in one app. It also gives travelers access to thousands of itineraries that have been optimized with AI, with what is now the world\u2019s largest selection of vacation packages in Europe.\n\u201cWe are thrilled to receive the continued support and trust from our existing shareholders,\u201d said David Stewart, CEO of Travelshift. \u201cThis financing round enables us to accelerate our growth initiatives and continue to build the next generation of travel through innovative use and application of AI to deliver personalized and seamless travel experiences.\u201d\nTravelshift would like to express its sincere gratitude to its dedicated team, loyal customers, and steadfast shareholders for their continued support and belief in the company\u2019s vision.\nAbout Travelshift:\nTravelshift is an leading Icelandic online travel agency (OTA) that specializes in providing technology-driven travel solutions. With over a decade of experience in the industry, Travelshift is committed to revolutionizing how people travel, offering innovative services and exceptional customer experiences.\n\nView source version on businesswire.com: https://www.businesswire.com/news/home/20230829071571/en/\nFor media inquiries or further information, please contact:David StewartChief Executive OfficerEmail: dave@travelshift.com Phone: +354 791 9394"}, "Google brings new AI to AlloyDB and database migration service": {"Date": "August 29, 2023 5:00 AM", "Author": "Sean Michael Kerner", "Link": "https://venturebeat.com/ai/google-brings-new-ai-to-alloydb-and-database-migration-service/", "Content": "At the Google Cloud Next conference today, Google will announce a series of AI-powered updates across its portfolio, including its database platforms.\nAmong the AI focused database announcements is the introduction of AlloyDB AI, which brings vector embeddings to the PostgreSQL compatible cloud database. The new vector embeddings will also be part of the AlloyDB Omni service which is entering public preview today, enabling users to run AlloyDB outside of the Google Cloud.\nAlloyDB was first announced as a preview by Google in May 2022, providing both transactional and analytics capabilities with a PostgreSQL based database. The AlloyDB Omni platform was initially detailed by Google in March 2023, opening up the database to wider deployment options.\u00a0\nAI will also help to enable database migrations from the Oracle database to AlloyDB, with the new Duet AI capability in the Google Database Migration Service. Beyond AlloyDB, Google is also introducing the new Cloud Spanner Data Boost capability that will enable data sorted in the Cloud Spanner database to be more easily queried with Google BigQuery. Duet AI is also making its way into Cloud Spanner to help enable natural language queries for data operations.\n\u201cWe really see databases as helping to bridge the gap between large language models (LLMs) and AI apps,\u201d Andi Gutmans, VP and GM for databases at Google, told VentureBeat. \u201cCustomers, especially enterprise customers,\u00a0really like the ChatGPT experience, but ultimately they can\u2019t have something that is too creative, and they really need to anchor their generative AI apps in the actual enterprise data.\u201d\nVector enabled databases are increasingly critical to enabling databases to be data stores for AI applications.\nWhile there are purpose built vector databases like Pinecone and milvus, existing database platforms such as PostgreSQL have also increasingly made efforts to support vectors. In PostgreSQL, the open-source pgvector technology is often used in the open-source database to support vectors.\u00a0Some vendors such as Neon, which is a PostgreSQL compatible cloud database, have gone beyond pgvector, with Neon developing its own pg_embedding approach to supporting vectors in PostgreSQL.\nGutmans explained that with AlloyDB, Google is providing AI is a \u2018superset\u2019 of capabilities on top of pgvector. For one, the vector capabilities have been integrated deeply into the AlloyDB query processing engine.\n\u201cWe\u2019re probably smarter in how we execute the queries and how we optimize the queries,\u201d said Gutmans.\u00a0\nThe other key element is added vector quantization support. Getmans explained that quantization enables AlloyDB users to significantly reduce vectors\u2019 resource footprint in a running database, which helps improve and reduce storage costs.\nBeyond just boosting pgvector, Gutmans emphasized that Google\u2019s goal is to make it easier for developers to bring LLMs and enterprise data together.\nAlloyDB AI integrates an easy way for developers to generate vector embeddings in several approaches. One approach is via an integration with Google\u2019s Vertex AI to create vector embeddings. Additionally, Gutmans noted that Google is integrating a series of very lightweight embeddings models into the database. Integration with the open source LangChain technology is also part of the rollout, with the goal to help developers pull together data for AI powered applications.\n\u201cYou should really think about [AlloyDB} as being all the different capabilities that developers need to be successful and bridging the gap between the data and LLMs,\u201d said Gutmans.\nPostgreSQL \u2014 and by extension, databases such as AlloyDB based on it \u2014 have long been positioned as potential alternatives to the Oracle database.\nGoogle has been iterating on its own database migration service for its databases over the last several years. The database migration service aims to automatically map an existing Oracle database and its functions into an AlloyDB deployment. Gutmans explained that the existing technology is a rules-based model that meets many requirements, but it doesn\u2019t solve for all use cases. That\u2019s where the new Duet AI in the database migration service fits in.\nThe Duet AI in the database migration service enables developers to provide a prompt with manual hints on how they want to migrate certain parts of their Oracle database stored procedures. Gutmans said that Duet AI uses an LLM to generate the necessary code that can run across a cluster.\n\u201cThere\u2019s only so much you can do with a rules-based engine to migrate Oracle stored procedures to PostgreSQL,\u201d said Gutmans. \u201cDuet AI is basically an AI system for folks doing code conversion for that last mile that we couldn\u2019t actually convert automatically.\u201d"}, "Dell\u2019s VC arm backs industrial edge software maker IOTech\u2019s expansion to North America": {"Date": "August 29, 2023 5:00 AM", "Author": "Carl Franzen", "Link": "https://venturebeat.com/automation/dells-vc-arm-backs-industrial-edge-software-maker-iotechs-expansion-to-north-america/", "Content": "You may not have heard of IOTech \u2014 yet. \nBut that\u2019s changing if Dell Technologies Capital has anything to say about it. The venture capital arm of the iconic PC brand has invested a new, undisclosed sum in IOTech, a U.K.-based firm that makes open-source software solutions for industrial edge devices. With the money, IOTech is targeting a major expansion of its business in the U.S. and North America. \nThink of all the sensors that the operator of a manufacturing plant might want to stick around their equipment to ensure it is running smoothly. Or the operator of a solar farm, who wants to know which cells are not performing well. Or the landlord of a building seeking to boost its environmental efficiency ratings. IOTech\u2019s software is designed to work for all these types of use cases where physical capital can be monitored best by sensors at the \u201cedge\u201d feeding data about performance, state and conditions back into the cloud for decision-makers to review and act upon. \nThis is what gives IOTech the \u201cIOT\u201d of its name: the Internet of Things \u2014 in this case, industrial things. Real-world devices equipped with sensors and analyzed using intelligent software.\nThe company already has a star-studded client list, including Accenture, EATON, Fluence Energy, Johnson Controls, King Steel and Schneider Electric.\nWhile IOTech has to date built up most of its clientele in Europe and the Asia/Pacific region, the new funding round from Dell Technologies Capital \u2014 following its 2018 seed investment, according to Crunchbase \u2014 seeks to empower the company to make a bigger impact across the pond. \nExisting stakeholders, including SPDG \u2014 the holding company of the P\u00e9rier-D\u2019Ieteren family \u2014 Northstar Ventures and the Scottish Investment Bank are all contributing more. \nThe fresh funds will empower the company to beef up its sales, marketing and pre-sales support. On top of that, IOTech has added field CTOs to its roster, further fortifying its expertise.\nTo help navigate this bold new chapter, David C. King, a seasoned hand in the industrial IoT world and former CEO of FogHorn, is joining IOTech\u2019s board of directors. \nKing is no stranger to steering companies toward success; he led FogHorn through three successful funding rounds before it was acquired by industrial automation giant Johnson Controls in 2022. \nGregg Adkin, managing director with Dell Technologies Capital, believes that IOTech\u2019s technology is like a gold mine for industrial data. \nAs IOTech sets its sights on further U.S. growth, it\u2019s also broadening its product portfolio beyond its current offering Edge Central, a control center that manages everything from connectivity to data processing of sensors and edge devices. \nThis platform is a spin-off from EdgeX, a leading open-source data integration platform.\nIOTech says its platform is not only adaptable, but future-proof, safeguarding investments well beyond the hardware life cycle."}, "BuildESG Adds Free Version of BuildRI Software, Accelerating the Path Toward a Single Source of Trust for Responsible Investment Integration in the Alternative Investment Sector": {"Date": "August 29, 2023 4:25 AM", "Author": "Press Release", "Link": "https://venturebeat.com/business/buildesg-adds-free-version-of-buildri-software-accelerating-the-path-toward-a-single-source-of-trust-for-responsible-investment-integration-in-the-alternative-investment-sector/", "Content": "\nThe BuildRI Platform for LPs, Lenders and Investment Managers Emerges as the Network for Assessing, Supporting and Sharing Responsible Investment and ESG Information\n\nNEW YORK\u2013(BUSINESS WIRE)\u2013August 29, 2023\u2013\nAfter launching its award-winning ESG operating platform in 2022, BuildESG, a leader in the responsible investment reporting landscape, is delighted to announce the launch of a free version of its BuildRI software. Tailored to meet the needs of alternative investment managers in private equity, venture capital and private debt and their key stakeholders, BuildRI aims to make responsible investment integration more standardized, accessible and actionable.\n\u201cIn a financial landscape where responsible investment practices are taking center stage, the need for a powerful, yet easy-to-use platform for the alternative investment sector is greater than ever,\u201d said James Lindstrom, CEO of BuildESG. Mr. Lindstrom continued, \u201cThe free BuildRI platform provides the essential tools for an alternative investment manager to launch, manage and report on its responsible investment program consistent with leading frameworks and standards.\u201d\nSupports Launch and Sharing of Responsible Investment Progress Across Limited Partner and Lender Network\nTo reinforce its commitment to facilitating responsible investment across the alternative investment industry, BuildRI offers free portals not just for investment managers, but also for their portfolio companies, limited partners and lenders. These dedicated portals enable sharing of content, ratings and data, serving as a centralized hub for collaborative responsible investment.\nFeature-Rich Software Focused on Responsible Investment\nTo support a firm\u2019s program launch, BuildRI offers a comprehensive set of features, including:\nTo get started with BuildRI, please contact info@buildesg.com or visit www.buildesg.com.\nAbout BuildESG\nBuildESG is a mission-driven organization providing a standardized Responsible Investment (RI) and Environmental, Social and Governance (ESG) platform and ratings system to investment managers, asset owners, limited partners and lenders. BuildESG\u2019s platform product, BuildRI, is a single source of trust for investment managers and their limited partners, helping to assess, support and highlight managers and portfolio companies who prioritize responsible investment practices. BuildESG\u2019s affiliates have provided strategic reporting services to the world\u2019s leading organizations since 1999. To learn more, please visit www.buildesg.com.\n\nView source version on businesswire.com: https://www.businesswire.com/news/home/20230829505166/en/\nInformation info@buildesg.com"}, "Professor J Mocco to Join Protembis\u2019 Board of Directors": {"Date": "August 29, 2023 12:25 AM", "Author": "Press Release", "Link": "https://venturebeat.com/business/professor-j-mocco-to-join-protembis-board-of-directors/", "Content": "\nProtembis announces the appointment of Professor J. Mocco to Board of Directors\n\nAACHEN, Germany\u2013(BUSINESS WIRE)\u2013August 29, 2023\u2013\nProtembis GmbH (Protembis) a privately-held emerging cardiovascular medical device company, announced today the appointment of Professor J Mocco MD, MS, FAANS, FAHA of Icahn School of Medicine at Mount Sinai, NY, USA as an independent member of their Board of Directors.\nProfessor Mocco brings a wealth of clinical and academic experience as the Kalmon D. Post Professor and Senior Vice Chair of the Department of Neurological Surgery at Mount Sinai and is the immediate past President of the Society of Neurointerventional Surgery. Over his distinguished medical career spanning more than 20 years, he has authorship credits on over 600 publications. He is an editorial board member of Stroke since 2015 and has served or is serving as an associate editor of other journals including Neurosurgery, the Journal of Neurointerventional Surgery, and ISNR Stroke.\nIn his new role on the Board of Protembis, Professor Mocco will offer insights into the strategic direction of the company with his deep knowledge and clinical insights of endovascular stroke diagnosis and management. He will offer guidance on clinical strategies and new product development.\n\u201cI have been impressed by the Protembis team\u2019s achievements in developing an elegant system to mitigate cerebral infarction risk during Transcatheter Aortic Valve Replacement\u201d says Professor Mocco. He continues: \u201cTheir adaptive IDE clinical trial strategy is both rigorous and innovative. I am excited to offer my insights and guidance to the Board as this field evolves to treat future aortic stenosis patients who will have zero tolerance for brain injury as a potential procedural complication\u201d.\nProtembis has recently received FDA approval to conduct an IDE study aimed at demonstrating safety and efficacy of the ProtEmbo\u00ae Cerebral Protection System (\u201cProtEmbo\u201d) during transcatheter aortic valve replacement (\u201cTAVR\u201d). The ProtEmbo\u00ae System is an intra-aortic filter device that protects the entire brain from embolic material liberated during the TAVR procedure. It is a low-profile system that shields all cerebral vessels, delivered through the left radial artery for optimal placement and stability. This is an ideal access site enabling physicians to avoid interference with TAVR equipment which is typically delivered through the femoral artery. The IDE study is designed as a multicenter randomized controlled trial in the USA and Europe.\n\u201cTo have such an eminent expert with deep experience in the field of stroke joining our Board, is a strong indication of the Protembis solution for cerebral embolic protection\u2019s impact in the future of TAVR\u201d say Karl von Mangoldt and Conrad Rasmus Co-CEOs of Protembis. \u201cI am delighted to welcome Professor Mocco to the Board of Protembis and to have his insights and strategic guidance as we generate confirmatory clinical data and further advance the field of cerebral embolic protection with the ProtEmbo System for complete cerebral protection\u201d adds Dr Azin Parhizgar, Chairwoman of the Protembis Board of Directors.\nAbout Protembis\nProtembis is a privately-held emerging medical device company that has developed the ProtEmbo\u00ae Cerebral Protection System. The company strives to provide a simple and reliable solution to protect patients from brain injury during left-sided heart procedures, improving patient quality of life and reducing overall healthcare costs associated with brain injury during such procedures. The ProtEmbo\u00ae System is currently undergoing clinical investigations.\n\nView source version on businesswire.com: https://www.businesswire.com/news/home/20230829785853/en/\nProtembis GmbHConrad Rasmus & Karl von MangoldtCo-CEOs & Co-Founders+49(0)241 9903 3622management[at]protembis.comwww.protembis.com"}, "OpenAI launches long-awaited ChatGPT for Enterprise \u2014 but is it playing catch-up?": {"Date": "August 28, 2023 10:54 AM", "Author": "Sharon Goldman", "Link": "https://venturebeat.com/ai/openai-launches-long-awaited-chatgpt-for-enterprise-but-is-it-playing-catch-up/", "Content": "Today OpenAI announced the launch of ChatGPT Enterprise, a platform that it hopes will entice large business users to invest in its growing software ecosystem. It is a long-awaited milestone that the company has been teasing since it launched ChatGPT last November \u2014 but is OpenAI now playing catch-up when it comes to bringing generative AI to the enterprise? \nAfter all, not only are many other companies targeting the same enterprise business audience with generative AI  \u2014 Cohere offers bespoke Large Language Model (LLM) options for the enterprise; Anthropic partnered with Scale AI to target the enterprise; and even Microsoft Azure has its own OpenAI service \u2014 but open source players are in the mix as well. Meta\u2019s LLaMA 2, for instance, is available for commercial use. \nStill, as the first massively popular LLM interface geared toward consumers with 100 million monthly users at one point, OpenAI\u2019s ChatGPT has already entered the pop culture lexicon (it was recently mentioned disparagingly at the U.S. Republican presidential debates). A new enterprise option may convince companies that were holding out for a product from arguably the most recognizable name in generative AI so far. \nThe company says ChatGPT for Enterprise focuses on \u201centerprise-grade security,\u201d unlimited access to GPT-4, extended context windows, advanced data analysis capabilities and customization options. \nSavvy enterprise technology leaders such as CTOs and heads of IT will be concerned about the security ramifications of ChatGPT for Enterprise. However, OpenAI offers two features to assuage doubts: \u201cCustomer prompts or data are not used for training models,\u201d the company states. \nIt also offers \u201cdata encryption at rest (AES-256) and in transit (TLS 1.2+),\u201d and OpenAI says ChatGPT for Enterprise \u201chas been audited and certified for SOC 2 Type 1 compliance (Type 2 coming soon).\u201d As for data retention, OpenAI explains that \u201cChatGPT Enterprise securely retains data to enable features like conversation history. You control how long your data is retained. Any deleted conversations are removed from our systems within 30 days.\u201d \nIn a blog post outlining the new service offerings, OpenAI introduces several features of ChatGPT Enterprise that elevate its capabilities beyond the standard version. Users gain unlimited access to the faster GPT-4, enabling seamless and efficient interactions. The increased context window of 32k tokens allows for processing longer inputs and files, enhancing versatility.\u00a0\nAdvanced data analysis, previously known as Code Interpreter, empowers both technical and non-technical teams to analyze information in seconds. \nAdditionally, shared chat templates enable collaborative workflows \u2014 with multiple team members able to engage in a single ChatGPT session \u2014 while free credits for OpenAI\u2019s API offer customization options for organizations seeking a fully tailored LLM solution.\nHow much does it cost? OpenAI hasn\u2019t specified, only sending VentureBeat the following email via a spokesperson: \u201cIt will depend on each company\u2019s use case. Those interested should reach out to us for more information.\u201d \nIn its blog post, OpenAI said it \u201cremains committed\u201d to continuous improvement and expansion of ChatGPT Enterprise. It says long-term plans include upcoming features such as secure customization with company data integration, a self-serve ChatGPT Business offering for smaller teams and enhanced power tools for advanced data analysis and browsing.\u00a0\nOpenAI said it aims to cater to specific roles within organizations, such as data analysts, marketers and customer support, by providing targeted solutions. \nEnterprise companies are moving slowly and deliberately to adopt\u00a0generative AI if they have even started at all \u2014 whether because of\u00a0concerns\u00a0around enterprise data security and AI \u201challucinations\u201d or a lack of the necessary technology, talent and governance to implement generative AI successfully.\nThere\u2019s certainly no doubt that executives want to access the power of generative AI. However, according to a\u00a0recent KPMG study\u00a0of U.S. executives, a solid majority (60%) of respondents said that while they expect generative AI to have an enormous long-term impact, they are still a year or two away from implementing their first solution."}, "Finding the soul of AI on an NYC rooftop at sunset  | The AI Beat": {"Date": "August 28, 2023 9:47 AM", "Author": "Sharon Goldman", "Link": "https://venturebeat.com/ai/finding-the-soul-of-ai-on-an-nyc-rooftop-at-sunset-the-ai-beat/", "Content": "As the senior reporter covering AI at VentureBeat, I often feel buried by the sheer scale of AI news, and occasionally left in the dust by the speed of the news cycle. I began my tenure in April 2022, the same week OpenAI launched its game-changing text-to-image generator DALL-E 2. From that moment on, it feels like I have barely stopped trying to catch up to the pace of development and trends in the space. I know I am far from alone \u2014 many in the AI community have shared with me that they feel the same way. \nI also work remotely in the New York City metro area, which I love. But mostly being on my own \u2014 interacting with my colleagues and editors on Slack, and chatting with sources on email, Twitter/X, Zoom, Teams, Meet, etc. \u2014 and living outside of San Francisco and Silicon Valley means only rarely getting a sense of the AI community in real life. Even the occasional conference is typically too overwhelming, with so many sessions, keynotes and workshops to attend, to get to meet people in a relaxed, casual way. \nYet, I often long to do just that. There are so many issues and trends at play right now in AI \u2014 everything from potential risks of generative AI and regulatory efforts to workplace issues, research developments, debates around open and closed source AI. In addition to the move towards an AI-focused technology stack to help companies and enterprises begin to address possible use cases. \nSometimes I just want to get a group together and, well, talk about it all. \nThat\u2019s why I was so amazed by the response I got to a simple, throwaway post on X back on August 10. Our editorial director, Michael Nu\u00f1ez, was coming to New York City from San Francisco the week of August 25. Would anyone be up for a drink hang? Perhaps a dozen might meet us at a local bar to talk AI, I suggested. \nInstead, the response was overwhelming, on social media, email and in direct messages. Clearly, we needed a bigger boat \u2014\u00a0that is, a venue for an actual meetup. I reached out to William Falcon, CEO of Lightning AI, for a suggestion \u2014 he immediately offered up his building\u2019s beautiful Manhattan rooftop. And we were off and running to quickly plan an AI event, called AI Loves NY, for the following week. In just a few days (thanks to the amazing team at Lightning AI, shout out to Surya!) we had more than 800 RSVPs, Michael was on a plane across the country, and we were ready to go. \nI can only describe the result as magical \u2014\u00a0a moment not just for the NYC tech community to come together, but also a welcome break from the normal networking routine of panels, workshops and discussions. I know plenty of Silicon Valley folks are at Burning Man this week, but for me, a laid-back evening with a Manhattan sunset and a view of the Empire State Building would have to do. \nI met programmers and researchers, startups and Big Tech folks, journalists and marketers, established brands and VCs. I felt the kind of energy and connection that is uniquely human \u2014 the antithesis of AI, really \u2014 and necessary, I think, to the success of any community or industry. \nLook, maybe I had a little too much wine. Perhaps I had a little too much adrenaline and excitement. But as cheesy as it may sound, I almost felt like I had discovered the soul of AI \u2014 no, not the endless talk about \u201csentience\u201d or \u201cAGI\u201d \u2014 but the community of people involved in bringing this technology into the mainstream. \nI\u2019ll pause for a minute, and acknowledge the thousands and thousands of human beings who often do not get acknowledged when it comes to thinking about the \u201cmagic\u201d of AI \u2014\u00a0the veritable army of overseas, often exploited workers supporting the development of generative AI. Today\u2019s article in the Washington Post about low-paid workers in the Philippines is just the latest example of a frustrating and nauseating trend that needs to be acknowledged more fully by companies and enterprises looking to profit from generative AI. \nBut I can\u2019t deny that on this Manhattan rooftop at sunset, on a late-summer evening with a slight breeze in the air, I felt a connection that I hope to experience more of: A vibrant, thriving AI community, in New York and beyond. "}, "Honeywell\u2019s acquisition of cybersecurity provider sets sights on manufacturing sector\u2019s deep IoT vulnerabilities": {"Date": "August 28, 2023 9:37 AM", "Author": "Louis Columbus", "Link": "https://venturebeat.com/security/honeywell-acquisition-cybersecurity-provider-manufacturing-sector-iot-vulnerabilities/", "Content": "The manufacturing sector is rife with unprotected Internet of Things (IoT) sensors and devices, many of them integrated into enterprises\u2019 mission-critical systems. The resulting gaps make operations technology (OT) and information technology (IT) networks vulnerable to devastating cyberattacks.\nVisibility is key. Shivan Mandalam, director of product management for IoT security at CrowdStrike, told VentureBeat that \u201cit\u2019s essential for organizations to eliminate blind spots associated with unmanaged or unsupported legacy systems. With greater visibility and analysis across IT and OT systems, security teams can quickly identify and address problems before adversaries exploit them.\u201d\nHoneywell\u2019s acquisition of Israel-based SCADAfence, a leading provider of OT and IoT cybersecurity solutions, is just one example of the manufacturing industry trying to catch up, close these gaps and defend against increasing numbers of ransomware attacks.\u00a0\nAnything that stops a shop floor from operating can quickly cost a business millions of dollars. That\u2019s why ransomware attacks on manufacturers generate millions in payouts. Hundreds of manufacturers pay ransomware demands without disclosing that fact to customers.\u00a0\nGartner predicts that the\u00a0financial impact of cyber-physical system (CPS) attacks will reach more than $50 billion by 2023. Recovery from a typical manufacturing breach costs $2.8 million. Not only that: Nearly nine in 10 manufacturers that have suffered a ransomware attack or breach have also had their supply chains disrupted.\u00a0\u00a0\nHoneywell\u2019s SCADAfence acquisition provides the manufacturing giant \u201cwith additional technology and expertise that help accelerate our innovation roadmap \u2026 and support rapidly evolving customer requirements,\u201d Michael Ruiz, GM of Honeywell Cybersecurity Services, said in a recent interview with VentureBeat.\nThe acquisition will deliver an integrated platform to manufacturers, process industries and infrastructure providers at a time when attacks are escalating.\u00a0\n\u201cSCADAfence is an ideal complement to Honeywell\u2019s OT cybersecurity portfolio, and when combined with the Honeywell Forge Cybersecurity+ suite, it enables us to provide an end-to-end solution with applicability to asset, site and enterprise across key Honeywell sectors,\u201d said Ruiz.\u00a0\nKey focus areas include asset discovery, threat detection and compliance management, he told VentureBeat. \u201cOur plan is to have the SCADAfence product portfolio integrate into the Honeywell Forge Cybersecurity+ suite within Honeywell Connected Enterprise, Honeywell\u2019s fast-growing software arm with a strategic focus on digitalization, sustainability and OT cybersecurity SaaS offerings and solutions.\u201d\u00a0\nKnown for its process analysis and integration expertise, Honeywell is concentrating on how it can make the most of its strengths in these areas and achieve scale quickly with the new acquisition. \n\u201cThis integration will enable Honeywell to provide an end-to-end enterprise OT cybersecurity solution to site managers, operations management and CISOs seeking enterprise security management and situational awareness,\u201d said Ruiz.\u00a0\nSCADAfence CEO Elad Ben Meir also commented on the synergies between the companies. \u201cWe are thrilled to join Honeywell as we work towards fulfilling our mission of empowering industrial organizations to operate securely, reliably and efficiently,\u201d Ben Meir said in a press release. \u201cThis combination creates a significant opportunity for growth, allowing us to combine our top-tier OT cybersecurity products with one of the world\u2019s leading companies in industrial software.\u201d\u00a0\u00a0\nThe deal expands Honeywell\u2019s cybersecurity center of excellence in Tel Aviv, where SCADAfence is headquartered. Ruiz told VentureBeat that one of the most valuable aspects of the acquisition is that Honeywell will be able to \u201cnearly double our research and development for OT cybersecurity, probably becoming one of the larger OT cybersecurity research and development organizations out there.\u201d\nThe IBM Security X-Force Threat Intelligence Index found that manufacturing is the most attacked industry worldwide: The sector accounted for 23% of all ransomware attacks last year. More than six in 10 breach attempts on manufacturers first targeted OT systems essential to manufacturing operations.\nResearch firm Dragos predicts that ransomware attacks on industrial organizations will accelerate this year. Dragos\u2019 most recent Industrial Ransomware Attack Analysis from Q2 2023 found that 47.5% of ransomware attacks tracked globally impacted industrial organizations and infrastructure in North America, an increase of 27% over the last quarter.\nAll told, seven out of 10 ransomware attacks in Q2 were aimed at manufacturing, followed by the industrial control systems (ICS) equipment and engineering sector, which accounted for16% of attacks.\nThe rapid rise in Fileless malware attacks reflects this trend. Fileless malware is designed to evade detection by cloaking its presence using legitimate tools. Kurt Baker, senior director of product marketing for CrowdStrike Falcon Intelligence, writes that \u201cfileless malware is a type of malicious activity that uses native, legitimate tools built into a system to execute a cyber-attack. Unlike traditional\u00a0malware, fileless malware does not require an attacker to install any code on a target\u2019s system, making it hard to detect. This fileless technique of using native tools to conduct a malicious attack is\u00a0sometimes referred to as\u00a0living off the land\u00a0or LOLbins.\u201d\nSecurity providers are upping their games. \nLast year at Fal.Con 2022, CrowdStrike augmented Falcon Insight, launching Falcon Insight XDR and Falcon Discover for IoT that target security gaps in and between industrial control systems (ICSs).\u00a0\nIvanti, for its part, has successfully launched four solutions for IoT security: Ivanti Neurons for RBVM, Ivanti Neurons for UEM, Ivanti Neurons for Healthcare \u2014 which supports the Internet of Medical Things (IoMT) \u2014 and Ivanti Neurons for IIoT\u00a0based on the company\u2019s Wavelink acquisition, which secures Industrial Internet of Things (IIoT) networks.\nOther leading providers offering IoT cybersecurity solutions include AirGap Networks, Absolute Software, Armis, Broadcom, Cisco, CradlePoint, CrowdStrike, Entrust, Forescout, Fortinet, Ivanti, JFrog and Rapid7.\nAirgap Networks has created one of the most innovative approaches to closing the OT-IT gap. Its \u00a0 Zero\u00a0Trust\u00a0Firewall (ZTFW)\u00a0combines agentless microsegmentation, secure access for critical assets and network and asset intelligence. Airgap\u2019s unique approach provides its customers with the option of fully\u00a0segmenting legacy servers, ICS, IoT and private 5G endpoints. The platform can also integrate into a running network without agents, hardware upgrades or major device changes.\u00a0\nVentureBeat interviewed Ritesh Agrawal, CEO of Airgap Networks, immediately following its launch of ThreatGPT, the company\u2019s ChatGPT integration with the Airgap Zero Trust Firewall. Agrawal told VentureBeat: \u201cBecause ThreatGPT is fully integrated into the core of the ZTFW architecture, our customers can use all available data to train the models. I believe we are first to market with this.\u201d \nThreatGPT uses\u00a0graph databases\u00a0and GPT-3 models to help SecOps teams gain new threat insights.\u00a0The GPT-3 models analyze natural language queries and identify security threats, while graph databases provide contextual intelligence on endpoint traffic relationships.\u00a0\nAgrawal told VentureBeat that, \u201cIoT puts a lot of pressure on enterprise security maturity.\u00a0Extending zero trust to IoT is hard because the endpoints vary, and the environment is dynamic and filled with legacy devices.\u201d\nAsked how manufacturers and other high-risk industry targets could get started, Agrawal advised that \u201caccurate asset discovery, microsegmentation and identity are still the right answer, but how to deploy them with traditional solutions when most IoT devices can\u2019t accept agents? This is why many enterprises embrace agentless cybersecurity like Airgap as the only workable architecture for IoT and IoMT.\u201d"}, "This is how AI will shape early-career tech jobs": {"Date": "August 28, 2023 9:24 AM", "Author": "Aoibhinn Mc Bride, Jobbio", "Link": "https://venturebeat.com/programming-development/this-is-how-ai-will-shape-early-career-tech-jobs/", "Content": "Move over dial-up internet.\nFrom now on, the generational divide within the workplace looks set to revolve around remembering the days before AI dominated almost every aspect of our work lives, and the period after.\nIn fact, according to a recent study by McKinsey, generative AI is now being used by 79% of all workers and 22% use it regularly to complete their everyday work tasks.\nCouple this with the fact that AI is predicted to eliminate 83 million global jobs by 2027 and it\u2019s easy to see why for those starting out in their careers, AI will not only shape their day-to-day but have a massive impact on their overall career trajectory.\nThis is probably why educational institutions are the second largest cohort to utilize ChatGPT within the workplace after tech, and colleges are racing to build state-of-the-art AI faculties to not only facilitate student demand but address the skills gap which has seen 75% of companies struggle to recruit qualified talent.\u00a0\nAt the University of Albany, 27 new faculty members specializing in artificial intelligence have been hired \u201cto incorporate elements of AI teaching and research across all academic programs.\u201d\nElsewhere, the University of Southern California has invested more than $1 billion in its AI initiative which included courses in advanced computation, quantum computing, AI and ethics.\nAnd Purdue University has established its Institute for Physical AI (IPAI), the first of its kind in the U.S., which will focus on areas including robotics, deep fake detection and AI-based manufacturing among others.\nSo, what does this mean for those who fall into the \u201cdays before AI\u201d camp?\nAccording to the World Economic Forum (WEF), 50% of all employees will need reskilling by 2025 as the adoption of technology increases.\nAnd while keeping hard skills fresh and up-to-date is imperative, there\u2019s also been a renewed focus on the importance of soft skills.\nAs such, the WEF has also identified the top 10 skills of tomorrow and critical thinking and problem-solving top the list along with creativity, leadership, resilience, flexibility and stress tolerance \u2014 all of which machines are yet to master.\nWhatever stage you\u2019re at in your working life, the VentureBeat Job Board is the perfect place to start your search if you\u2019re looking for a way to futureproof your career prospects. It features thousands of jobs in companies that are actively hiring, like the three below.\nNVIDIA is seeking a Senior Deep Learning Algorithms Software Engineer to join its deep learning algorithms team to develop and commercialize AI solutions related to natural language processing, computer vision, speech, text and recommendation systems. Day-to-day you\u2019ll be developing algorithms for deep learning, data analytics, machine learning or scientific computing, constructing and curating large problem specific datasets, analyzing and improving the performance of graphic processing unit implementations and publishing state-of-the-art results on Github and scientific publications. View more details here.\nCapgemini Engineering is an integral part of the Capgemini Group which addresses business needs, from strategy and design to operations, fuelled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. As Software Engineer Lead, you will design, develop and unit test APIs and applications, collaborate with multi-functional teams (such as architects, testers, product managers) and deliver, contribute to design architectural discussions, help triage, identify root cause for issues and implement solutions and document high and low level designs, sequence diagrams and flow diagrams etc. See the full job description here.\nProject Starline from Google combines advances in hardware and software to enable friends, families and co-workers to feel together, even when they\u2019re cities (or countries) apart. In this Senior Product Manager role, you will work cross-functionally to guide products from conception to launch by connecting the technical and business worlds. You can break down complex problems into steps that drive product development. You\u2019ll need a Bachelor\u2019s degree or equivalent practical experience, eight years\u2019 of experience in product management, consulting, co-founder or related technical role, and three years\u2019 of experience in building and shipping technical products. Get more information here.\nDiscover thousands more opportunities in tech on the VentureBeat Job Board."}, "ConverSight raises $9M to accelerate data analytics with generative AI": {"Date": "August 28, 2023 8:47 AM", "Author": "Shubham Sharma", "Link": "https://venturebeat.com/enterprise-analytics/conversight-raises-9m-to-accelerate-data-analytics-with-generative-ai/", "Content": "Indianapolis-based ConverSight, a startup that seeks to leverage generative AI to provide better and faster data analytics to enterprises, today announced a $9 million series A round. \nThe company said it will use the new funding to fuel go-to-market efforts and expand its product with new features, including what it calls \u201cMarketSpace.\u201d\nSurface Ventures led the investment, with participation from Techstars, Augment Ventures, Elevate Ventures and multiple earlier backers returning. \nWith it, ConverSight has raised more than $15 million to date, and the new infusion comes at a critical time, as a number of data infrastructure vendors also seek to use AI large language models (LLMs) to make it easier for teams to control, access and configure their data. \n\u201cWhile many companies have incorporated generative AI into data analytics over the past year, ConverSight has been working on this problem for more than 5 years and we believe has a critical head start in ensuring accuracy for mission-critical analytics,\u201d Gyan Kapur, co-managing partner at Surface VC, said in a statement. \u201cWe see the potential for ConverSight\u2019s platform to continue to extend its market leadership\u2026\u201d\nTraditionally, businesses relied on developer-generated reports and dashboards to get the visualizations they needed to perform analysis and make decisions. The process was pretty static and took a lot of time, especially considering the pre-analytic steps of data integration, storage, etc.\nConverSight, founded in 2017, created a self-service, all-in-one solution for enterprise customers, covering the whole process end to end, right from data integration and storage to data transformation, analysis and reporting.\n\u201cThe platform offers the necessary data Infrastructure, data sourcing and data storage (cloud neutral) foundation followed by a thorough data exploration and data transformation process. Once that\u2019s done, the data science and data consumption (visualization) layer follow up, which is rounded off with conversational AI and NLP functionality to drive a totally unique and contextual experience down to the user role, level and department,\u201d Ganesh Gandhieswaran, CEO and cofounder of ConverSight, told VentureBeat.\nThe conversational AI experience, dubbed Athena, is delivered with the company\u2019s homegrown LLM and patented knowledge graph. It works just like OpenAI\u2019s ChatGPT, where users simply put in their queries through voice or chat and the bot provides the required answer, complete with necessary details and context.\u00a0\n\u201cOver time, the AI capabilities enable Athena to anticipate questions or insights needed to proactively push insights and reports to end users. It develops a contextual understanding to paint a real-time picture of your business followed by recommendations and automated actions to help teams meet goals and improve decision-making,\u201d Gandhieswaran added.\nThis, in a nutshell, makes the entire process of analytics consumption more on-demand and dynamic than ever.\nConverSight has already established a strong footprint with over 200 enterprise customers and dedicated solutions catering to functions like supply chain, services, sales and procurement. With this round, the company plans to accelerate its go-to-market teams and efforts as well as build out new product innovations to transform how companies consume data analytics.\u00a0\nThis, Gandhieswaran said, will include a new MarketSpace, which will be enterprise teams\u2019 go-to place to discover a curated list of commonly used resources and solution templates.\u00a0\n\u201cNeed to supercharge your inventory management? Try out the inventory optimization resource. Looking to enhance supply chain visibility? The supply chain visibility resource might be just what you need. Each resource comes with detailed explanations of its benefits for subscribers. You can easily subscribe and access these resources for a nominal fee. While payment integration is in the works, for now, a simple subscription process will notify us when you\u2019re ready to dive in,\u201d the CEO explained.\nAlong with ConverSight, a number of data players are using generative AI to transform how teams interact with their data and consume insights.\u00a0\nData lakehouse vendor Databricks, for one, has launched LakehouseIQ to allow anyone in an organization to search, understand and query internal corporate data by simply asking questions in plain English. Similarly, ThoughtSpot has launched Sage, a new LLM-driven search experience that provides enterprise users with a chat experience where they can type natural language prompts to query data for text or visual insights. Dremio and Tableau have also taken similar steps.\nAccording to McKinsey, generative AI, with its promise to unlock new sources of value and innovation, could add up to $4.4 trillion to the global economy.\u00a0"}, "Qualiti.ai Secures $6.5 Million Seed Funding to Ensure Software Engineers Never Need to Test Again": {"Date": "August 28, 2023 7:25 AM", "Author": "Press Release", "Link": "https://venturebeat.com/business/qualiti-ai-secures-6-5-million-seed-funding-to-ensure-software-engineers-never-need-to-test-again/", "Content": "LEHI, Utah\u2013(BUSINESS WIRE)\u2013August 28, 2023\u2013\nQualiti.ai, a Utah-based software test automation solution, announced the closing of a $6.5 million Seed round today. Sierra Ventures led the funding round, with participation from Epic Ventures.\nFounded by industry veterans Peter West (CEO) and Jeff Handy (COO), Qualiti uses AI to test any software product without human input. Qualiti can be set up in just 15 minutes, after which a full test suite will be created without human effort. Qualiti\u2019s AI handles all new and ongoing test authoring and maintenance. Qualiti takes care of it 100% hands-off, adding new tests, maintaining existing tests, triaging results in real-time, and reporting any bugs found, all without human oversight or time, thus allowing it to replace up to 30% of a company\u2019s engineering budget.\nWith a rapidly growing customer base (340% MoM and growing), Qualiti will use the funding to expand sales and their world-class engineering team. Qualiti is poised to be the only tool a company will need for all of its QA. With engineers getting near-instant feedback on their applications as they push code, Qualiti will change the way software is developed forever.\n\u201cMost AI companies today are wrappers around chat-gpt and most seem to just be glorified grammar checkers. Even the more interesting applications tend to just be a tool to help you do what you\u2019re already doing. It\u2019s about time that AI does the work for us, and Qualiti has made that happen for testing \u2013 and we\u2019re the only ones who have truly made that, a truly hands-off no-human-work-needed AI managed solution, happen in testing,\u201d stated Qualiti.ai CEO Peter West.\n\u201cQualiti has an opportunity to disrupt the test automation industry, which is in desperate need of true innovation,\u201d said Sierra Ventures Managing Director Mark Fernandes. \u201cThe rapid adoption of their solution by developers at very selective companies is evidence that the team has hit a nerve.\u201d\nAbout Qualiti.ai:\nQualiti is a generative AI-powered software solution for testing automation. It builds test automation suites without any human input. Qualiti ensures applications are covered by writing high-quality automated tests. It will then execute tests, provide advanced triage, and alert team members of any failures. The company is based in Lehi, Utah. For more information, visit https://qualiti.ai/.\nAbout Sierra Ventures:\nSierra Ventures is a leading early-stage venture capital firm focused on the future of enterprise technologies. With four decades of experience and over $2 billion of assets under management, Sierra has created a vast network of successful entrepreneurs, Global 1000 CXOs, operational executives, and deep domain experts, providing a platform for entrepreneurs around the world. To connect with Sierra, visit https://www.sierraventures.com/.\nAbout Epic Ventures:\nEpic Ventures is a premier early-stage venture firm whose mission is to back entrepreneurs and companies positioned to lead the technologies and economy of tomorrow. With more than 15 IPO\u2019s and several dozen acquisitions, people, products, and passion drive our time and resources. To connect with Epic, visit https://epicvc.com/.\nFor inquiries, please reach out to Jeff Handy at jhandy@qualiti.ai.\n\nView source version on businesswire.com: https://www.businesswire.com/news/home/20230828402881/en/\nJeff Handyjhandy@qualiti.ai"}, "DoorDash launches AI-powered voice ordering": {"Date": "August 28, 2023 6:00 AM", "Author": "Sharon Goldman", "Link": "https://venturebeat.com/ai/doordash-launches-ai-powered-voice-ordering/", "Content": "For those who prefer the old-school method of ordering takeout \u2014 over the phone \u2014 DoorDash has your back. Today the food delivery platform launched AI-powered voice ordering that answers calls and provides customers with curated recommendations. \nAccording to\u00a0the company\u2019s\u00a02023 Restaurant Online Ordering Trends Report, one in five customers prefer ordering takeout via phone \u2014 but up to 50% of customer calls currently go unanswered, resulting in potential revenue losses.\u00a0\n\u201cCustomers expect more from restaurateurs, and in return, restaurateurs expect even more technology-forward solutions from us \u2014 including support for phone channels to meet customers where they\u2019re ordering,\u201d said Rajat Shroff, head of product and design at\u00a0DoorDash, in a press release. \u201cSupporting operators by capturing customer demand through investments in our voice product is one way we\u2019re delivering more and enabling our partners to grow their business.\u201d\nAI-powered voice ordering is becoming big business across the restaurant industry: In May, AI company SoundHound\u00a0announced\u00a0a voice AI partnership with Oracle for a point-of-sale technology integration that enables consumers to dictate their orders at the drive-thru. \nAt the same time, Uber Eats\u00a0launched\u00a0an Amazon Alexa integration that allows consumers to track orders through their Amazon Echo devices. \nAccording to DoorDash, the new voice AI offering is based on feedback from restaurant partners and on customer preferences. \u201cCoupling AI with best-in-class live agents ensures customer calls will be answered with little to no wait, enabling operators to capture the unmet customer demand,\u201d said the press release. \nIn addition, during restaurant peak times, AI can answer calls to allow employees to focus on hospitality to in-store customers. The AI offering also allows returning customers to quickly reorder their favorite meal, while live agents can jump in at any time. \nOf course, DoorDash was built on AI: According to a 2017 VentureBeat article, Tony Xu, DoorDash\u2019s cofounder, decided in 2013 to build the company\u2019s food-delivery software on artificial intelligence. \n\u201cDoorDash at the end of the day has to be a phenomenal measurement and data business,\u201d Xu said at\u00a0MB 2017. \u201cThere\u2019s a lot of information in the software world and in the physical world. From day one, our thinking was to create a business to bridge the two.\u201d\nMachine learning has long helped DoorDash with logistics, navigating \u201cdashers\u201d to the right places at the right time. It can also recalibrate a restaurant\u2019s offerings when a worker has called in sick, and offer personalized recommendations. "}, "Salesforce survey flags AI trust gap between enterprises and customers": {"Date": "August 28, 2023 5:00 AM", "Author": "Shubham Sharma", "Link": "https://venturebeat.com/ai/salesforce-survey-flags-ai-trust-gap-between-enterprises-and-customers/", "Content": "Regardless of the sector, companies of all sizes are moving to implement large language models (LLMs) into their workflows \u2014 to drive efficiencies and deliver better customer experiences.\u00a0\nHowever, a new Salesforce survey found that this so-called \u201crace\u201d to build out generative AI as soon as possible might come at the cost of a \u201ctrust gap\u201d with customers. The company\u2019s sixth State of the Connected Customer report, featuring data gathered between May 3 and July 14, 2023, surveyed more than 14,000 consumers and business buyers across 25 countries. It shows that even though customers and buyers are generally open to the use of AI for better experiences, a large number of folks still don\u2019t trust their companies to use AI ethically.\u00a0\nThe findings highlight a major issue that enterprises implementing gen AI need to address in order to deliver the best possible AI experiences to their customers and keep their business growing.\u00a0\nWhile the concept of \u201ctrust\u201d seems simple at first, the reality is it can be very complex and multifaceted. For instance, a person might trust the quality of a company\u2019s product but not its efforts toward sustainability. Similarly, they might not trust the company to protect their data.\nFor AI, trust is rooted in ethical principles where the system adheres to well-defined guidelines regarding certain fundamental values like individual rights, privacy and non-discrimination. According to the Salesforce survey, this is where the problem may appear.\nOut of the 14,000 respondents surveyed, 76% said they trust companies to make honest claims about their products and services but nearly 50% claimed they do not trust them to use use AI ethically.\u00a0\nWhile they highlighted multiple concerns, the most prominent challenges they reported were the lack of transparency and the lack of a human in the loop to validate the output of the AI \u2014 demanded by more than 80%. Just 37% of the respondents said they actually trust AI to provide as accurate responses as a human would.\u00a0\nOther concerns they flagged included data security risks, the possibility of bias (where the system may discriminate against a gender, for example), and unintended consequences for society.\nAmong the survey respondents, business buyers expressed more optimism towards AI than consumers did, with 73% of them noting they are open to the use of this technology by businesses for better experiences. In contrast, just 51% of consumers shared the same view.\nWhat\u2019s intriguing here is that the general sentiment still seems to have dipped since 2022 when generative AI \u2014 capable of producing new content in a matter of seconds \u2014 came onto the scene. Last year, as many as 82% of business buyers and 65% of consumers were open to the use of AI for better experiences, Salesforce said.\u00a0\nNotably, on the vendor side, optimism continues to remain sky-high, with a majority of professionals at the forefront of customer engagement (from IT and marketing to sales and service teams) saying generative AI will help their companies serve customers better.\u00a0\nEven though companies cannot stop AI implementation \u2014 after all, they have to stay relevant in today\u2019s dynamic environment \u2014 the survey found that a few key steps can help them win consumers\u2019 trust and make sure they are on board with the shift.\nThe first, as mentioned above, would be ensuring a greater level of transparency and human validation of AI\u2019s outputs. More than half of the customers surveyed said this would boost their trust. Beyond that, 49% of respondents said companies should focus on giving them more control of where and how AI is applied in engagement \u2014 such as opportunities to opt out; 39% called for third-party ethics review; and 36% sought government oversight.\u00a0\nOther suggested steps included industry standards for AI implementation, solicitation of customer feedback on how to improve AI\u2019s use, training on diverse datasets and making the underlying algorithms publicly available.\n\u201cAs brands find new ways to keep up with rising customer expectations, they must also consider diverse viewpoints among their (targeted) base,\u201d Michael Affronti, SVP and GM for Salesforce Commerce Cloud, said in a press release.\u00a0\n\u201cLeading with strong values and ethical use of emerging technologies like generative AI will be a key indicator of future success,\u201d he added."}, "Why generative AI is a double-edged sword for the cybersecurity sector": {"Date": "August 27, 2023 10:10 AM", "Author": "Peter Klimek, Imperva", "Link": "https://venturebeat.com/security/why-generative-ai-is-a-double-edged-sword-for-the-cybersecurity-sector/", "Content": "Much has been made of the potential for generative AI and large language models (LLMs) to upend the security industry. On the one hand, the positive impact is hard to ignore. These new tools may be able to help write and scan code, supplement understaffed teams, analyze threats in real time, and perform a wide range of other functions to help make security teams more accurate, efficient and productive. In time, these tools may also be able to take over the mundane and repetitive tasks that today\u2019s security analysts dread, freeing them up for the more engaging and impactful work that demands human attention and decision-making.\u00a0\nOn the other hand, generative AI and LLMs are still in their relative infancy \u2014 which means organizations are still grappling with how to use them responsibly. On top of that, security professionals aren\u2019t the only ones who recognize the potential of generative AI. What\u2019s good for security professionals is often good for attackers as well, and today\u2019s adversaries are exploring ways to use generative AI for their own nefarious purposes. What happens when something we think is helping us begins hurting us? Will we eventually reach a tipping point where the technology\u2019s potential as a threat eclipses its potential as a resource?\nUnderstanding the capabilities of generative AI and how to use it responsibly will be critical as the technology grows both more advanced and more commonplace.\u00a0\nIt\u2019s no overstatement to say that generative AI models like ChatGPT may fundamentally change the way we approach programming and coding. True, they are not capable of creating code completely from scratch (at least not yet). But if you have an idea for an application or program, there\u2019s a good chance gen AI can help you execute it. It\u2019s helpful to think of such code as a first draft. It may not be perfect, but it\u2019s a useful starting point. And it\u2019s a lot easier (not to mention faster) to edit existing code than to generate it from scratch. Handing these base-level tasks off to a capable AI means engineers and developers are free to engage in tasks more befitting of their experience and expertise.\u00a0\nThat being said, gen AI and LLMs create output based on existing content, whether that comes from the open internet or the specific datasets that they have been trained on. That means they are good at iterating on what came before, which can be a boon for attackers. For example, in the same way that AI can create iterations of content using the same set of words, it can create malicious code that is similar to something that already exists, but different enough to evade detection. With this technology, bad actors will generate unique payloads or attacks designed to evade security defenses that are built around known attack signatures.\nOne way attackers are already doing this is by using AI to develop webshell variants, malicious code used to maintain persistence on compromised servers. Attackers can input the existing webshell into a generative AI tool and ask it to create iterations of the malicious code. These variants can then be used, often in conjunction with a remote code execution vulnerability (RCE), on a compromised server to evade detection.\u00a0\nWell-financed attackers are also good at reading and scanning source code to identify exploits, but this process is time-intensive and requires a high level of skill. LLMs and generative AI tools can help such attackers, and even those less skilled, discover and carry out sophisticated exploits by analyzing the source code of commonly used open-source projects or by reverse engineering commercial off-the-shelf software.\u00a0\u00a0\nIn most cases, attackers have tools or plugins written to automate this process. They\u2019re also more likely to use open-source LLMs, as these don\u2019t have the same protection mechanisms in place to prevent this type of malicious behavior and are typically free to use. The result will be an explosion in the number of zero-day hacks and other dangerous exploits, similar to the MOVEit and Log4Shell vulnerabilities that enabled attackers to exfiltrate data from vulnerable organizations.\u00a0\nUnfortunately, the average organization already has tens or even hundreds of thousands of unresolved vulnerabilities lurking in their code bases. As programmers introduce AI-generated code without scanning it for vulnerabilities, we\u2019ll see this number rise due to poor coding practices. Naturally, nation-state attackers and other advanced groups will be ready to take advantage, and generative AI tools will make it easier for them to do so.\u00a0\u00a0\nThere are no easy solutions to this problem, but there are steps organizations can take to ensure they are using these new tools in a safe and responsible way. One way to do that is to do exactly what attackers are doing: By using AI tools to scan for potential vulnerabilities in their code bases, organizations can identify potentially exploitative aspects of their code and remediate them before attackers can strike. This is particularly important for organizations looking to use gen AI tools and LLMs to assist in code generation. If an AI pulls in open-source code from an existing repository, it\u2019s critical to verify that it isn\u2019t bringing known security vulnerabilities with it.\u00a0\nThe concerns today\u2019s security professionals have regarding the use and proliferation of generative AI and LLMs are very real \u2014 a fact underscored by a group of tech leaders recently urging an \u201cAI pause\u201d due to the perceived societal risk. And while these tools have the potential to make engineers and developers significantly more productive, it is essential that today\u2019s organizations approach their use in a carefully considered manner, implementing the necessary safeguards before letting AI off its metaphorical leash.\u00a0\nPeter Klimek is the director of technology within the Office of the CTO at Imperva."}}